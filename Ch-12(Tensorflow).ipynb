{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tensorflow like Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [4, 5, 5]])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1, 2, 3], [4, 5, 5]]) # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(40) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3]), tf.float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t.shape, t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras's Low Level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = tf.keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors And NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type Conversion\n",
    "\n",
    "# tf.constant(2.) + tf.constant(40) # Gives Error\n",
    "# tf.constant(2.) + tf.constant(40., dtype=tf.float64) # Also Give Error\n",
    "tf.constant(2.0) + tf.cast(tf.constant(40.), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors can't be changed so we use something called\n",
    "\n",
    "v = tf.Variable([[1., 2., 3.], [4. ,5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modifying Tensors\n",
    "\n",
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,   4.,   6.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Data Structures\n",
    "* Sparse tensors(tf.SparseTensor) -> efficiently represent tensors using mostly zeroes.\n",
    "* Tensor Array(tf.TensorArray) -> lists of tensors. all have same shape and same type. Could Be Dynamic\n",
    "* Ragged Tensor(tf.RaggedTensor) -> same as Tensor Array but Static\n",
    "* String Tensor(tf.string) -> they represent byte strings. can be converted into Unicode\n",
    "* Sets(tf.sets) -> can be represented by regular tensor or sparse tensor\n",
    "* Queues (tf.queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) * 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.arange(0, 100) * 3 + 2\n",
    "X_train = X_train.reshape((100, 1)).astype(dtype=np.float32)\n",
    "y_train = np.arange(0, 100, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e2a10dd4c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(10, activation=\"relu\"), \n",
    "                             tf.keras.layers.Dense(1)])\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"test_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Models That Contain Custom Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"test_model.h5\", \n",
    "                                   custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function with some different threshold\n",
    "\n",
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn\n",
    "\n",
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\")\n",
    "model.fit(X_train, y_train, epochs=10, verbose=0)\n",
    "model.save(\"test_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model of custom threshold loss\n",
    "model = tf.keras.models.load_model(\"test_model2.h5\", \n",
    "                                   custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Loss function with keras.losses.Loss Subclass\n",
    "\n",
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold*tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\":self.threshold}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\")\n",
    "model.fit(X_train, y_train, epochs=10, verbose=0)\n",
    "model.save(\"test_model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"test_model3.h5\", \n",
    "#                                    custom_objects={\"HuberLoss\", HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Activation Function, Initializer, Regularizer, and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights < 0, tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(30, activation=my_softplus, \n",
    "                              kernel_initializer=my_glorot_initializer, \n",
    "                              kernel_regularizer=my_l1_regularizer, \n",
    "                              kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom l1 regualrizer with subclassing\n",
    "\n",
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom  Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Metrics using SubClassing\n",
    "\n",
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layers with no weights\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "layer = layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dense layer with subclassing\n",
    "class MyDense(layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(name=\"kernel\", shape=[batch_input_shape[-1], self.units], \n",
    "                                      initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "    \n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units, \n",
    "                \"activation\": tf.keras.activations.get(self.activation)}\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layer with multiple inputs\n",
    "\n",
    "class MyMultiLayer(layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        return [X1 + X2, X1 * X2, X1 / X2]\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        b1, b2 = batch_input_shape\n",
    "        return [b1, b1, b1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layer with different behaivour while training\n",
    "class MyGaussianNoise(layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "    \n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        return X\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [layers.Dense(n_neurons, activation=\"elu\", \n",
    "                                    kernel_initializer=\"he_normal\") for _ in range(n_layers)]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom model\n",
    "class ResidualRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = layers.Dense(30, activation=\"elu\", \n",
    "                                   kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = layers.Dense(output_dim)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and Metrics Based on Model internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructionRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [layers.Dense(30, activation=\"selu\", \n",
    "                                    kernel_initializer=\"lecun_normal\") for _ in range(5)]\n",
    "        self.out = layers.Dense(output_dim)\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[:-1]\n",
    "        self.reconstruct = layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        return self.out(Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.expand_dims(3 * np.arange(0, 100) + np.random.randn(100), axis=1)\n",
    "y = np.arange(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = tf.keras.regularizers.l2(0.05)\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\", \n",
    "                 kernel_regularizer=l2_reg), \n",
    "    layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result()) for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.expand_dims(3 * np.arange(0, 1000) + 4, axis=1)\n",
    "y_train = np.arange(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4],\n",
       "        [ 7],\n",
       "        [10],\n",
       "        [13],\n",
       "        [16],\n",
       "        [19],\n",
       "        [22],\n",
       "        [25],\n",
       "        [28],\n",
       "        [31]]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10], y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "n_epochs = 20\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.mean_squared_error\n",
    "mean_loss = tf.keras.metrics.Mean()\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 - mean: 652224.5625 - mean_absolute_error: 390.40272\n",
      "Epoch 2/20\n",
      "1000/1000 - mean: 146244.1719 - mean_absolute_error: 123.4486\n",
      "Epoch 3/20\n",
      "1000/1000 - mean: 143371.0156 - mean_absolute_error: 120.3137\n",
      "Epoch 4/20\n",
      "1000/1000 - mean: 145454.6250 - mean_absolute_error: 124.0024\n",
      "Epoch 5/20\n",
      "1000/1000 - mean: 145320.7812 - mean_absolute_error: 123.1653\n",
      "Epoch 6/20\n",
      "1000/1000 - mean: 140095.8125 - mean_absolute_error: 120.6189\n",
      "Epoch 7/20\n",
      "1000/1000 - mean: 140602.5625 - mean_absolute_error: 119.2709\n",
      "Epoch 8/20\n",
      "1000/1000 - mean: 143449.7656 - mean_absolute_error: 120.5120\n",
      "Epoch 9/20\n",
      "1000/1000 - mean: 141065.4688 - mean_absolute_error: 118.8797\n",
      "Epoch 10/20\n",
      "1000/1000 - mean: 135523.9688 - mean_absolute_error: 113.4624\n",
      "Epoch 11/20\n",
      "1000/1000 - mean: 135005.6094 - mean_absolute_error: 113.3805\n",
      "Epoch 12/20\n",
      "1000/1000 - mean: 142380.9688 - mean_absolute_error: 117.3519\n",
      "Epoch 13/20\n",
      "1000/1000 - mean: 134118.3281 - mean_absolute_error: 113.9107\n",
      "Epoch 14/20\n",
      "1000/1000 - mean: 137253.5156 - mean_absolute_error: 115.2580\n",
      "Epoch 15/20\n",
      "1000/1000 - mean: 138937.7188 - mean_absolute_error: 122.7187\n",
      "Epoch 16/20\n",
      "1000/1000 - mean: 135149.9688 - mean_absolute_error: 114.4129\n",
      "Epoch 17/20\n",
      "1000/1000 - mean: 131934.9844 - mean_absolute_error: 117.9544\n",
      "Epoch 18/20\n",
      "1000/1000 - mean: 129218.5234 - mean_absolute_error: 111.0912\n",
      "Epoch 19/20\n",
      "1000/1000 - mean: 127589.7656 - mean_absolute_error: 113.4999\n",
      "Epoch 20/20\n",
      "1000/1000 - mean: 137636.0469 - mean_absolute_error: 121.4096\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        # Used When Using Kernel_constriants in layers while creating layer\n",
    "        # for variable in model.variables:\n",
    "        #   if variable.constraint is not None:\n",
    "        #       variable.assign(variable.constraint(variables))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Functions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube = lambda x: x**3\n",
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python function to tensorflow function\n",
    "tf_cube = tf.function(cube)\n",
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use tensorflow decorator for this\n",
    "@tf.function\n",
    "def tf_cube(x): return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting orginal python function from tensorflow function\n",
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tf__lam = (lambda x: ag__.with_function_scope((lambda lscope: (x ** 3)), 'lscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)))\\n\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.autograph.to_code(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "class MyLayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, epsilon=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        shape = input_shape[-1:]\n",
    "        self.alpha = self.add_weight(name=\"alpha\", initializer=\"ones\", \n",
    "                                     shape=shape, dtype=tf.float32)\n",
    "        self.beta = self.add_weight(name=\"beta\", initializer=\"zeros\", \n",
    "                                    shape=shape, dtype=tf.float32)\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, X, y=None, training=None):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        sd = tf.math.sqrt(variance)\n",
    "        return self.alpha * (X - mean)/(sd + self.epsilon) + self.beta\n",
    "    \n",
    "    def conpute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"epsilon\": self.epsilon}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=5)\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-5.1069832e-01, -5.7739085e-01, -9.4291204e-01, -4.5033672e-01,\n",
       "         -4.8785728e-01],\n",
       "        [ 9.8259677e-04, -7.8620315e-01,  8.7763184e-01, -4.4420934e-01,\n",
       "         -6.3795716e-01],\n",
       "        [-5.8136702e-01,  3.4705624e-01,  6.8357337e-01,  9.5518053e-01,\n",
       "         -1.7072307e+00],\n",
       "        [ 6.1355406e-01,  1.4041770e+00,  1.8225477e+00,  2.2782083e-01,\n",
       "         -4.1533902e-01],\n",
       "        [-5.3237361e-01, -9.5471901e-01, -6.1224246e-01, -8.7758839e-01,\n",
       "         -5.8460987e-01]], dtype=float32),\n",
       " array([-134.82821596,  -26.33945562,   44.05531636,  137.85072483,\n",
       "        -161.68674774]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.00046119821>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_norm_layer = MyLayerNormalization()\n",
    "keras_norm_layer = keras.layers.LayerNormalization()\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(custom_norm_layer(X), keras_norm_layer(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 97.4643\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 95.6691\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 92.0266\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 79.2323\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 53.8663\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 35.3591\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 26.0753\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 22.0763\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 19.4397\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 17.2413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af461e9c70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(10), \n",
    "    MyLayerNormalization(), \n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mae\", optimizer=\"sgd\")\n",
    "model.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 731us/step - loss: 96.8731\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 94.8426\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 89.8132\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 73.1531\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 913us/step - loss: 50.2599\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 33.2309\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 25.4041\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 21.8266\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 18.9184\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 16.5698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af472c5b80>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(10), \n",
    "    layers.LayerNormalization(), \n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mae\", optimizer=\"sgd\")\n",
    "model.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model Using Custom Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train, X_val, y_train, y_val = X_train[:50000], X_train[50000:], y_train[:50000], y_train[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, optimizers, Sequential, losses, metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)), \n",
    "    layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "], name=\"fashion_mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result()) for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(iteration, total) + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 32\n",
    "n_steps = len(X) // batch_size\n",
    "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
    "loss_fn = losses.sparse_categorical_crossentropy\n",
    "mean_loss = metrics.Mean()\n",
    "metrics = [metrics.Accuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000 - 50000mean: 39.6706 - accuracy: 0.4899\n",
      "Epoch 2/100\n",
      "50000 - 50000mean: 15.9651 - accuracy: 0.5978\n",
      "Epoch 3/100\n",
      "50000 - 50000mean: 10.7381 - accuracy: 0.6714\n",
      "Epoch 4/100\n",
      "50000 - 50000mean: 6.3557 - accuracy: 0.6986\n",
      "Epoch 5/100\n",
      "50000 - 50000mean: 4.8818 - accuracy: 0.6956\n",
      "Epoch 6/100\n",
      "50000 - 50000mean: 4.0036 - accuracy: 0.7006\n",
      "Epoch 7/100\n",
      "50000 - 50000mean: 3.4636 - accuracy: 0.7288\n",
      "Epoch 8/100\n",
      "50000 - 50000mean: 3.2233 - accuracy: 0.7157\n",
      "Epoch 9/100\n",
      "50000 - 50000mean: 3.0913 - accuracy: 0.6976\n",
      "Epoch 10/100\n",
      "50000 - 50000mean: 3.6358 - accuracy: 0.6593\n",
      "Epoch 11/100\n",
      "50000 - 50000mean: 2.0224 - accuracy: 0.7097\n",
      "Epoch 12/100\n",
      "50000 - 50000mean: 1.8251 - accuracy: 0.7026\n",
      "Epoch 13/100\n",
      "50000 - 50000mean: 2.0329 - accuracy: 0.7137\n",
      "Epoch 14/100\n",
      "50000 - 50000mean: 1.3845 - accuracy: 0.7228\n",
      "Epoch 15/100\n",
      "50000 - 50000mean: 1.5505 - accuracy: 0.6976\n",
      "Epoch 16/100\n",
      "50000 - 50000mean: 1.2465 - accuracy: 0.7157\n",
      "Epoch 17/100\n",
      "50000 - 50000mean: 1.3590 - accuracy: 0.7097\n",
      "Epoch 18/100\n",
      "50000 - 50000mean: 1.1329 - accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "50000 - 50000mean: 1.0080 - accuracy: 0.7581\n",
      "Epoch 20/100\n",
      "50000 - 50000mean: 1.0940 - accuracy: 0.7550\n",
      "Epoch 21/100\n",
      "50000 - 50000mean: 1.1495 - accuracy: 0.7127\n",
      "Epoch 22/100\n",
      "50000 - 50000mean: 1.1885 - accuracy: 0.7278\n",
      "Epoch 23/100\n",
      "50000 - 50000mean: 1.1400 - accuracy: 0.6976\n",
      "Epoch 24/100\n",
      "50000 - 50000mean: 0.9965 - accuracy: 0.7147\n",
      "Epoch 25/100\n",
      "50000 - 50000mean: 0.8727 - accuracy: 0.7389\n",
      "Epoch 26/100\n",
      "50000 - 50000mean: 0.9598 - accuracy: 0.7198\n",
      "Epoch 27/100\n",
      "50000 - 50000mean: 0.8875 - accuracy: 0.7188\n",
      "Epoch 28/100\n",
      "50000 - 50000mean: 0.7690 - accuracy: 0.7762\n",
      "Epoch 29/100\n",
      "50000 - 50000mean: 0.8124 - accuracy: 0.7641\n",
      "Epoch 30/100\n",
      "50000 - 50000mean: 0.7916 - accuracy: 0.7843\n",
      "Epoch 31/100\n",
      "50000 - 50000mean: 0.8301 - accuracy: 0.7651\n",
      "Epoch 32/100\n",
      "50000 - 50000mean: 0.7576 - accuracy: 0.7843\n",
      "Epoch 33/100\n",
      "50000 - 50000mean: 0.8738 - accuracy: 0.7429\n",
      "Epoch 34/100\n",
      "50000 - 50000mean: 0.7572 - accuracy: 0.7540\n",
      "Epoch 35/100\n",
      "50000 - 50000mean: 0.6490 - accuracy: 0.7893\n",
      "Epoch 36/100\n",
      "50000 - 50000mean: 0.7271 - accuracy: 0.7853\n",
      "Epoch 37/100\n",
      "50000 - 50000mean: 0.7070 - accuracy: 0.7681\n",
      "Epoch 38/100\n",
      "50000 - 50000mean: 0.6549 - accuracy: 0.7873\n",
      "Epoch 39/100\n",
      "50000 - 50000mean: 0.7748 - accuracy: 0.7702\n",
      "Epoch 40/100\n",
      "50000 - 50000mean: 0.7343 - accuracy: 0.7611\n",
      "Epoch 41/100\n",
      "50000 - 50000mean: 0.6912 - accuracy: 0.7631\n",
      "Epoch 42/100\n",
      "50000 - 50000mean: 0.6654 - accuracy: 0.7903\n",
      "Epoch 43/100\n",
      "50000 - 50000mean: 0.6620 - accuracy: 0.8024\n",
      "Epoch 44/100\n",
      "50000 - 50000mean: 0.6819 - accuracy: 0.7863\n",
      "Epoch 45/100\n",
      "50000 - 50000mean: 0.7450 - accuracy: 0.7853\n",
      "Epoch 46/100\n",
      "50000 - 50000mean: 0.6927 - accuracy: 0.7742\n",
      "Epoch 47/100\n",
      "50000 - 50000mean: 0.6113 - accuracy: 0.7833\n",
      "Epoch 48/100\n",
      "50000 - 50000mean: 0.6036 - accuracy: 0.7923\n",
      "Epoch 49/100\n",
      "50000 - 50000mean: 0.7214 - accuracy: 0.7510\n",
      "Epoch 50/100\n",
      "50000 - 50000mean: 0.6850 - accuracy: 0.7681\n",
      "Epoch 51/100\n",
      "50000 - 50000mean: 0.6050 - accuracy: 0.7883\n",
      "Epoch 52/100\n",
      "50000 - 50000mean: 0.6010 - accuracy: 0.7893\n",
      "Epoch 53/100\n",
      "50000 - 50000mean: 0.6673 - accuracy: 0.7923\n",
      "Epoch 54/100\n",
      "50000 - 50000mean: 0.5867 - accuracy: 0.8044\n",
      "Epoch 55/100\n",
      "50000 - 50000mean: 0.6301 - accuracy: 0.7944\n",
      "Epoch 56/100\n",
      "50000 - 50000mean: 0.5924 - accuracy: 0.7964\n",
      "Epoch 57/100\n",
      "50000 - 50000mean: 0.7165 - accuracy: 0.7621\n",
      "Epoch 58/100\n",
      "50000 - 50000mean: 0.5953 - accuracy: 0.7974\n",
      "Epoch 59/100\n",
      "50000 - 50000mean: 0.7607 - accuracy: 0.7671\n",
      "Epoch 60/100\n",
      "50000 - 50000mean: 0.5418 - accuracy: 0.8125\n",
      "Epoch 61/100\n",
      "50000 - 50000mean: 0.6158 - accuracy: 0.7843\n",
      "Epoch 62/100\n",
      "50000 - 50000mean: 0.5291 - accuracy: 0.8185\n",
      "Epoch 63/100\n",
      "50000 - 50000mean: 0.6222 - accuracy: 0.7893\n",
      "Epoch 64/100\n",
      "50000 - 50000mean: 0.6067 - accuracy: 0.7893\n",
      "Epoch 65/100\n",
      "50000 - 50000mean: 0.6090 - accuracy: 0.8115\n",
      "Epoch 66/100\n",
      "50000 - 50000mean: 0.6232 - accuracy: 0.7974\n",
      "Epoch 67/100\n",
      "50000 - 50000mean: 0.6995 - accuracy: 0.7903\n",
      "Epoch 68/100\n",
      "50000 - 50000mean: 0.6439 - accuracy: 0.7833\n",
      "Epoch 69/100\n",
      "50000 - 50000mean: 0.6329 - accuracy: 0.7893\n",
      "Epoch 70/100\n",
      "50000 - 50000mean: 0.6820 - accuracy: 0.7732\n",
      "Epoch 71/100\n",
      "50000 - 50000mean: 0.6414 - accuracy: 0.8034\n",
      "Epoch 72/100\n",
      "50000 - 50000mean: 0.5895 - accuracy: 0.8044\n",
      "Epoch 73/100\n",
      "50000 - 50000mean: 0.6472 - accuracy: 0.7752\n",
      "Epoch 74/100\n",
      "50000 - 50000mean: 0.7276 - accuracy: 0.7591\n",
      "Epoch 75/100\n",
      "50000 - 50000mean: 0.6260 - accuracy: 0.7944\n",
      "Epoch 76/100\n",
      "50000 - 50000mean: 0.6758 - accuracy: 0.7702\n",
      "Epoch 77/100\n",
      "50000 - 50000mean: 0.6367 - accuracy: 0.7913\n",
      "Epoch 78/100\n",
      "50000 - 50000mean: 0.7499 - accuracy: 0.7298\n",
      "Epoch 79/100\n",
      "50000 - 50000mean: 0.8354 - accuracy: 0.7288\n",
      "Epoch 80/100\n",
      "50000 - 50000mean: 0.6514 - accuracy: 0.7873\n",
      "Epoch 81/100\n",
      "50000 - 50000mean: 0.6428 - accuracy: 0.7702\n",
      "Epoch 82/100\n",
      "50000 - 50000mean: 0.6163 - accuracy: 0.8004\n",
      "Epoch 83/100\n",
      "50000 - 50000mean: 0.6753 - accuracy: 0.7681\n",
      "Epoch 84/100\n",
      "50000 - 50000mean: 0.5728 - accuracy: 0.8115\n",
      "Epoch 85/100\n",
      "50000 - 50000mean: 0.6297 - accuracy: 0.7984\n",
      "Epoch 86/100\n",
      "50000 - 50000mean: 0.6797 - accuracy: 0.7903\n",
      "Epoch 87/100\n",
      "50000 - 50000mean: 0.6086 - accuracy: 0.7863\n",
      "Epoch 88/100\n",
      "50000 - 50000mean: 0.5550 - accuracy: 0.8034\n",
      "Epoch 89/100\n",
      "50000 - 50000mean: 0.6028 - accuracy: 0.7933\n",
      "Epoch 90/100\n",
      "50000 - 50000mean: 0.6796 - accuracy: 0.7873\n",
      "Epoch 91/100\n",
      "50000 - 50000mean: 0.6250 - accuracy: 0.7853\n",
      "Epoch 92/100\n",
      "50000 - 50000mean: 0.6384 - accuracy: 0.7873\n",
      "Epoch 93/100\n",
      "50000 - 50000mean: 0.6222 - accuracy: 0.7631\n",
      "Epoch 94/100\n",
      "50000 - 50000mean: 0.5747 - accuracy: 0.8095\n",
      "Epoch 95/100\n",
      "50000 - 50000mean: 0.6895 - accuracy: 0.7651\n",
      "Epoch 96/100\n",
      "50000 - 50000mean: 0.5401 - accuracy: 0.7903\n",
      "Epoch 97/100\n",
      "50000 - 50000mean: 0.6066 - accuracy: 0.7944\n",
      "Epoch 98/100\n",
      "50000 - 50000mean: 0.6109 - accuracy: 0.7994\n",
      "Epoch 99/100\n",
      "50000 - 50000mean: 0.6204 - accuracy: 0.7853\n",
      "Epoch 100/100\n",
      "50000 - 50000mean: 0.6319 - accuracy: 0.8034\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps+1):\n",
    "        X_batch, y_batch = random_batch(X_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, tf.argmax(y_pred, axis=1))\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 8, 5, 5, 5], dtype=int64)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4897 - accuracy: 0.8247 - val_loss: 0.4302 - val_accuracy: 0.8430\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3931 - accuracy: 0.8559 - val_loss: 0.3816 - val_accuracy: 0.8683\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3646 - accuracy: 0.8650 - val_loss: 0.4724 - val_accuracy: 0.8619\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3380 - accuracy: 0.8752 - val_loss: 0.4959 - val_accuracy: 0.8720\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3184 - accuracy: 0.8818 - val_loss: 0.6493 - val_accuracy: 0.8757\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3016 - accuracy: 0.8885 - val_loss: 0.5066 - val_accuracy: 0.8644\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2863 - accuracy: 0.8920 - val_loss: 0.4828 - val_accuracy: 0.8733\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2799 - accuracy: 0.8952 - val_loss: 0.4527 - val_accuracy: 0.8751\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2720 - accuracy: 0.8982 - val_loss: 0.4674 - val_accuracy: 0.8695\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2601 - accuracy: 0.9020 - val_loss: 0.3637 - val_accuracy: 0.8824\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2543 - accuracy: 0.9044 - val_loss: 0.3973 - val_accuracy: 0.8819\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2513 - accuracy: 0.9065 - val_loss: 0.4351 - val_accuracy: 0.8853\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2451 - accuracy: 0.9066 - val_loss: 0.4293 - val_accuracy: 0.8839\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2395 - accuracy: 0.9100 - val_loss: 0.4919 - val_accuracy: 0.8657\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2277 - accuracy: 0.9149 - val_loss: 0.4403 - val_accuracy: 0.8825\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2226 - accuracy: 0.9156 - val_loss: 0.4965 - val_accuracy: 0.8774\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2185 - accuracy: 0.9175 - val_loss: 0.4521 - val_accuracy: 0.8793\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2113 - accuracy: 0.9192 - val_loss: 0.4154 - val_accuracy: 0.8847\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2081 - accuracy: 0.9214 - val_loss: 0.3939 - val_accuracy: 0.8789\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2056 - accuracy: 0.9214 - val_loss: 0.5175 - val_accuracy: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af4bfa8fa0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)), \n",
    "    layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "], name=\"fashion_mnist_model_2\")\n",
    "model_2.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"adam\", \n",
    "                metrics=[\"accuracy\"])\n",
    "model_2.fit(X_train, y_train, epochs=100, \n",
    "            validation_data=(X_val, y_val), \n",
    "            callbacks=[keras.callbacks.EarlyStopping(patience=10, \n",
    "                                                     monitor=\"val_loss\",\n",
    "                                                     restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81727fb6587a0e5418c3cf386f53a5fb924b641d49e181fa8e28403b9a38d60e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
