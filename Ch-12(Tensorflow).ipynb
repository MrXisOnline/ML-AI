{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8-ZjiwPDZbw"
      },
      "source": [
        "## Using Tensorflow like Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i65n3tpDZby"
      },
      "source": [
        "### Tensors and Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8la60jMCDZby"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74itK4FADZby",
        "outputId": "ce06cff2-51e6-44fc-f4fa-0790212c8269"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [4, 5, 5]])>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.constant([[1, 2, 3], [4, 5, 5]]) # matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCRJ_exXDZbz",
        "outputId": "f93508b5-8c32-4df1-b6bd-c00a63fcdb7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=40>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.constant(40) # scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-7q4XliDZb0",
        "outputId": "1ee0f76a-e079-44a4-c7c6-a7da3f85691a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([2, 3]), tf.float32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "t.shape, t.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwbP_1azDZb0",
        "outputId": "de6bbbf6-51f7-4d85-f51e-e40a51cf642d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[2., 3.],\n",
              "       [5., 6.]], dtype=float32)>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqpAohvADZb0",
        "outputId": "03e082ee-7c1b-4aff-8b82-6ebe7751bdbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              "array([[2.],\n",
              "       [5.]], dtype=float32)>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[..., 1, tf.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqT8vBbUDZb1",
        "outputId": "8024d803-d78a-4384-ae74-ea13853f440b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[11., 12., 13.],\n",
              "       [14., 15., 16.]], dtype=float32)>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkhK6yfADZb1",
        "outputId": "527ca522-39fd-4147-811b-a35d04f850ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[ 1.,  4.,  9.],\n",
              "       [16., 25., 36.]], dtype=float32)>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.square(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37sNufzjDZb1",
        "outputId": "11e7bb4f-59bd-4f29-9528-ad3ed6536a00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[14., 32.],\n",
              "       [32., 77.]], dtype=float32)>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t @ tf.transpose(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbXhcJECDZb1"
      },
      "source": [
        "#### Keras's Low Level API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDdImGJMDZb2",
        "outputId": "63e9c14f-ca30-4eb5-be38-e52097a6ec6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[11., 26.],\n",
              "       [14., 35.],\n",
              "       [19., 46.]], dtype=float32)>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "K = tf.keras.backend\n",
        "K.square(K.transpose(t)) + 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LlHoQqMDZb2"
      },
      "source": [
        "### Tensors And NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OUxdQZWDZb2",
        "outputId": "f2e30dfa-b3ba-4d35-ccd1-7fda90a398f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = np.array([2., 4., 5.])\n",
        "tf.constant(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVi36a5vDZb3",
        "outputId": "18c45735-fc3b-4eea-eec1-c9c61b4b1a1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5h_CEmTDZb3",
        "outputId": "b50d7b65-b258-4204-b046-847a1263aa39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.square(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5HX7YUyDZb3",
        "outputId": "88f9f087-846f-4992-bdc4-d42d12c60d44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.,  4.,  9.],\n",
              "       [16., 25., 36.]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.square(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqWKKmQdDZb3",
        "outputId": "b290a500-262b-4c04-f929-419393cc2b13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Type Conversion\n",
        "\n",
        "# tf.constant(2.) + tf.constant(40) # Gives Error\n",
        "# tf.constant(2.) + tf.constant(40., dtype=tf.float64) # Also Give Error\n",
        "tf.constant(2.0) + tf.cast(tf.constant(40.), dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O8i-ODtDZb4"
      },
      "source": [
        "### Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r90J-s9DZb4",
        "outputId": "12e92d48-fc5f-43d9-c2b8-5961e03e1deb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensors can't be changed so we use something called\n",
        "\n",
        "v = tf.Variable([[1., 2., 3.], [4. ,5., 6.]])\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45KMtF1SDZb4",
        "outputId": "ea06883b-4910-45fd-fe3c-080a4ee40e1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2.,  4.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Modifying Tensors\n",
        "\n",
        "v.assign(2 * v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_hqsqj0DZb5",
        "outputId": "13b490e1-773b-4587-e555-ac014b0ee5d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[100.,   4.,   6.],\n",
              "       [  8.,  10., 200.]], dtype=float32)>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy0b5o5gDZb5"
      },
      "source": [
        "### Other Data Structures\n",
        "* Sparse tensors(tf.SparseTensor) -> efficiently represent tensors using mostly zeroes.\n",
        "* Tensor Array(tf.TensorArray) -> lists of tensors. all have same shape and same type. Could Be Dynamic\n",
        "* Ragged Tensor(tf.RaggedTensor) -> same as Tensor Array but Static\n",
        "* String Tensor(tf.string) -> they represent byte strings. can be converted into Unicode\n",
        "* Sets(tf.sets) -> can be represented by regular tensor or sparse tensor\n",
        "* Queues (tf.queue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4KwgQDJDZb5"
      },
      "source": [
        "## Customizing Models and Training Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwhHG7ezDZb5"
      },
      "source": [
        "### Custom Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uaY-WNHDZb5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < 1\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = tf.abs(error) * 0.5\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBifUabrDZb6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X_train = np.arange(0, 100) * 3 + 2\n",
        "X_train = X_train.reshape((100, 1)).astype(dtype=np.float32)\n",
        "y_train = np.arange(0, 100, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzMAt8JgDZb6",
        "outputId": "b8227783-bbd8-43bc-9ea6-97286be197d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2e2a10dd4c0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.Sequential([tf.keras.layers.Dense(10, activation=\"relu\"), \n",
        "                             tf.keras.layers.Dense(1)])\n",
        "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqTSeHN_DZb6"
      },
      "outputs": [],
      "source": [
        "model.save(\"test_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVTlNverDZb6"
      },
      "source": [
        "### Saving and Loading Models That Contain Custom Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5MkjYNaDZb6"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"test_model.h5\", \n",
        "                                   custom_objects={\"huber_fn\": huber_fn})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG9rZ85bDZb7"
      },
      "outputs": [],
      "source": [
        "# custom loss function with some different threshold\n",
        "\n",
        "def create_huber(threshold=1.0):\n",
        "    def huber_fn(y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "    return huber_fn\n",
        "\n",
        "model.compile(loss=create_huber(2.0), optimizer=\"nadam\")\n",
        "model.fit(X_train, y_train, epochs=10, verbose=0)\n",
        "model.save(\"test_model2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09j1WPbMDZb7"
      },
      "outputs": [],
      "source": [
        "# load model of custom threshold loss\n",
        "model = tf.keras.models.load_model(\"test_model2.h5\", \n",
        "                                   custom_objects={\"huber_fn\": create_huber(2.0)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOD3j9zwDZb7"
      },
      "outputs": [],
      "source": [
        "# Creating Loss function with keras.losses.Loss Subclass\n",
        "\n",
        "class HuberLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        self.threshold = threshold\n",
        "        super().__init__(**kwargs)\n",
        "    def call(self, y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < self.threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = self.threshold*tf.abs(error) - self.threshold**2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\":self.threshold}\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-1K4mPFDZb7"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\")\n",
        "model.fit(X_train, y_train, epochs=10, verbose=0)\n",
        "model.save(\"test_model3.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wq_mMmpDZb8"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.models.load_model(\"test_model3.h5\", \n",
        "#                                    custom_objects={\"HuberLoss\", HuberLoss})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO8KeAIgDZb8"
      },
      "source": [
        "### Custom Activation Function, Initializer, Regularizer, and Constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BLsW7oUDZb8"
      },
      "outputs": [],
      "source": [
        "def my_softplus(z):\n",
        "    return tf.math.log(tf.exp(z) + 1.0)\n",
        "\n",
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "def my_l1_regularizer(weights):\n",
        "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "\n",
        "def my_positive_weights(weights):\n",
        "    return tf.where(weights < 0, tf.zeros_like(weights), weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mcp9ZRHiDZb8"
      },
      "outputs": [],
      "source": [
        "layer = tf.keras.layers.Dense(30, activation=my_softplus, \n",
        "                              kernel_initializer=my_glorot_initializer, \n",
        "                              kernel_regularizer=my_l1_regularizer, \n",
        "                              kernel_constraint=my_positive_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBQhaSurDZb8"
      },
      "outputs": [],
      "source": [
        "# custom l1 regualrizer with subclassing\n",
        "\n",
        "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "    def __call__(self, weights):\n",
        "        return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "    def get_config(self):\n",
        "        return {\"factor\": self.factor}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29mZc4sqDZb8"
      },
      "source": [
        "### Custom  Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkNH86JWDZb9"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5itMeN_wDZb9",
        "outputId": "7b8e0165-61bb-411d-d4ce-6e640a9c048c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision = tf.keras.metrics.Precision()\n",
        "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eylCOIaDZb9",
        "outputId": "74cf3e39-4f94-44f5-aa7b-f3caef1b04dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpLqi5RsDZb9",
        "outputId": "e99a24ab-f0e6-4a24-afdc-bd1ba79f2ebe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5XZ1HuQDZb9",
        "outputId": "e4a3e6b5-033d-4aaf-d6bc-1a1a808ea670"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
              " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7dSUFHtDZb9"
      },
      "outputs": [],
      "source": [
        "precision.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYSVk1dMDZb9"
      },
      "outputs": [],
      "source": [
        "# Custom Metrics using SubClassing\n",
        "\n",
        "class HuberMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = create_huber(threshold)\n",
        "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        metric = self.huber_fn(y_true, y_pred)\n",
        "        self.total.assign_add(tf.reduce_sum(metric))\n",
        "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "    def result(self):\n",
        "        return self.total / self.count\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL9i2enfDZb-"
      },
      "source": [
        "### Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JPdfrsFUDZb-"
      },
      "outputs": [],
      "source": [
        "# custom layers with no weights\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "layer = layers.Lambda(lambda x: tf.exp(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zrCK7L2DZb-"
      },
      "outputs": [],
      "source": [
        "# custom dense layer with subclassing\n",
        "class MyDense(layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "        \n",
        "    def build(self, batch_input_shape):\n",
        "        self.kernel = self.add_weight(name=\"kernel\", shape=[batch_input_shape[-1], self.units], \n",
        "                                      initializer=\"glorot_normal\")\n",
        "        self.bias = self.add_weight(name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
        "        super().build(batch_input_shape)\n",
        "    \n",
        "    def call(self, X):\n",
        "        return self.activation(X @ self.kernel + self.bias)\n",
        "    \n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
        "    \n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"units\": self.units, \n",
        "                \"activation\": tf.keras.activations.get(self.activation)}\n",
        "    \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXDkbvRVDZb-"
      },
      "outputs": [],
      "source": [
        "# custom layer with multiple inputs\n",
        "\n",
        "class MyMultiLayer(layers.Layer):\n",
        "    def call(self, X):\n",
        "        X1, X2 = X\n",
        "        return [X1 + X2, X1 * X2, X1 / X2]\n",
        "    \n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        b1, b2 = batch_input_shape\n",
        "        return [b1, b1, b1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl6SE46cDZb-"
      },
      "outputs": [],
      "source": [
        "# custom layer with different behaivour while training\n",
        "class MyGaussianNoise(layers.Layer):\n",
        "    def __init__(self, stddev, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.stddev = stddev\n",
        "    \n",
        "    def call(self, X, training=None):\n",
        "        if training:\n",
        "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
        "            return X + noise\n",
        "        return X\n",
        "    \n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        return batch_input_shape\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stuCddGSDZb_"
      },
      "source": [
        "### Custom Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vW9Ejkt6DZb_"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(layers.Layer):\n",
        "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [layers.Dense(n_neurons, activation=\"elu\", \n",
        "                                    kernel_initializer=\"he_normal\") \n",
        "        for _ in range(n_layers)]\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        return inputs + Z\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-1o1lMbDZb_"
      },
      "outputs": [],
      "source": [
        "# custom model\n",
        "class ResidualRegressor(tf.keras.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = layers.Dense(30, activation=\"elu\", \n",
        "                                   kernel_initializer=\"he_normal\")\n",
        "        self.block1 = ResidualBlock(2, 30)\n",
        "        self.block2 = ResidualBlock(2, 30)\n",
        "        self.out = layers.Dense(output_dim)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        Z = self.hidden1(inputs)\n",
        "        for _ in range(1 + 3):\n",
        "            Z = self.block1(Z)\n",
        "        Z = self.block2(Z)\n",
        "        return self.out(Z)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcch3wDpDZb_"
      },
      "source": [
        "### Losses and Metrics Based on Model internals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5d8WbFODZb_"
      },
      "outputs": [],
      "source": [
        "class ReconstructionRegressor(tf.keras.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [layers.Dense(30, activation=\"selu\", \n",
        "                                    kernel_initializer=\"lecun_normal\") for _ in range(5)]\n",
        "        self.out = layers.Dense(output_dim)\n",
        "    \n",
        "    def build(self, batch_input_shape):\n",
        "        n_inputs = batch_input_shape[:-1]\n",
        "        self.reconstruct = layers.Dense(n_inputs)\n",
        "        super().build(batch_input_shape)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        reconstruction = self.reconstruct(Z)\n",
        "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
        "        self.add_loss(0.05 * recon_loss)\n",
        "        return self.out(Z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJo360bADZcA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X = np.expand_dims(3 * np.arange(0, 100) + np.random.randn(100), axis=1)\n",
        "y = np.arange(0, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dNFUp28DZcA"
      },
      "source": [
        "### Custom Training Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVX5oULMDZcA"
      },
      "outputs": [],
      "source": [
        "l2_reg = tf.keras.regularizers.l2(0.05)\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\", \n",
        "                 kernel_regularizer=l2_reg), \n",
        "    layers.Dense(1, kernel_regularizer=l2_reg)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S6ucIO_DZcA"
      },
      "outputs": [],
      "source": [
        "def random_batch(X, y, batch_size=32):\n",
        "    idx = np.random.randint(len(X), size=batch_size)\n",
        "    return X[idx], y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0kKKVZgDZcA"
      },
      "outputs": [],
      "source": [
        "def print_status_bar(iteration, total, loss, metrics=None):\n",
        "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result()) for m in [loss] + (metrics or [])])\n",
        "    end = \"\" if iteration < total else \"\\n\"\n",
        "    print(\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvbcrp1CDZcB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.expand_dims(3 * np.arange(0, 1000) + 4, axis=1)\n",
        "y_train = np.arange(0, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PnLWyxRDZcB",
        "outputId": "35100788-55bc-4b8e-d275-e589ea117b46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 4],\n",
              "        [ 7],\n",
              "        [10],\n",
              "        [13],\n",
              "        [16],\n",
              "        [19],\n",
              "        [22],\n",
              "        [25],\n",
              "        [28],\n",
              "        [31]]),\n",
              " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[:10], y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWaa-c0MDZcB"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "n_epochs = 20\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // batch_size\n",
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
        "loss_fn = tf.keras.losses.mean_squared_error\n",
        "mean_loss = tf.keras.metrics.Mean()\n",
        "metrics = [tf.keras.metrics.MeanAbsoluteError()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51AZkF75DZcB",
        "outputId": "210b9ecd-dce0-4a65-87d7-d088ac96c7b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 - mean: 652224.5625 - mean_absolute_error: 390.40272\n",
            "Epoch 2/20\n",
            "1000/1000 - mean: 146244.1719 - mean_absolute_error: 123.4486\n",
            "Epoch 3/20\n",
            "1000/1000 - mean: 143371.0156 - mean_absolute_error: 120.3137\n",
            "Epoch 4/20\n",
            "1000/1000 - mean: 145454.6250 - mean_absolute_error: 124.0024\n",
            "Epoch 5/20\n",
            "1000/1000 - mean: 145320.7812 - mean_absolute_error: 123.1653\n",
            "Epoch 6/20\n",
            "1000/1000 - mean: 140095.8125 - mean_absolute_error: 120.6189\n",
            "Epoch 7/20\n",
            "1000/1000 - mean: 140602.5625 - mean_absolute_error: 119.2709\n",
            "Epoch 8/20\n",
            "1000/1000 - mean: 143449.7656 - mean_absolute_error: 120.5120\n",
            "Epoch 9/20\n",
            "1000/1000 - mean: 141065.4688 - mean_absolute_error: 118.8797\n",
            "Epoch 10/20\n",
            "1000/1000 - mean: 135523.9688 - mean_absolute_error: 113.4624\n",
            "Epoch 11/20\n",
            "1000/1000 - mean: 135005.6094 - mean_absolute_error: 113.3805\n",
            "Epoch 12/20\n",
            "1000/1000 - mean: 142380.9688 - mean_absolute_error: 117.3519\n",
            "Epoch 13/20\n",
            "1000/1000 - mean: 134118.3281 - mean_absolute_error: 113.9107\n",
            "Epoch 14/20\n",
            "1000/1000 - mean: 137253.5156 - mean_absolute_error: 115.2580\n",
            "Epoch 15/20\n",
            "1000/1000 - mean: 138937.7188 - mean_absolute_error: 122.7187\n",
            "Epoch 16/20\n",
            "1000/1000 - mean: 135149.9688 - mean_absolute_error: 114.4129\n",
            "Epoch 17/20\n",
            "1000/1000 - mean: 131934.9844 - mean_absolute_error: 117.9544\n",
            "Epoch 18/20\n",
            "1000/1000 - mean: 129218.5234 - mean_absolute_error: 111.0912\n",
            "Epoch 19/20\n",
            "1000/1000 - mean: 127589.7656 - mean_absolute_error: 113.4999\n",
            "Epoch 20/20\n",
            "1000/1000 - mean: 137636.0469 - mean_absolute_error: 121.4096\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
        "    for step in range(1, n_steps + 1):\n",
        "        X_batch, y_batch = random_batch(X_train, y_train)\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_batch, training=True)\n",
        "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "            loss = tf.add_n([main_loss] + model.losses)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        # Used When Using Kernel_constriants in layers while creating layer\n",
        "        # for variable in model.variables:\n",
        "        #   if variable.constraint is not None:\n",
        "        #       variable.assign(variable.constraint(variables))\n",
        "        mean_loss(loss)\n",
        "        for metric in metrics:\n",
        "            metric(y_batch, y_pred)\n",
        "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
        "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
        "    for metric in [mean_loss] + metrics:\n",
        "        metric.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozojXWNYDZcB"
      },
      "source": [
        "## Tensorflow Functions and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqPbA7T5DZcB",
        "outputId": "39e047ad-896f-4e7c-f355-6c33361da224"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cube = lambda x: x**3\n",
        "cube(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8L56ueIDZcC",
        "outputId": "768d449c-3686-4706-b523-61931426286f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cube(tf.constant(2.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prUMlEw-DZcC",
        "outputId": "1060ceb2-f880-417d-998e-b4e59163af8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# python function to tensorflow function\n",
        "tf_cube = tf.function(cube)\n",
        "tf_cube(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlnXjUgkDZcC"
      },
      "outputs": [],
      "source": [
        "# we can also use tensorflow decorator for this\n",
        "@tf.function\n",
        "def tf_cube(x): return x**3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCenykzmDZcC",
        "outputId": "1c61ccb7-5071-4e2a-8380-0573e938763a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# getting orginal python function from tensorflow function\n",
        "tf_cube.python_function(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-d6l8F8DZcC",
        "outputId": "bb31dc5f-57af-4c87-e438-a20ff54b605c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"tf__lam = (lambda x: ag__.with_function_scope((lambda lscope: (x ** 3)), 'lscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)))\\n\""
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.autograph.to_code(cube)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38DC8cvVDZcC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYShD-WpDZcC"
      },
      "source": [
        "## Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BipE0k2PDZcD"
      },
      "source": [
        "### Custom Layer Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dWTd8Z-DZcD"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "class MyLayerNormalization(keras.layers.Layer):\n",
        "    def __init__(self, epsilon=0.001, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.epsilon = epsilon\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        shape = input_shape[-1:]\n",
        "        self.alpha = self.add_weight(name=\"alpha\", initializer=\"ones\", \n",
        "                                     shape=shape, dtype=tf.float32)\n",
        "        self.beta = self.add_weight(name=\"beta\", initializer=\"zeros\", \n",
        "                                    shape=shape, dtype=tf.float32)\n",
        "        super().build(input_shape)\n",
        "        \n",
        "    def call(self, X, y=None, training=None):\n",
        "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
        "        sd = tf.math.sqrt(variance)\n",
        "        return self.alpha * (X - mean)/(sd + self.epsilon) + self.beta\n",
        "    \n",
        "    def conpute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "    \n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"epsilon\": self.epsilon}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glmyq09bDZcD"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.datasets import make_regression\n",
        "import numpy as np\n",
        "\n",
        "X, y = make_regression(n_samples=1000, n_features=5)\n",
        "X = X.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtvtDNPUDZcD",
        "outputId": "0ced2f9b-3a81-41aa-f8a4-0cde60d416a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-5.1069832e-01, -5.7739085e-01, -9.4291204e-01, -4.5033672e-01,\n",
              "         -4.8785728e-01],\n",
              "        [ 9.8259677e-04, -7.8620315e-01,  8.7763184e-01, -4.4420934e-01,\n",
              "         -6.3795716e-01],\n",
              "        [-5.8136702e-01,  3.4705624e-01,  6.8357337e-01,  9.5518053e-01,\n",
              "         -1.7072307e+00],\n",
              "        [ 6.1355406e-01,  1.4041770e+00,  1.8225477e+00,  2.2782083e-01,\n",
              "         -4.1533902e-01],\n",
              "        [-5.3237361e-01, -9.5471901e-01, -6.1224246e-01, -8.7758839e-01,\n",
              "         -5.8460987e-01]], dtype=float32),\n",
              " array([-134.82821596,  -26.33945562,   44.05531636,  137.85072483,\n",
              "        -161.68674774]))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[:5], y[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MSyjP5BDZcD",
        "outputId": "2475cc74-668b-4f29-a1f3-562e1d890f3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.00046119821>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_norm_layer = MyLayerNormalization()\n",
        "keras_norm_layer = keras.layers.LayerNormalization()\n",
        "tf.reduce_mean(keras.losses.mean_absolute_error(custom_norm_layer(X), keras_norm_layer(X)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVKwee9eDZcD",
        "outputId": "917d7e4f-f624-4b8d-b8c2-a877b0b9ef28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 97.4643\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 95.6691\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 92.0266\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 79.2323\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 53.8663\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 35.3591\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 26.0753\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 22.0763\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 19.4397\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 17.2413\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2af461e9c70>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(10), \n",
        "    MyLayerNormalization(), \n",
        "    layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mae\", optimizer=\"sgd\")\n",
        "model.fit(X, y, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybw1OiGxDZcE",
        "outputId": "a6e2b95c-a44c-4095-daa3-0f7be6946b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 731us/step - loss: 96.8731\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 94.8426\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 89.8132\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 73.1531\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 913us/step - loss: 50.2599\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 33.2309\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 25.4041\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 21.8266\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 18.9184\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 16.5698\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2af472c5b80>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(10), \n",
        "    layers.LayerNormalization(), \n",
        "    layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mae\", optimizer=\"sgd\")\n",
        "model.fit(X, y, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APSHu_PkDZcE"
      },
      "source": [
        "### Train Model Using Custom Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1XTtTObDZcE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train, X_val, y_train, y_val = X_train[:50000], X_train[50000:], y_train[:50000], y_train[50000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6uPx76mDZcE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, optimizers, Sequential, losses, metrics\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3frjo1yhDZcE"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq7A8gFQDZcE"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)), \n",
        "    layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    layers.BatchNormalization(), \n",
        "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    layers.BatchNormalization(), \n",
        "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    layers.BatchNormalization(), \n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "], name=\"fashion_mnist_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCIbVeKSDZcE"
      },
      "outputs": [],
      "source": [
        "def random_batch(X, y, batch_size=32):\n",
        "    idx = np.random.randint(len(X), size=batch_size)\n",
        "    return X[idx], y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNzC1cqEDZcF"
      },
      "outputs": [],
      "source": [
        "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
        "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result()) for m in [loss] + (metrics or [])])\n",
        "    end = \"\" if iteration < total else \"\\n\"\n",
        "    print(\"\\r{} - {}\".format(iteration, total) + metrics, end=end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0rRsOYMDZcF"
      },
      "outputs": [],
      "source": [
        "n_epochs = 100\n",
        "batch_size = 32\n",
        "n_steps = len(X) // batch_size\n",
        "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
        "loss_fn = losses.sparse_categorical_crossentropy\n",
        "mean_loss = metrics.Mean()\n",
        "metrics = [metrics.Accuracy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLlVd3V3DZcF",
        "outputId": "eab33f91-bd63-496b-87f8-e597b61be323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50000 - 50000mean: 39.6706 - accuracy: 0.4899\n",
            "Epoch 2/100\n",
            "50000 - 50000mean: 15.9651 - accuracy: 0.5978\n",
            "Epoch 3/100\n",
            "50000 - 50000mean: 10.7381 - accuracy: 0.6714\n",
            "Epoch 4/100\n",
            "50000 - 50000mean: 6.3557 - accuracy: 0.6986\n",
            "Epoch 5/100\n",
            "50000 - 50000mean: 4.8818 - accuracy: 0.6956\n",
            "Epoch 6/100\n",
            "50000 - 50000mean: 4.0036 - accuracy: 0.7006\n",
            "Epoch 7/100\n",
            "50000 - 50000mean: 3.4636 - accuracy: 0.7288\n",
            "Epoch 8/100\n",
            "50000 - 50000mean: 3.2233 - accuracy: 0.7157\n",
            "Epoch 9/100\n",
            "50000 - 50000mean: 3.0913 - accuracy: 0.6976\n",
            "Epoch 10/100\n",
            "50000 - 50000mean: 3.6358 - accuracy: 0.6593\n",
            "Epoch 11/100\n",
            "50000 - 50000mean: 2.0224 - accuracy: 0.7097\n",
            "Epoch 12/100\n",
            "50000 - 50000mean: 1.8251 - accuracy: 0.7026\n",
            "Epoch 13/100\n",
            "50000 - 50000mean: 2.0329 - accuracy: 0.7137\n",
            "Epoch 14/100\n",
            "50000 - 50000mean: 1.3845 - accuracy: 0.7228\n",
            "Epoch 15/100\n",
            "50000 - 50000mean: 1.5505 - accuracy: 0.6976\n",
            "Epoch 16/100\n",
            "50000 - 50000mean: 1.2465 - accuracy: 0.7157\n",
            "Epoch 17/100\n",
            "50000 - 50000mean: 1.3590 - accuracy: 0.7097\n",
            "Epoch 18/100\n",
            "50000 - 50000mean: 1.1329 - accuracy: 0.7429\n",
            "Epoch 19/100\n",
            "50000 - 50000mean: 1.0080 - accuracy: 0.7581\n",
            "Epoch 20/100\n",
            "50000 - 50000mean: 1.0940 - accuracy: 0.7550\n",
            "Epoch 21/100\n",
            "50000 - 50000mean: 1.1495 - accuracy: 0.7127\n",
            "Epoch 22/100\n",
            "50000 - 50000mean: 1.1885 - accuracy: 0.7278\n",
            "Epoch 23/100\n",
            "50000 - 50000mean: 1.1400 - accuracy: 0.6976\n",
            "Epoch 24/100\n",
            "50000 - 50000mean: 0.9965 - accuracy: 0.7147\n",
            "Epoch 25/100\n",
            "50000 - 50000mean: 0.8727 - accuracy: 0.7389\n",
            "Epoch 26/100\n",
            "50000 - 50000mean: 0.9598 - accuracy: 0.7198\n",
            "Epoch 27/100\n",
            "50000 - 50000mean: 0.8875 - accuracy: 0.7188\n",
            "Epoch 28/100\n",
            "50000 - 50000mean: 0.7690 - accuracy: 0.7762\n",
            "Epoch 29/100\n",
            "50000 - 50000mean: 0.8124 - accuracy: 0.7641\n",
            "Epoch 30/100\n",
            "50000 - 50000mean: 0.7916 - accuracy: 0.7843\n",
            "Epoch 31/100\n",
            "50000 - 50000mean: 0.8301 - accuracy: 0.7651\n",
            "Epoch 32/100\n",
            "50000 - 50000mean: 0.7576 - accuracy: 0.7843\n",
            "Epoch 33/100\n",
            "50000 - 50000mean: 0.8738 - accuracy: 0.7429\n",
            "Epoch 34/100\n",
            "50000 - 50000mean: 0.7572 - accuracy: 0.7540\n",
            "Epoch 35/100\n",
            "50000 - 50000mean: 0.6490 - accuracy: 0.7893\n",
            "Epoch 36/100\n",
            "50000 - 50000mean: 0.7271 - accuracy: 0.7853\n",
            "Epoch 37/100\n",
            "50000 - 50000mean: 0.7070 - accuracy: 0.7681\n",
            "Epoch 38/100\n",
            "50000 - 50000mean: 0.6549 - accuracy: 0.7873\n",
            "Epoch 39/100\n",
            "50000 - 50000mean: 0.7748 - accuracy: 0.7702\n",
            "Epoch 40/100\n",
            "50000 - 50000mean: 0.7343 - accuracy: 0.7611\n",
            "Epoch 41/100\n",
            "50000 - 50000mean: 0.6912 - accuracy: 0.7631\n",
            "Epoch 42/100\n",
            "50000 - 50000mean: 0.6654 - accuracy: 0.7903\n",
            "Epoch 43/100\n",
            "50000 - 50000mean: 0.6620 - accuracy: 0.8024\n",
            "Epoch 44/100\n",
            "50000 - 50000mean: 0.6819 - accuracy: 0.7863\n",
            "Epoch 45/100\n",
            "50000 - 50000mean: 0.7450 - accuracy: 0.7853\n",
            "Epoch 46/100\n",
            "50000 - 50000mean: 0.6927 - accuracy: 0.7742\n",
            "Epoch 47/100\n",
            "50000 - 50000mean: 0.6113 - accuracy: 0.7833\n",
            "Epoch 48/100\n",
            "50000 - 50000mean: 0.6036 - accuracy: 0.7923\n",
            "Epoch 49/100\n",
            "50000 - 50000mean: 0.7214 - accuracy: 0.7510\n",
            "Epoch 50/100\n",
            "50000 - 50000mean: 0.6850 - accuracy: 0.7681\n",
            "Epoch 51/100\n",
            "50000 - 50000mean: 0.6050 - accuracy: 0.7883\n",
            "Epoch 52/100\n",
            "50000 - 50000mean: 0.6010 - accuracy: 0.7893\n",
            "Epoch 53/100\n",
            "50000 - 50000mean: 0.6673 - accuracy: 0.7923\n",
            "Epoch 54/100\n",
            "50000 - 50000mean: 0.5867 - accuracy: 0.8044\n",
            "Epoch 55/100\n",
            "50000 - 50000mean: 0.6301 - accuracy: 0.7944\n",
            "Epoch 56/100\n",
            "50000 - 50000mean: 0.5924 - accuracy: 0.7964\n",
            "Epoch 57/100\n",
            "50000 - 50000mean: 0.7165 - accuracy: 0.7621\n",
            "Epoch 58/100\n",
            "50000 - 50000mean: 0.5953 - accuracy: 0.7974\n",
            "Epoch 59/100\n",
            "50000 - 50000mean: 0.7607 - accuracy: 0.7671\n",
            "Epoch 60/100\n",
            "50000 - 50000mean: 0.5418 - accuracy: 0.8125\n",
            "Epoch 61/100\n",
            "50000 - 50000mean: 0.6158 - accuracy: 0.7843\n",
            "Epoch 62/100\n",
            "50000 - 50000mean: 0.5291 - accuracy: 0.8185\n",
            "Epoch 63/100\n",
            "50000 - 50000mean: 0.6222 - accuracy: 0.7893\n",
            "Epoch 64/100\n",
            "50000 - 50000mean: 0.6067 - accuracy: 0.7893\n",
            "Epoch 65/100\n",
            "50000 - 50000mean: 0.6090 - accuracy: 0.8115\n",
            "Epoch 66/100\n",
            "50000 - 50000mean: 0.6232 - accuracy: 0.7974\n",
            "Epoch 67/100\n",
            "50000 - 50000mean: 0.6995 - accuracy: 0.7903\n",
            "Epoch 68/100\n",
            "50000 - 50000mean: 0.6439 - accuracy: 0.7833\n",
            "Epoch 69/100\n",
            "50000 - 50000mean: 0.6329 - accuracy: 0.7893\n",
            "Epoch 70/100\n",
            "50000 - 50000mean: 0.6820 - accuracy: 0.7732\n",
            "Epoch 71/100\n",
            "50000 - 50000mean: 0.6414 - accuracy: 0.8034\n",
            "Epoch 72/100\n",
            "50000 - 50000mean: 0.5895 - accuracy: 0.8044\n",
            "Epoch 73/100\n",
            "50000 - 50000mean: 0.6472 - accuracy: 0.7752\n",
            "Epoch 74/100\n",
            "50000 - 50000mean: 0.7276 - accuracy: 0.7591\n",
            "Epoch 75/100\n",
            "50000 - 50000mean: 0.6260 - accuracy: 0.7944\n",
            "Epoch 76/100\n",
            "50000 - 50000mean: 0.6758 - accuracy: 0.7702\n",
            "Epoch 77/100\n",
            "50000 - 50000mean: 0.6367 - accuracy: 0.7913\n",
            "Epoch 78/100\n",
            "50000 - 50000mean: 0.7499 - accuracy: 0.7298\n",
            "Epoch 79/100\n",
            "50000 - 50000mean: 0.8354 - accuracy: 0.7288\n",
            "Epoch 80/100\n",
            "50000 - 50000mean: 0.6514 - accuracy: 0.7873\n",
            "Epoch 81/100\n",
            "50000 - 50000mean: 0.6428 - accuracy: 0.7702\n",
            "Epoch 82/100\n",
            "50000 - 50000mean: 0.6163 - accuracy: 0.8004\n",
            "Epoch 83/100\n",
            "50000 - 50000mean: 0.6753 - accuracy: 0.7681\n",
            "Epoch 84/100\n",
            "50000 - 50000mean: 0.5728 - accuracy: 0.8115\n",
            "Epoch 85/100\n",
            "50000 - 50000mean: 0.6297 - accuracy: 0.7984\n",
            "Epoch 86/100\n",
            "50000 - 50000mean: 0.6797 - accuracy: 0.7903\n",
            "Epoch 87/100\n",
            "50000 - 50000mean: 0.6086 - accuracy: 0.7863\n",
            "Epoch 88/100\n",
            "50000 - 50000mean: 0.5550 - accuracy: 0.8034\n",
            "Epoch 89/100\n",
            "50000 - 50000mean: 0.6028 - accuracy: 0.7933\n",
            "Epoch 90/100\n",
            "50000 - 50000mean: 0.6796 - accuracy: 0.7873\n",
            "Epoch 91/100\n",
            "50000 - 50000mean: 0.6250 - accuracy: 0.7853\n",
            "Epoch 92/100\n",
            "50000 - 50000mean: 0.6384 - accuracy: 0.7873\n",
            "Epoch 93/100\n",
            "50000 - 50000mean: 0.6222 - accuracy: 0.7631\n",
            "Epoch 94/100\n",
            "50000 - 50000mean: 0.5747 - accuracy: 0.8095\n",
            "Epoch 95/100\n",
            "50000 - 50000mean: 0.6895 - accuracy: 0.7651\n",
            "Epoch 96/100\n",
            "50000 - 50000mean: 0.5401 - accuracy: 0.7903\n",
            "Epoch 97/100\n",
            "50000 - 50000mean: 0.6066 - accuracy: 0.7944\n",
            "Epoch 98/100\n",
            "50000 - 50000mean: 0.6109 - accuracy: 0.7994\n",
            "Epoch 99/100\n",
            "50000 - 50000mean: 0.6204 - accuracy: 0.7853\n",
            "Epoch 100/100\n",
            "50000 - 50000mean: 0.6319 - accuracy: 0.8034\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, n_epochs+1):\n",
        "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
        "    for step in range(1, n_steps+1):\n",
        "        X_batch, y_batch = random_batch(X_train, y_train)\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_batch)\n",
        "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "            loss = tf.add_n([main_loss] + model.losses)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        for variable in model.variables:\n",
        "            if variable.constraint is not None:\n",
        "                variable.assign(variable.constraint(variable))\n",
        "        mean_loss(loss)\n",
        "        for metric in metrics:\n",
        "            metric(y_batch, tf.argmax(y_pred, axis=1))\n",
        "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
        "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
        "    for metric in [mean_loss] + metrics:\n",
        "        metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpwAOFgCDZcF",
        "outputId": "5e71ae22-74b4-4309-930e-ecb8e2a1ebf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
              "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 8, 5, 5, 5], dtype=int64)>"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veVTJ5PADZcF",
        "outputId": "9427d807-587b-4449-f789-86fbd2dd6605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4897 - accuracy: 0.8247 - val_loss: 0.4302 - val_accuracy: 0.8430\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3931 - accuracy: 0.8559 - val_loss: 0.3816 - val_accuracy: 0.8683\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3646 - accuracy: 0.8650 - val_loss: 0.4724 - val_accuracy: 0.8619\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3380 - accuracy: 0.8752 - val_loss: 0.4959 - val_accuracy: 0.8720\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3184 - accuracy: 0.8818 - val_loss: 0.6493 - val_accuracy: 0.8757\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3016 - accuracy: 0.8885 - val_loss: 0.5066 - val_accuracy: 0.8644\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2863 - accuracy: 0.8920 - val_loss: 0.4828 - val_accuracy: 0.8733\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2799 - accuracy: 0.8952 - val_loss: 0.4527 - val_accuracy: 0.8751\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2720 - accuracy: 0.8982 - val_loss: 0.4674 - val_accuracy: 0.8695\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2601 - accuracy: 0.9020 - val_loss: 0.3637 - val_accuracy: 0.8824\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2543 - accuracy: 0.9044 - val_loss: 0.3973 - val_accuracy: 0.8819\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2513 - accuracy: 0.9065 - val_loss: 0.4351 - val_accuracy: 0.8853\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2451 - accuracy: 0.9066 - val_loss: 0.4293 - val_accuracy: 0.8839\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2395 - accuracy: 0.9100 - val_loss: 0.4919 - val_accuracy: 0.8657\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2277 - accuracy: 0.9149 - val_loss: 0.4403 - val_accuracy: 0.8825\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2226 - accuracy: 0.9156 - val_loss: 0.4965 - val_accuracy: 0.8774\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2185 - accuracy: 0.9175 - val_loss: 0.4521 - val_accuracy: 0.8793\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2113 - accuracy: 0.9192 - val_loss: 0.4154 - val_accuracy: 0.8847\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2081 - accuracy: 0.9214 - val_loss: 0.3939 - val_accuracy: 0.8789\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2056 - accuracy: 0.9214 - val_loss: 0.5175 - val_accuracy: 0.8839\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2af4bfa8fa0>"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2 = model = Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)), \n",
        "    layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    layers.BatchNormalization(), \n",
        "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    layers.BatchNormalization(), \n",
        "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    layers.BatchNormalization(), \n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "], name=\"fashion_mnist_model_2\")\n",
        "model_2.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "                optimizer=\"adam\", \n",
        "                metrics=[\"accuracy\"])\n",
        "model_2.fit(X_train, y_train, epochs=100, \n",
        "            validation_data=(X_val, y_val), \n",
        "            callbacks=[keras.callbacks.EarlyStopping(patience=10, \n",
        "                                                     monitor=\"val_loss\",\n",
        "                                                     restore_best_weights=True)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaNa6kXFDZcF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "81727fb6587a0e5418c3cf386f53a5fb924b641d49e181fa8e28403b9a38d60e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Ch-12(Tensorflow).ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}