{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIOGA0h5jLhK"
      },
      "source": [
        "### ShakesPearean Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-F8NW5WjLhT"
      },
      "source": [
        "#### Creating a Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qwTXqBVqjLhV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Sequential, callbacks\n",
        "import numpy as np\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H0rp6hV5jLhY",
        "outputId": "1cf4d3e9-dbc2-4323-c974-a537fac30e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "r = requests.get(\"https://homl.info/shakespeare\")\n",
        "open(\"shakespearean_text.txt\", \"wb\").write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qAT6INH_jLhb"
      },
      "outputs": [],
      "source": [
        "with open(\"shakespearean_text.txt\") as f:\n",
        "    shakespear_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2gzYwYBJjLhc"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts([shakespear_text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h8CP81MvjLhd",
        "outputId": "1a9353c5-68fe-46ee-ec0c-54f883bc5e67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 2, 12, 12, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([\"Hello\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OataVLotjLhf",
        "outputId": "ad7ec6a2-b707-4ad4-ee98-da4c016ea281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['h e l l o']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts([[7, 2, 12, 12, 4]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mAi_MGujjLhh"
      },
      "outputs": [],
      "source": [
        "max_id = len(tokenizer.word_index)\n",
        "# dataset_size = tokenizer.document_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JC__HknljLhi",
        "outputId": "4e46dd8b-248a-4ab5-dc1b-6af268173e42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "max_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zdnaxLVxjLhk"
      },
      "outputs": [],
      "source": [
        "[encoded_text] = np.array(tokenizer.texts_to_sequences([shakespear_text])) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pfrrgpO-jLhl",
        "outputId": "08fd6c74-95da-4742-cd0d-b7f60f116e70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1115394,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "encoded_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8v4_BfiNjLhm",
        "outputId": "495e5c22-27ae-4d09-82d5-d74e36e100b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset_size = len(encoded_text)\n",
        "dataset_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo_eyDHRjLhn"
      },
      "source": [
        "#### Spliting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wtFvShSKjLhn"
      },
      "outputs": [],
      "source": [
        "train_size = int(dataset_size * 0.9)\n",
        "train_set = tf.data.Dataset.from_tensor_slices(encoded_text[:train_size])\n",
        "validation_set = tf.data.Dataset.from_tensor_slices(encoded_text[train_size:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lszf9UyojLho"
      },
      "source": [
        "#### Batching dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "865-VRWQjLhp"
      },
      "outputs": [],
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1\n",
        "train_set = train_set.window(window_length, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wtE4f29djLhq",
        "outputId": "68f96708-5c31-4b1f-9b2d-a4166f198074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 5 8 7 2 0 18 5 2 5 35 1 9 23 10 21 1 19 3 8 1 0 16 1 0 22 8 3 18 1 1 12 0 4 9 15 0 19 13 8 2 6 1 8 17 0 6 1 4 8 0 14 1 0 7 22 1 4 24 26 10 10 4 11 11 23 10 7 22 1 4 24 17 0 7 22 1 4 24 26 10 10 19 5 8 7 2 0 18 5 2 5 35 1 9 23 10 15 3 13 0 "
          ]
        }
      ],
      "source": [
        "for i in train_set.take(1):\n",
        "    for x in i.as_numpy_iterator():\n",
        "        print(x, end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "C8sqoqhmjLhr"
      },
      "outputs": [],
      "source": [
        "train_set = train_set.flat_map(lambda window: window.batch(window_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Lk_vyKS7jLhr",
        "outputId": "22d8ecab-29c1-4f8c-bd2e-205d31d4386a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1\n",
            "  0 22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1\n",
            "  4  8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24\n",
            " 17  0  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23\n",
            " 10 15  3 13  0], shape=(101,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for i in train_set.take(1):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OuqC_It6jLhs"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_set = train_set.shuffle(10000).batch(batch_size)\n",
        "train_set = train_set.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AMzUQzZFjLht"
      },
      "outputs": [],
      "source": [
        "train_set = train_set.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)\n",
        ")\n",
        "train_set = train_set.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_RGkYKyjLhu"
      },
      "source": [
        "#### Training Char-RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4O7ax5ljLhu"
      },
      "outputs": [],
      "source": [
        "model1 = Sequential([\n",
        "    layers.GRU(128, input_shape=[None, max_id],\n",
        "               dropout=0.2,\n",
        "            #    recurrent_dropout=0.2, \n",
        "               return_sequences=True), \n",
        "    layers.GRU(128, dropout=0.2, \n",
        "            #    recurrent_dropout=0.2, \n",
        "               return_sequences=True), \n",
        "    layers.TimeDistributed(layers.Dense(max_id, activation=\"softmax\"))\n",
        "])\n",
        "model1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history1 = model1.fit(train_set, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfmbUN1CjLhw"
      },
      "outputs": [],
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts))\n",
        "    return tf.one_hot(X, max_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tWeI4_0jLhw"
      },
      "outputs": [],
      "source": [
        "X_new = preprocess([\"How are yo\"])\n",
        "Y_pred = model1.predict_classes(X_new)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temperature):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model1.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "metadata": {
        "id": "9XXqEqLiA0vp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "metadata": {
        "id": "l5xI-flfBnLz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Statefull RNN"
      ],
      "metadata": {
        "id": "PzhjfBAVB68N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(encoded_text[:train_size])\n",
        "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "dataset = dataset.batch(1)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "I5iaRyp8Keso"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "        layers.GRU(128, return_sequences=True, stateful=True, \n",
        "                dropout=0.2, \n",
        "                # recurrent_dropout=0.2, \n",
        "                batch_input_shape=[1, None, max_id]), \n",
        "        layers.GRU(128, return_sequences=True, stateful=True, \n",
        "                dropout=0.2, \n",
        "                # recurrent_dropout=0.2,\n",
        "                ), \n",
        "        layers.TimeDistributed(layers.Dense(max_id, activation=\"softmax\"))\n",
        "])"
      ],
      "metadata": {
        "id": "mmhErHnQLlyU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResetStateCallback(callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()"
      ],
      "metadata": {
        "id": "XFfS81edNCDR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "              optimizer=\"adam\")\n",
        "model2.fit(dataset, epochs=50, callbacks=[ResetStateCallback()])"
      ],
      "metadata": {
        "id": "9jzHivh0NTGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Analysis"
      ],
      "metadata": {
        "id": "lYjHnuDKNsKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0BEDKn3jNuj_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "81727fb6587a0e5418c3cf386f53a5fb924b641d49e181fa8e28403b9a38d60e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Ch-16(NLP).ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}