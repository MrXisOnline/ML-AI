{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqex3jKgs68E"
      },
      "source": [
        "## The Data API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abgb4zgFu-i7"
      },
      "source": [
        "### Creating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4xtBXGixwEb",
        "outputId": "e7266f5c-fc1b-4ed8-8dde-7e71f1e6ab2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "X = tf.range(10)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_UW4K35yHm_",
        "outputId": "d1c2d24d-d2b4-45df-8b64-49c4a17d708a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_rn22doy0NU"
      },
      "source": [
        "### Chaining Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIm-O6xLzCRY",
        "outputId": "5ae57341-59f7-4c9b-9af6-89de68f794d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.repeat(3).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN7XXGxs2oYC",
        "outputId": "b33707ac-e97e-4740-f8ba-24a2f355b77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
            "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.map(lambda x: x*2)\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PicldsV6WzI",
        "outputId": "8b257b6a-616c-400a-d8e7-8c520731464c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\msi1\\AppData\\Local\\Temp/ipykernel_9424/643490874.py:1: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.unbatch()`.\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.apply(tf.data.experimental.unbatch())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6JmwO0xu-i_",
        "outputId": "f710918f-a6dc-404c-a37f-1bff1561de6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for item in dataset.take(5):\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbvgYNzzu-i_"
      },
      "source": [
        "### Shuffling the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz-Pv4Ixu-i_",
        "outputId": "7b53532e-e462-4c04-cd33-01eaaaf24ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 6 5 7 3 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 2 1 0 4 6 4], shape=(7,), dtype=int64)\n",
            "tf.Tensor([7 2 5 9 2 1 3], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 3 8 7 9 5 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 6], shape=(2,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "dataset = tf.data.Dataset.range(10).repeat(3)\n",
        "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU_M8hSJu-i_"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target.reshape(-1, 1), \n",
        "                                                    random_state=42)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_mean, X_std = scaler.mean_, scaler.scale_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOQ3tTn6u-jA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
        "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
        "    os.makedirs(housing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
        "    \n",
        "    filepaths = []\n",
        "    m = len(data)\n",
        "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(part_csv)\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoOyHkRMu-jA"
      },
      "outputs": [],
      "source": [
        "train_data = np.c_[X_train, y_train]\n",
        "test_data = np.c_[X_test, y_test]\n",
        "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
        "header = \",\".join(header_cols)\n",
        "\n",
        "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header=header, n_parts=20)\n",
        "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header=header, n_parts=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojuWhkt-u-jA",
        "outputId": "9a8834c2-9cf7-49f6-935a-585fd8b409c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>MedianHouseValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.2143</td>\n",
              "      <td>37.0</td>\n",
              "      <td>5.288235</td>\n",
              "      <td>0.973529</td>\n",
              "      <td>860.0</td>\n",
              "      <td>2.529412</td>\n",
              "      <td>33.81</td>\n",
              "      <td>-118.12</td>\n",
              "      <td>2.285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.3468</td>\n",
              "      <td>42.0</td>\n",
              "      <td>6.364322</td>\n",
              "      <td>1.087940</td>\n",
              "      <td>957.0</td>\n",
              "      <td>2.404523</td>\n",
              "      <td>37.16</td>\n",
              "      <td>-121.98</td>\n",
              "      <td>2.799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.9191</td>\n",
              "      <td>36.0</td>\n",
              "      <td>6.110063</td>\n",
              "      <td>1.059748</td>\n",
              "      <td>711.0</td>\n",
              "      <td>2.235849</td>\n",
              "      <td>38.45</td>\n",
              "      <td>-122.69</td>\n",
              "      <td>1.830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.3703</td>\n",
              "      <td>32.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.990196</td>\n",
              "      <td>1159.0</td>\n",
              "      <td>2.272549</td>\n",
              "      <td>34.16</td>\n",
              "      <td>-118.41</td>\n",
              "      <td>4.658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.3684</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.795858</td>\n",
              "      <td>1.035503</td>\n",
              "      <td>706.0</td>\n",
              "      <td>2.088757</td>\n",
              "      <td>38.57</td>\n",
              "      <td>-121.33</td>\n",
              "      <td>1.500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
              "0  4.2143      37.0  5.288235   0.973529       860.0  2.529412     33.81   \n",
              "1  5.3468      42.0  6.364322   1.087940       957.0  2.404523     37.16   \n",
              "2  3.9191      36.0  6.110063   1.059748       711.0  2.235849     38.45   \n",
              "3  6.3703      32.0  6.000000   0.990196      1159.0  2.272549     34.16   \n",
              "4  2.3684      17.0  4.795858   1.035503       706.0  2.088757     38.57   \n",
              "\n",
              "   Longitude  MedianHouseValue  \n",
              "0    -118.12             2.285  \n",
              "1    -121.98             2.799  \n",
              "2    -122.69             1.830  \n",
              "3    -118.41             4.658  \n",
              "4    -121.33             1.500  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.read_csv(train_filepaths[0]).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBnawEieu-jB",
        "outputId": "a6dd99fe-d47a-43ae-f4bd-7f7c9e14470c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
            "4.2143,37.0,5.288235294117647,0.9735294117647059,860.0,2.5294117647058822,33.81,-118.12,2.285\n",
            "5.3468,42.0,6.364321608040201,1.0879396984924623,957.0,2.4045226130653266,37.16,-121.98,2.799\n",
            "3.9191,36.0,6.110062893081761,1.059748427672956,711.0,2.2358490566037736,38.45,-122.69,1.83\n",
            "6.3703,32.0,6.0,0.9901960784313726,1159.0,2.272549019607843,34.16,-118.41,4.658\n"
          ]
        }
      ],
      "source": [
        "with open(train_filepaths[0]) as f:\n",
        "    for i in range(5):\n",
        "        print(f.readline(), end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxY1GdFWu-jB"
      },
      "source": [
        "### Building an Input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l925DhNu-jB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtYemE64u-jB",
        "outputId": "dc91608d-9312-4fa1-a02e-37fdc385650a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_05.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_16.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_01.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_17.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_00.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_14.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_10.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_02.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_12.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_19.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_07.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_09.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_13.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_15.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_11.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_18.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_04.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_06.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_03.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_08.csv', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for filepath in filepath_dataset:\n",
        "    print(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynFNmcteu-jC"
      },
      "outputs": [],
      "source": [
        "n_reader = 5\n",
        "dataset = filepath_dataset.interleave(\n",
        "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1), \n",
        "    cycle_length=n_reader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gryzdLlu-jC",
        "outputId": "13a53db3-447d-402e-a1f6-e929fef5b8bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'3.3125,11.0,5.361736334405145,1.0578778135048232,1963.0,3.1559485530546625,38.69,-121.46,0.968'\n",
            "b'2.4524,41.0,5.340116279069767,1.188953488372093,1430.0,4.156976744186046,34.13,-117.32,0.704'\n",
            "b'5.8735,35.0,5.811638591117918,1.0566615620214395,1521.0,2.329249617151608,34.11,-118.63,4.481'\n",
            "b'3.8788,20.0,5.140068886337543,1.060849598163031,2656.0,3.049368541905855,37.13,-121.66,2.269'\n",
            "b'4.5893,39.0,5.711688311688311,1.0077922077922077,1025.0,2.6623376623376624,37.95,-122.07,1.9'\n"
          ]
        }
      ],
      "source": [
        "for line in dataset.take(5):\n",
        "    print(line.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhg8N1dMu-jC"
      },
      "source": [
        "### Processing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWGXycR-u-jC"
      },
      "outputs": [],
      "source": [
        "n_inputs = 8\n",
        "\n",
        "def preprocess(line):\n",
        "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
        "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
        "    x = tf.stack(fields[:-1])\n",
        "    y = tf.stack(fields[-1:])\n",
        "    return (x - X_mean)/X_std, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DluopSngu-jD",
        "outputId": "a253294f-21bb-4451-c99f-37d7dcdfd9e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 0.17648865,  0.66640687, -0.06085434, -0.2811182 , -0.49654418,\n",
              "        -0.04828325, -0.86074144,  0.73099613], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.285], dtype=float32)>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess(b'4.2143,37.0,5.288235294117647,0.9735294117647059,860.0,2.5294117647058822,33.81,-118.12,2.285')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0XJqbtcu-jD"
      },
      "outputs": [],
      "source": [
        "def csv_reader_dataset(filepaths, repeat=1, n_readers=5, \n",
        "                       n_read_threads=None, shuffle_buffer_size=10000, \n",
        "                       n_parse_threads=5, batch_size=32):\n",
        "    dataset = tf.data.Dataset.list_files(filepaths)\n",
        "    dataset = dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1), \n",
        "                                 cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
        "    return dataset.batch(batch_size).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7umE9zG3u-jD",
        "outputId": "c3744a1d-36d5-436a-bc76-b5e5c9457f7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   4.2143    ,   37.        ,    5.28823529,    0.97352941,\n",
              "        860.        ,    2.52941176,   33.81      , -118.12      ])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA2IBLsvu-jD"
      },
      "source": [
        "### Using Dataset with tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb3v2euFu-jD"
      },
      "outputs": [],
      "source": [
        "train_set = csv_reader_dataset(train_filepaths)\n",
        "test_set = csv_reader_dataset(test_filepaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz3dGUrLu-jE",
        "outputId": "71ca0029-1e89-4708-9ea7-98020e5f8560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "484/484 [==============================] - 2s 2ms/step - loss: 0.5514 - mae: 0.5358 - val_loss: 0.5612 - val_mae: 0.5202\n",
            "Epoch 2/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.4150 - mae: 0.4621 - val_loss: 0.3551 - val_mae: 0.4313\n",
            "Epoch 3/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3963 - mae: 0.4492 - val_loss: 0.4187 - val_mae: 0.4794\n",
            "Epoch 4/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3832 - mae: 0.4426 - val_loss: 0.5200 - val_mae: 0.4968\n",
            "Epoch 5/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3792 - mae: 0.4359 - val_loss: 0.4806 - val_mae: 0.5197\n",
            "Epoch 6/100\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.3643 - mae: 0.4304 - val_loss: 0.3219 - val_mae: 0.4059\n",
            "Epoch 7/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3563 - mae: 0.4240 - val_loss: 0.4373 - val_mae: 0.4445\n",
            "Epoch 8/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3542 - mae: 0.4233 - val_loss: 0.4294 - val_mae: 0.4442\n",
            "Epoch 9/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3489 - mae: 0.4207 - val_loss: 0.4071 - val_mae: 0.4907\n",
            "Epoch 10/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3555 - mae: 0.4265 - val_loss: 0.3989 - val_mae: 0.4681\n",
            "Epoch 11/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3401 - mae: 0.4151 - val_loss: 0.3602 - val_mae: 0.3993\n",
            "Epoch 12/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3499 - mae: 0.4227 - val_loss: 0.3358 - val_mae: 0.3846\n",
            "Epoch 13/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3502 - mae: 0.4231 - val_loss: 0.4278 - val_mae: 0.5148\n",
            "Epoch 14/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3369 - mae: 0.4141 - val_loss: 0.3552 - val_mae: 0.4362\n",
            "Epoch 15/100\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.3415 - mae: 0.4167 - val_loss: 0.4747 - val_mae: 0.4915\n",
            "Epoch 16/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3362 - mae: 0.4117 - val_loss: 0.4302 - val_mae: 0.4429\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x24bab27f2b0>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers, callbacks\n",
        "model = keras.Sequential([keras.layers.Dense(100, activation=\"relu\"), \n",
        "                          keras.layers.BatchNormalization(), \n",
        "                          keras.layers.Dense(200, activation=\"relu\"), \n",
        "                          keras.layers.BatchNormalization(), \n",
        "                          keras.layers.Dense(10, activation=\"relu\"), \n",
        "                          keras.layers.BatchNormalization(), \n",
        "                          keras.layers.Dense(1)])\n",
        "model.compile(loss=\"mse\", optimizer=optimizers.SGD(learning_rate=1e-2, nesterov=True, \n",
        "                                                   momentum=0.93), metrics=[\"mae\"])\n",
        "model.fit(train_set, epochs=100, \n",
        "          validation_data=test_set, \n",
        "          callbacks=[callbacks.EarlyStopping(patience=10, \n",
        "                                             restore_best_weights=True, \n",
        "                                             monitor=\"val_loss\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqbFwMuCu-jE",
        "outputId": "20c3398f-6bf3-41d1-f5ee-d1f48da7e603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 1ms/step - loss: 0.3219 - mae: 0.4059\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.3218575417995453, 0.4059430658817291]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p36a7gxju-jE",
        "outputId": "449dc09a-ab99-462d-a6e7-52d26513c25f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.9361138 ],\n",
              "       [0.9133055 ],\n",
              "       [2.434945  ],\n",
              "       [2.3590877 ],\n",
              "       [1.2241691 ],\n",
              "       [2.530606  ],\n",
              "       [4.6654253 ],\n",
              "       [2.7495708 ],\n",
              "       [0.93317914],\n",
              "       [2.0079727 ],\n",
              "       [3.4963975 ],\n",
              "       [2.6451511 ],\n",
              "       [2.0391731 ],\n",
              "       [1.194759  ],\n",
              "       [1.3651963 ],\n",
              "       [5.110795  ],\n",
              "       [3.0155265 ],\n",
              "       [1.4997151 ],\n",
              "       [2.5836954 ],\n",
              "       [1.0702391 ],\n",
              "       [2.1778834 ],\n",
              "       [1.0713279 ],\n",
              "       [0.9217081 ],\n",
              "       [2.8020098 ],\n",
              "       [1.7460865 ],\n",
              "       [2.945178  ],\n",
              "       [1.7114737 ],\n",
              "       [2.0891716 ],\n",
              "       [2.305393  ],\n",
              "       [2.0068982 ],\n",
              "       [1.7338572 ],\n",
              "       [2.7331486 ],\n",
              "       [3.7790947 ],\n",
              "       [0.9678383 ],\n",
              "       [2.425568  ],\n",
              "       [2.6264007 ],\n",
              "       [1.9635203 ],\n",
              "       [1.2492391 ],\n",
              "       [1.0608734 ],\n",
              "       [2.624142  ],\n",
              "       [2.179114  ],\n",
              "       [1.9583938 ],\n",
              "       [0.8439145 ],\n",
              "       [1.301668  ],\n",
              "       [1.7930489 ],\n",
              "       [1.8987231 ],\n",
              "       [1.1935368 ],\n",
              "       [2.2147698 ],\n",
              "       [3.7301488 ],\n",
              "       [3.182203  ],\n",
              "       [2.209907  ],\n",
              "       [2.4681718 ],\n",
              "       [2.8485055 ],\n",
              "       [2.186312  ],\n",
              "       [1.9342339 ],\n",
              "       [1.6700764 ],\n",
              "       [1.2814641 ],\n",
              "       [2.0246856 ],\n",
              "       [2.1582336 ],\n",
              "       [2.3998184 ],\n",
              "       [2.0721788 ],\n",
              "       [2.1509278 ],\n",
              "       [2.8144794 ],\n",
              "       [2.6759672 ],\n",
              "       [2.6319306 ],\n",
              "       [2.6405406 ],\n",
              "       [1.7776796 ],\n",
              "       [2.1983848 ],\n",
              "       [2.9530194 ],\n",
              "       [5.768956  ],\n",
              "       [2.238689  ],\n",
              "       [1.4894311 ],\n",
              "       [1.553855  ],\n",
              "       [4.4035435 ],\n",
              "       [2.30749   ],\n",
              "       [1.8487935 ],\n",
              "       [1.7697408 ],\n",
              "       [1.4272227 ],\n",
              "       [1.5867543 ],\n",
              "       [1.890112  ],\n",
              "       [3.5849648 ],\n",
              "       [2.646664  ],\n",
              "       [2.9345837 ],\n",
              "       [1.131978  ],\n",
              "       [1.3661853 ],\n",
              "       [1.4781072 ],\n",
              "       [3.4416242 ],\n",
              "       [0.8668957 ],\n",
              "       [2.9001527 ],\n",
              "       [2.401717  ],\n",
              "       [1.9755334 ],\n",
              "       [1.8014824 ],\n",
              "       [1.6597252 ],\n",
              "       [1.5336657 ],\n",
              "       [3.0155883 ],\n",
              "       [1.1764789 ]], dtype=float32)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_set = test_set.take(3).map(lambda X, y: X)\n",
        "model.predict(new_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNjLCpQpu-jE"
      },
      "outputs": [],
      "source": [
        "# Custom function to train model\n",
        "\n",
        "@tf.function\n",
        "def train(model, optimizers, loss_fn, n_epochs, **kwargs):\n",
        "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs)\n",
        "    for X_batch, y_batch in train_set:\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_batch)\n",
        "            main_loss = loss_fn(y_batch, y_pred)\n",
        "            loss = tf.add_n([main_loss] + model.losses)\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiRYytiHu-jE"
      },
      "source": [
        "## The TFRecord Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-tQPG6Nu-jE"
      },
      "source": [
        "### Creating a TFRecord dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_gj9y_Au-jF",
        "outputId": "794ed0f9-c8ac-46ab-abce-9e3a2d3b8f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And, This is the second Record.', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
        "    f.write(b\"This is the first record\")\n",
        "    f.write(b\"And, This is the second Record.\")\n",
        "filepaths = [\"my_data.tfrecord\"]\n",
        "dataset = tf.data.TFRecordDataset(filepaths)\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUvYsA8-u-jF"
      },
      "source": [
        "### Compressed TFRecord Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJchAWLZu-jF",
        "outputId": "06aaf884-d965-4ebb-82d4-5714dd51e3d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'This is First One', shape=(), dtype=string)\n",
            "tf.Tensor(b'And the Another One', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "with tf.io.TFRecordWriter(\"my_compressed_data.tfrecord\", options) as f:\n",
        "    f.write(\"This is First One\")\n",
        "    f.write(\"And the Another One\")\n",
        "dataset = tf.data.TFRecordDataset([\"my_compressed_data.tfrecord\"], \n",
        "                                  compression_type=\"GZIP\")\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYE-TW3_u-jF"
      },
      "source": [
        "### Protocol Buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXY6JNTTu-jF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.train import BytesList, FloatList, Int64List\n",
        "from tensorflow.train import Feature, Features, Example\n",
        "\n",
        "person_example = Example(\n",
        "    features=Features(\n",
        "        feature={\n",
        "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])), \n",
        "            \"id\": Feature(int64_list=Int64List(value=[123])), \n",
        "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", \n",
        "                                                          b\"c@d.com\"]))\n",
        "        }))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISEwCI_4u-jF"
      },
      "outputs": [],
      "source": [
        "with tf.io.TFRecordWriter(\"my_contact.tfrecord\") as f:\n",
        "    f.write(person_example.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APesgI8xu-jF"
      },
      "source": [
        "### Loading and Parsing Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJhv85c6u-jG"
      },
      "outputs": [],
      "source": [
        "feature_description = {\n",
        "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"), \n",
        "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0), \n",
        "    \"emails\": tf.io.VarLenFeature(tf.string),\n",
        "}\n",
        "\n",
        "for serialized_example in tf.data.TFRecordDataset([\"my_contact.tfrecord\"]):\n",
        "    parsed_example = tf.io.parse_single_example(serialized_example, \n",
        "                                               feature_description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh0yj09zu-jG",
        "outputId": "b9a5eb70-2c22-4e21-e979-867c48e6e569"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0l79WTIu-jG",
        "outputId": "846c3b92-2308-4437-b8da-5ae1e85241be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_example[\"emails\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4Bmav9Ou-jG"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.TFRecordDataset([\"my_contact.tfrecord\"]).batch(10)\n",
        "for serialized_example in dataset:\n",
        "    parsed_examples = tf.io.parse_example(serialized_example, \n",
        "                                          feature_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBOmuuRDu-jG"
      },
      "source": [
        "### Handling Lists of List Using SequenceExample ProtoBuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpRZs3q0u-jG"
      },
      "outputs": [],
      "source": [
        "FeatureList = tf.train.FeatureList\n",
        "FeatureLists = tf.train.FeatureLists\n",
        "SequenceExample = tf.train.SequenceExample\n",
        "\n",
        "context = Features(feature={\n",
        "    \"author_id\": Feature(int64_list=Int64List(value=[123])), \n",
        "    \"title\": Feature(bytes_list=BytesList(value=[b\"A\", b\"desert\", b\"place\", b\".\"])), \n",
        "    \"pub_date\": Feature(int64_list=Int64List(value=[1623, 12, 25]))\n",
        "})\n",
        "\n",
        "content = [[\"When\", \"shall\", \"we\", \"three\", \"meet\", \"again\", \"?\"], \n",
        "           [\"In\", \"thunder\", \",\", \"lightning\", \",\", \"or\", \"in\", \"rain\", \"?\"]]\n",
        "comments = [[\"When\", \"the\", \"hurlyburly\", \"'s\", \"done\", \".\"], \n",
        "            [\"When\", \"the\", \"battle\", \"'s\", \"lost\", \"and\", \"won\", \".\"]]\n",
        "\n",
        "def words_to_feature(words):\n",
        "    return Feature(bytes_list=BytesList(value=[word.encode(\"utf-8\") for word in words]))\n",
        "\n",
        "content_features = [words_to_feature(sentence) for sentence in content]\n",
        "comment_features = [words_to_feature(comment) for comment in comments]\n",
        "\n",
        "sequence_example = SequenceExample(\n",
        "    context=context, \n",
        "    feature_lists=FeatureLists(feature_list={\n",
        "        \"content\": FeatureList(feature=content_features), \n",
        "        \"comments\": FeatureList(feature=comment_features)\n",
        "    })\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaDMKWWHu-jG"
      },
      "outputs": [],
      "source": [
        "context_feature_descriptions = {\n",
        "    \"author_id\": tf.io.FixedLenFeature([], tf.int64, default_value=0), \n",
        "    \"title\": tf.io.VarLenFeature(tf.string), \n",
        "    \"pub_data\": tf.io.FixedLenFeature([3], tf.int64, default_value=[0, 0, 0]), \n",
        "}\n",
        "\n",
        "sequence_feature_descriptions = {\n",
        "    \"content\": tf.io.VarLenFeature(tf.string), \n",
        "    \"comments\": tf.io.VarLenFeature(tf.string), \n",
        "}\n",
        "\n",
        "serialized_sequence_example = sequence_example.SerializeToString()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWzOiyVTu-jH"
      },
      "outputs": [],
      "source": [
        "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
        "    serialized_sequence_example, context_feature_descriptions, \n",
        "    sequence_feature_descriptions)\n",
        "parsed_content = tf.RaggedTensor.from_sparse(parsed_feature_lists[\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X9JnEbdu-jH",
        "outputId": "4ec12b55-2f2a-4b94-d82a-8e814399d101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x274a6b47af0>,\n",
              " 'author_id': <tf.Tensor: shape=(), dtype=int64, numpy=123>,\n",
              " 'pub_data': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 0, 0], dtype=int64)>}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cIRUD57u-jH",
        "outputId": "2d9c5b49-1c7e-49b5-9488-8df0f17edfba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'A', b'desert', b'place', b'.'], dtype=object)>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_context[\"title\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7BsJS-ju-jH",
        "outputId": "71a4bb1e-1413-418e-beef-5ce32feb11e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'comments': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x274ade08160>,\n",
              " 'content': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x274ae02c9d0>}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_feature_lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnqMKRvPu-jH",
        "outputId": "8f97a7df-64d5-4224-c030-ad0e93fbee99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'When', b'shall', b'we', b'three', b'meet', b'again', b'?'], [b'In', b'thunder', b',', b'lightning', b',', b'or', b'in', b'rain', b'?']]>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp2jTnJEu-jH"
      },
      "source": [
        "## Preprocessing the Input Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSg5Z-DUu-jI"
      },
      "source": [
        "### Standardization of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jEJH80Du-jI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "means = np.mean(X_train, axis=0, keepdims=True)\n",
        "stds = np.std(X_train, axis=0, keepdims=True)\n",
        "eps = keras.backend.epsilon()\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Lambda(lambda inputs: (input - means) / (stds + eps)), \n",
        "    keras.layers.Dense(10), \n",
        "    keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai1Q9ouPu-jI"
      },
      "outputs": [],
      "source": [
        "class StandardScaler(keras.layers.Layer):\n",
        "    def adapt(self, data_samples):\n",
        "        self.means_ = np.mean(data_samples, axis=0, keepdims=True)\n",
        "        self.std_ = np.std(data_samples, axis=0, keepdims=True)\n",
        "    def call(self, inputs):\n",
        "        return (inputs - self.means_)/(self.std_ + keras.backend.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v7nodrUu-jI"
      },
      "outputs": [],
      "source": [
        "std_layer = StandardScaler()\n",
        "std_layer.adapt(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXkJQUN_u-jI"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(std_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGoWS94Qu-jI"
      },
      "source": [
        "### Encoding Categorical Features Using One-Hot Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bpg4Z70u-jI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"dataset\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG88_r3bu-jI"
      },
      "outputs": [],
      "source": [
        "fetch_housing_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX4iZpmTu-jJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1Tc-9bIu-jJ",
        "outputId": "636fdc95-1957-45bd-dceb-2d2eabef9944"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.23     37.88                41.0        880.0           129.0   \n",
              "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
              "2    -122.24     37.85                52.0       1467.0           190.0   \n",
              "3    -122.25     37.85                52.0       1274.0           235.0   \n",
              "4    -122.25     37.85                52.0       1627.0           280.0   \n",
              "\n",
              "   population  households  median_income  median_house_value ocean_proximity  \n",
              "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
              "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
              "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
              "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
              "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "housing = load_housing_data()\n",
        "housing.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKcbk6Zgu-jL"
      },
      "source": [
        "#### in github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM2ytRWQu-jL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "housing_median_age = tf.feature_column.numeric_column(\"housing_median_age\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AsotPJau-jL"
      },
      "outputs": [],
      "source": [
        "age_mean, age_std = X_mean[1], X_std[1]\n",
        "housing_median_age = tf.feature_column.numeric_column(\n",
        "    \"housing_median_age\", normalizer_fn=lambda x: (x - age_mean)/age_std\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcV7HuVJu-jL"
      },
      "outputs": [],
      "source": [
        "median_income = tf.feature_column.numeric_column(\"median_income\")\n",
        "bucketized_income = tf.feature_column.bucketized_column(\n",
        "    median_income, boundaries=[1.5, 3., 4.5, 6.]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tDktBQMu-jM",
        "outputId": "e205552d-b28e-4bb8-91db-72fc94225bfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BucketizedColumn(source_column=NumericColumn(key='median_income', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(1.5, 3.0, 4.5, 6.0))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bucketized_income"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PikvbIQdu-jM"
      },
      "outputs": [],
      "source": [
        "ocean_prox_vocab = [\"<1H OCEAN\", \"INLAND\", \"ISLAND\", \"NEAR BAY\", \"NEAR OCEAN\"]\n",
        "ocean_proximity = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    \"ocean_proximity\", ocean_prox_vocab\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEStjWSSu-jM",
        "outputId": "5f34b795-31d0-4800-f100-ee4d2200d13d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VocabularyListCategoricalColumn(key='ocean_proximity', vocabulary_list=('<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ocean_proximity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWLMTnTdu-jM"
      },
      "source": [
        "#### book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjzNWJJgu-jM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcG0Rw0Wu-jM"
      },
      "outputs": [],
      "source": [
        "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
        "indices = tf.range(len(vocab), dtype=tf.int64)\n",
        "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
        "num_oov_buckets = 2\n",
        "table= tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets=num_oov_buckets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6uQeqPju-jM",
        "outputId": "69f89925-8473-4263-af01-db7112dbf9e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrofjU8_u-jM",
        "outputId": "c2e9e527-5a57-467e-b5b3-363465106f7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab)+num_oov_buckets)\n",
        "cat_one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NDMommfu-jN"
      },
      "source": [
        "### Encoding Categorical Features Using Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ-pzQPtu-jN"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 2\n",
        "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
        "embedding_matrix = tf.Variable(embed_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12VCcwd5u-jN",
        "outputId": "57d791f6-5352-46b5-b509-767a00c2501c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
              "array([[0.76847804, 0.24180698],\n",
              "       [0.53683543, 0.04629397],\n",
              "       [0.62679946, 0.00700271],\n",
              "       [0.723444  , 0.20266068],\n",
              "       [0.11565375, 0.5128256 ],\n",
              "       [0.3641951 , 0.01004899],\n",
              "       [0.14566624, 0.851266  ]], dtype=float32)>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm1mOL79u-jN",
        "outputId": "d33ac79f-2b23-4245-d982-09613c33ef1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHMuycTmu-jN",
        "outputId": "93a4e629-59f1-4c0f-fd9c-e5417a8801f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[0.723444  , 0.20266068],\n",
              "       [0.3641951 , 0.01004899],\n",
              "       [0.53683543, 0.04629397],\n",
              "       [0.53683543, 0.04629397]], dtype=float32)>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j86nIlpGu-jN"
      },
      "outputs": [],
      "source": [
        "embedding = keras.layers.Embedding(input_dim=len(vocab)+num_oov_buckets, \n",
        "                                   output_dim=embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o2I91Bpu-jN",
        "outputId": "fc5cd197-2273-441f-bdcc-5f08b9008d68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[-0.03529421, -0.03804005],\n",
              "       [-0.03340534,  0.03543509],\n",
              "       [-0.03967112, -0.04716682],\n",
              "       [-0.03967112, -0.04716682]], dtype=float32)>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding(cat_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etBE5cTPu-jO"
      },
      "outputs": [],
      "source": [
        "regular_inputs = keras.layers.Input(shape=[8])\n",
        "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
        "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
        "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
        "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
        "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
        "model = keras.models.Model(inputs=[regular_inputs, categories], outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pag1JSjAu-jO"
      },
      "source": [
        "### Keras Preprocessing Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMJoH-_du-jO"
      },
      "outputs": [],
      "source": [
        "normalization = layers.Normalization()\n",
        "discretization = layers.Discretization()\n",
        "# pipeline = layers.PreprocessingStage([normalization, discretization])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9Ck3iVJu-jO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgrshUFSu-jO"
      },
      "source": [
        "## TF Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IR-w3r3u-jO"
      },
      "outputs": [],
      "source": [
        "import tensorflow_transform as tft\n",
        "\n",
        "def preprocess(inputs):\n",
        "    median_age = inputs[\"housing_median_age\"]\n",
        "    ocean_proximity = inputs[\"ocean_proximity\"]\n",
        "    standardized_age = tft.scale_to_z_score(median_age)\n",
        "    ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
        "    return {\n",
        "        \"standardized_median_age\": standardized_age, \n",
        "        \"ocean_proximity_id\": ocean_proximity_id\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJaZEHiuu-jO"
      },
      "source": [
        "## The Tensorflow Dataset (TFDS) Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-25chf5u-jO"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset = tfds.load(name=\"mnist\")\n",
        "mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZOb4B1eu-jP",
        "outputId": "6068604e-17b9-47f8-e24f-953ecb3f818b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "mnist_train = mnist_train.shuffle(10000).batch(32)\n",
        "for item in mnist_train:\n",
        "    images = item[\"image\"]\n",
        "    labels = item[\"label\"]\n",
        "    for index in range(5):\n",
        "        plt.subplot(1, 5, index + 1)\n",
        "        image = images[index, ..., 0]\n",
        "        label = labels[index].numpy()\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.title(label)\n",
        "        plt.axis(\"off\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG9Yhubiu-jP"
      },
      "outputs": [],
      "source": [
        "mnist_train = mnist_train.map(lambda item: (item[\"image\"], item[\"label\"]))\n",
        "mnist_train = mnist_train.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A84SCPqu-jP"
      },
      "outputs": [],
      "source": [
        "## Going all this while loading\n",
        "dataset = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
        "mnist_train = dataset[\"train\"].prefetch(1)\n",
        "mnist_test = dataset[\"test\"].prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMe44foQu-jP",
        "outputId": "639a5d62-5ad8-4e17-ee48-8c8704f77fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 4ms/step - loss: 0.2149 - accuracy: 0.9339 - val_loss: 0.1012 - val_accuracy: 0.9690\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1003 - accuracy: 0.9688 - val_loss: 0.1040 - val_accuracy: 0.9684\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0722 - accuracy: 0.9770 - val_loss: 0.0965 - val_accuracy: 0.9740\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0516 - accuracy: 0.9826 - val_loss: 0.0978 - val_accuracy: 0.9751\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.1245 - val_accuracy: 0.9703\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0341 - accuracy: 0.9886 - val_loss: 0.1383 - val_accuracy: 0.9715\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0293 - accuracy: 0.9898 - val_loss: 0.1127 - val_accuracy: 0.9770\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.1068 - val_accuracy: 0.9772\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x215a09568e0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)), \n",
        "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    keras.layers.BatchNormalization(), \n",
        "    keras.layers.Dense(200, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    keras.layers.BatchNormalization(), \n",
        "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "              optimizer=\"adam\", \n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(mnist_train, epochs=10, \n",
        "          validation_data=mnist_test, \n",
        "          callbacks=[keras.callbacks.EarlyStopping(patience=5, \n",
        "                                                   restore_best_weights=True)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m94PyiLtu-jP"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tqPRdJcou-jP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers, initializers, losses, Sequential, datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Dxmt50YAu-jP"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "part = int(len(X_train) * 0.8)\n",
        "X_train, X_val, y_train, y_val = X_train[:part], X_train[part:], y_train[:part], y_train[part:]"
      ],
      "metadata": {
        "id": "00BWM2f-6Ylm"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Xat-m7_Cu-jQ",
        "outputId": "cc3c391b-cf53-41d4-9cd0-2118dadbd8e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "r_in = random.randint(0, len(X_train)-1)\n",
        "plt.imshow(X_train[r_in], cmap=plt.cm.binary)\n",
        "plt.title(y_train[r_in], c=\"r\")\n",
        "plt.axis(\"off\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "6X4MG23Zu-jQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.train import BytesList, Int64List, Feature, Features, Example"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tfrecord(filename, X, y):\n",
        "    with tf.io.TFRecordWriter(filename) as f:\n",
        "        for index in range(X.shape[0]):\n",
        "            data = tf.io.encode_jpeg(np.expand_dims(X[index], axis=2))\n",
        "            label = y[index]\n",
        "            image_ex = Example(features=Features(feature={\n",
        "                \"image\": Feature(bytes_list=BytesList(value=[data.numpy()])), \n",
        "                \"label\": Feature(int64_list=Int64List(value=[label]))\n",
        "            }))\n",
        "            f.write(image_ex.SerializeToString())"
      ],
      "metadata": {
        "id": "yVsm1_I75DlX"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "CdPjn8NNu-jQ"
      },
      "outputs": [],
      "source": [
        "make_tfrecord(\"my_fashion_mnist_train.tfrecord\", X_train, y_train)\n",
        "make_tfrecord(\"my_fashion_mnist_val.tfrecord\", X_val, y_train)\n",
        "make_tfrecord(\"my_fashion_mnist_test.tfrecord\", X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "irIBQdEnu-jQ"
      },
      "outputs": [],
      "source": [
        "feature_description = {\n",
        "    \"image\": tf.io.VarLenFeature(dtype=tf.string), \n",
        "    \"label\": tf.io.FixedLenFeature(dtype=tf.int64, shape=[])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_and_label(serialized_example):\n",
        "    parsed_ex = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    image = tf.reshape(tf.io.decode_jpeg(tf.sparse.to_dense(parsed_ex[\"image\"])[0]), (28, 28))\n",
        "    label = parsed_ex[\"label\"]\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "cqtIWr-h1EYb"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_dataset_train = tf.data.TFRecordDataset(\"my_fashion_mnist_train.tfrecord\").map(lambda e: get_image_and_label(e)).shuffle(32).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "fashion_dataset_val = tf.data.TFRecordDataset(\"my_fashion_mnist_val.tfrecord\").map(lambda e: get_image_and_label(e)).shuffle(32).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "fashion_dataset_test = tf.data.TFRecordDataset(\"my_fashion_mnist_test.tfrecord\").map(lambda e: get_image_and_label(e)).shuffle(32).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "7bKKbFHU0BWw"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Standardization(layers.Layer):\n",
        "    def adapt(self, data_samples):\n",
        "        for ()\n",
        "        self.mean_ = tf.reduce_mean(data_samples, axis=0, keepdims=True)\n",
        "        self.std_ = tf.math.reduce_std(data_samples, axis=0, keepdims=True)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return (inputs - self.mean_)/(self.std_ + keras.backend.epsilon())\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return super().compute_output_shape(input_shape)"
      ],
      "metadata": {
        "id": "muJGDJ4i8r78"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Standardization_layer = Standardization(input_shape=[28, 28])\n",
        "Standardization_layer.adapt(fashion_dataset_train)\n",
        "\n",
        "model = Sequential([\n",
        "                    layers.Flatten(input_shape=(28, 28)), \n",
        "                    Standardization(), \n",
        "                    layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "                    layers.BatchNormalization(), \n",
        "                    layers.Dense(200, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "                    layers.BatchNormalization(), \n",
        "                    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "                    layers.Dense(10, activation=\"softmax\")\n",
        "], name=\"fashion_mnist_model\")"
      ],
      "metadata": {
        "id": "ynR_4S3a_qZD",
        "outputId": "a6a3112f-5852-42d7-b911-e95fa270e0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-9f354de6b177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mStandardization_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mStandardization_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashion_dataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model = Sequential([\n\u001b[1;32m      5\u001b[0m                     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-7b5259a9c864>\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data_samples)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mStandardization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<PrefetchDataset shapes: ((None, 28, 28), (None,)), types: (tf.uint8, tf.int64)>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>) to a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wAc6oKfyAiVP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Ch-13(Data Pipelines).ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "81727fb6587a0e5418c3cf386f53a5fb924b641d49e181fa8e28403b9a38d60e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}