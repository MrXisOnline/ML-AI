{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqex3jKgs68E"
      },
      "source": [
        "## The Data API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4xtBXGixwEb",
        "outputId": "e7266f5c-fc1b-4ed8-8dde-7e71f1e6ab2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "X = tf.range(10)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_UW4K35yHm_",
        "outputId": "d1c2d24d-d2b4-45df-8b64-49c4a17d708a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_rn22doy0NU"
      },
      "source": [
        "### Chaining Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIm-O6xLzCRY",
        "outputId": "5ae57341-59f7-4c9b-9af6-89de68f794d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.repeat(3).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN7XXGxs2oYC",
        "outputId": "b33707ac-e97e-4740-f8ba-24a2f355b77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
            "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.map(lambda x: x*2)\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4PicldsV6WzI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\msi1\\AppData\\Local\\Temp/ipykernel_9424/643490874.py:1: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.unbatch()`.\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.apply(tf.data.experimental.unbatch())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for item in dataset.take(5):\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Shuffling the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 6 5 7 3 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 2 1 0 4 6 4], shape=(7,), dtype=int64)\n",
            "tf.Tensor([7 2 5 9 2 1 3], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 3 8 7 9 5 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 6], shape=(2,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "dataset = tf.data.Dataset.range(10).repeat(3)\n",
        "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target.reshape(-1, 1), \n",
        "                                                    random_state=42)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_mean, X_std = scaler.mean_, scaler.scale_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
        "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
        "    os.makedirs(housing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
        "    \n",
        "    filepaths = []\n",
        "    m = len(data)\n",
        "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(part_csv)\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = np.c_[X_train, y_train]\n",
        "test_data = np.c_[X_test, y_test]\n",
        "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
        "header = \",\".join(header_cols)\n",
        "\n",
        "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header=header, n_parts=20)\n",
        "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header=header, n_parts=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>MedianHouseValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.2143</td>\n",
              "      <td>37.0</td>\n",
              "      <td>5.288235</td>\n",
              "      <td>0.973529</td>\n",
              "      <td>860.0</td>\n",
              "      <td>2.529412</td>\n",
              "      <td>33.81</td>\n",
              "      <td>-118.12</td>\n",
              "      <td>2.285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.3468</td>\n",
              "      <td>42.0</td>\n",
              "      <td>6.364322</td>\n",
              "      <td>1.087940</td>\n",
              "      <td>957.0</td>\n",
              "      <td>2.404523</td>\n",
              "      <td>37.16</td>\n",
              "      <td>-121.98</td>\n",
              "      <td>2.799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.9191</td>\n",
              "      <td>36.0</td>\n",
              "      <td>6.110063</td>\n",
              "      <td>1.059748</td>\n",
              "      <td>711.0</td>\n",
              "      <td>2.235849</td>\n",
              "      <td>38.45</td>\n",
              "      <td>-122.69</td>\n",
              "      <td>1.830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.3703</td>\n",
              "      <td>32.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.990196</td>\n",
              "      <td>1159.0</td>\n",
              "      <td>2.272549</td>\n",
              "      <td>34.16</td>\n",
              "      <td>-118.41</td>\n",
              "      <td>4.658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.3684</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.795858</td>\n",
              "      <td>1.035503</td>\n",
              "      <td>706.0</td>\n",
              "      <td>2.088757</td>\n",
              "      <td>38.57</td>\n",
              "      <td>-121.33</td>\n",
              "      <td>1.500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
              "0  4.2143      37.0  5.288235   0.973529       860.0  2.529412     33.81   \n",
              "1  5.3468      42.0  6.364322   1.087940       957.0  2.404523     37.16   \n",
              "2  3.9191      36.0  6.110063   1.059748       711.0  2.235849     38.45   \n",
              "3  6.3703      32.0  6.000000   0.990196      1159.0  2.272549     34.16   \n",
              "4  2.3684      17.0  4.795858   1.035503       706.0  2.088757     38.57   \n",
              "\n",
              "   Longitude  MedianHouseValue  \n",
              "0    -118.12             2.285  \n",
              "1    -121.98             2.799  \n",
              "2    -122.69             1.830  \n",
              "3    -118.41             4.658  \n",
              "4    -121.33             1.500  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.read_csv(train_filepaths[0]).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
            "4.2143,37.0,5.288235294117647,0.9735294117647059,860.0,2.5294117647058822,33.81,-118.12,2.285\n",
            "5.3468,42.0,6.364321608040201,1.0879396984924623,957.0,2.4045226130653266,37.16,-121.98,2.799\n",
            "3.9191,36.0,6.110062893081761,1.059748427672956,711.0,2.2358490566037736,38.45,-122.69,1.83\n",
            "6.3703,32.0,6.0,0.9901960784313726,1159.0,2.272549019607843,34.16,-118.41,4.658\n"
          ]
        }
      ],
      "source": [
        "with open(train_filepaths[0]) as f:\n",
        "    for i in range(5):\n",
        "        print(f.readline(), end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Building an Input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_05.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_16.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_01.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_17.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_00.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_14.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_10.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_02.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_12.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_19.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_07.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_09.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_13.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_15.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_11.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_18.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_04.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_06.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_03.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets\\\\housing\\\\my_train_08.csv', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for filepath in filepath_dataset:\n",
        "    print(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_reader = 5\n",
        "dataset = filepath_dataset.interleave(\n",
        "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1), \n",
        "    cycle_length=n_reader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'3.3125,11.0,5.361736334405145,1.0578778135048232,1963.0,3.1559485530546625,38.69,-121.46,0.968'\n",
            "b'2.4524,41.0,5.340116279069767,1.188953488372093,1430.0,4.156976744186046,34.13,-117.32,0.704'\n",
            "b'5.8735,35.0,5.811638591117918,1.0566615620214395,1521.0,2.329249617151608,34.11,-118.63,4.481'\n",
            "b'3.8788,20.0,5.140068886337543,1.060849598163031,2656.0,3.049368541905855,37.13,-121.66,2.269'\n",
            "b'4.5893,39.0,5.711688311688311,1.0077922077922077,1025.0,2.6623376623376624,37.95,-122.07,1.9'\n"
          ]
        }
      ],
      "source": [
        "for line in dataset.take(5):\n",
        "    print(line.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Processing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_inputs = 8\n",
        "\n",
        "def preprocess(line):\n",
        "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
        "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
        "    x = tf.stack(fields[:-1])\n",
        "    y = tf.stack(fields[-1:])\n",
        "    return (x - X_mean)/X_std, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 0.17648865,  0.66640687, -0.06085434, -0.2811182 , -0.49654418,\n",
              "        -0.04828325, -0.86074144,  0.73099613], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.285], dtype=float32)>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess(b'4.2143,37.0,5.288235294117647,0.9735294117647059,860.0,2.5294117647058822,33.81,-118.12,2.285')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def csv_reader_dataset(filepaths, repeat=1, n_readers=5, \n",
        "                       n_read_threads=None, shuffle_buffer_size=10000, \n",
        "                       n_parse_threads=5, batch_size=32):\n",
        "    dataset = tf.data.Dataset.list_files(filepaths)\n",
        "    dataset = dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1), \n",
        "                                 cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
        "    return dataset.batch(batch_size).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   4.2143    ,   37.        ,    5.28823529,    0.97352941,\n",
              "        860.        ,    2.52941176,   33.81      , -118.12      ])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using Dataset with tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set = csv_reader_dataset(train_filepaths)\n",
        "test_set = csv_reader_dataset(test_filepaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "484/484 [==============================] - 2s 2ms/step - loss: 0.5514 - mae: 0.5358 - val_loss: 0.5612 - val_mae: 0.5202\n",
            "Epoch 2/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.4150 - mae: 0.4621 - val_loss: 0.3551 - val_mae: 0.4313\n",
            "Epoch 3/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3963 - mae: 0.4492 - val_loss: 0.4187 - val_mae: 0.4794\n",
            "Epoch 4/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3832 - mae: 0.4426 - val_loss: 0.5200 - val_mae: 0.4968\n",
            "Epoch 5/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3792 - mae: 0.4359 - val_loss: 0.4806 - val_mae: 0.5197\n",
            "Epoch 6/100\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.3643 - mae: 0.4304 - val_loss: 0.3219 - val_mae: 0.4059\n",
            "Epoch 7/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3563 - mae: 0.4240 - val_loss: 0.4373 - val_mae: 0.4445\n",
            "Epoch 8/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3542 - mae: 0.4233 - val_loss: 0.4294 - val_mae: 0.4442\n",
            "Epoch 9/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3489 - mae: 0.4207 - val_loss: 0.4071 - val_mae: 0.4907\n",
            "Epoch 10/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3555 - mae: 0.4265 - val_loss: 0.3989 - val_mae: 0.4681\n",
            "Epoch 11/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3401 - mae: 0.4151 - val_loss: 0.3602 - val_mae: 0.3993\n",
            "Epoch 12/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3499 - mae: 0.4227 - val_loss: 0.3358 - val_mae: 0.3846\n",
            "Epoch 13/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3502 - mae: 0.4231 - val_loss: 0.4278 - val_mae: 0.5148\n",
            "Epoch 14/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3369 - mae: 0.4141 - val_loss: 0.3552 - val_mae: 0.4362\n",
            "Epoch 15/100\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.3415 - mae: 0.4167 - val_loss: 0.4747 - val_mae: 0.4915\n",
            "Epoch 16/100\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.3362 - mae: 0.4117 - val_loss: 0.4302 - val_mae: 0.4429\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x24bab27f2b0>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers, callbacks\n",
        "model = keras.Sequential([keras.layers.Dense(100, activation=\"relu\"), \n",
        "                          keras.layers.BatchNormalization(), \n",
        "                          keras.layers.Dense(200, activation=\"relu\"), \n",
        "                          keras.layers.BatchNormalization(), \n",
        "                          keras.layers.Dense(10, activation=\"relu\"), \n",
        "                          keras.layers.BatchNormalization(), \n",
        "                          keras.layers.Dense(1)])\n",
        "model.compile(loss=\"mse\", optimizer=optimizers.SGD(learning_rate=1e-2, nesterov=True, \n",
        "                                                   momentum=0.93), metrics=[\"mae\"])\n",
        "model.fit(train_set, epochs=100, \n",
        "          validation_data=test_set, \n",
        "          callbacks=[callbacks.EarlyStopping(patience=10, \n",
        "                                             restore_best_weights=True, \n",
        "                                             monitor=\"val_loss\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 1ms/step - loss: 0.3219 - mae: 0.4059\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.3218575417995453, 0.4059430658817291]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.9361138 ],\n",
              "       [0.9133055 ],\n",
              "       [2.434945  ],\n",
              "       [2.3590877 ],\n",
              "       [1.2241691 ],\n",
              "       [2.530606  ],\n",
              "       [4.6654253 ],\n",
              "       [2.7495708 ],\n",
              "       [0.93317914],\n",
              "       [2.0079727 ],\n",
              "       [3.4963975 ],\n",
              "       [2.6451511 ],\n",
              "       [2.0391731 ],\n",
              "       [1.194759  ],\n",
              "       [1.3651963 ],\n",
              "       [5.110795  ],\n",
              "       [3.0155265 ],\n",
              "       [1.4997151 ],\n",
              "       [2.5836954 ],\n",
              "       [1.0702391 ],\n",
              "       [2.1778834 ],\n",
              "       [1.0713279 ],\n",
              "       [0.9217081 ],\n",
              "       [2.8020098 ],\n",
              "       [1.7460865 ],\n",
              "       [2.945178  ],\n",
              "       [1.7114737 ],\n",
              "       [2.0891716 ],\n",
              "       [2.305393  ],\n",
              "       [2.0068982 ],\n",
              "       [1.7338572 ],\n",
              "       [2.7331486 ],\n",
              "       [3.7790947 ],\n",
              "       [0.9678383 ],\n",
              "       [2.425568  ],\n",
              "       [2.6264007 ],\n",
              "       [1.9635203 ],\n",
              "       [1.2492391 ],\n",
              "       [1.0608734 ],\n",
              "       [2.624142  ],\n",
              "       [2.179114  ],\n",
              "       [1.9583938 ],\n",
              "       [0.8439145 ],\n",
              "       [1.301668  ],\n",
              "       [1.7930489 ],\n",
              "       [1.8987231 ],\n",
              "       [1.1935368 ],\n",
              "       [2.2147698 ],\n",
              "       [3.7301488 ],\n",
              "       [3.182203  ],\n",
              "       [2.209907  ],\n",
              "       [2.4681718 ],\n",
              "       [2.8485055 ],\n",
              "       [2.186312  ],\n",
              "       [1.9342339 ],\n",
              "       [1.6700764 ],\n",
              "       [1.2814641 ],\n",
              "       [2.0246856 ],\n",
              "       [2.1582336 ],\n",
              "       [2.3998184 ],\n",
              "       [2.0721788 ],\n",
              "       [2.1509278 ],\n",
              "       [2.8144794 ],\n",
              "       [2.6759672 ],\n",
              "       [2.6319306 ],\n",
              "       [2.6405406 ],\n",
              "       [1.7776796 ],\n",
              "       [2.1983848 ],\n",
              "       [2.9530194 ],\n",
              "       [5.768956  ],\n",
              "       [2.238689  ],\n",
              "       [1.4894311 ],\n",
              "       [1.553855  ],\n",
              "       [4.4035435 ],\n",
              "       [2.30749   ],\n",
              "       [1.8487935 ],\n",
              "       [1.7697408 ],\n",
              "       [1.4272227 ],\n",
              "       [1.5867543 ],\n",
              "       [1.890112  ],\n",
              "       [3.5849648 ],\n",
              "       [2.646664  ],\n",
              "       [2.9345837 ],\n",
              "       [1.131978  ],\n",
              "       [1.3661853 ],\n",
              "       [1.4781072 ],\n",
              "       [3.4416242 ],\n",
              "       [0.8668957 ],\n",
              "       [2.9001527 ],\n",
              "       [2.401717  ],\n",
              "       [1.9755334 ],\n",
              "       [1.8014824 ],\n",
              "       [1.6597252 ],\n",
              "       [1.5336657 ],\n",
              "       [3.0155883 ],\n",
              "       [1.1764789 ]], dtype=float32)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_set = test_set.take(3).map(lambda X, y: X)\n",
        "model.predict(new_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom function to train model\n",
        "\n",
        "@tf.function\n",
        "def train(model, optimizers, loss_fn, n_epochs, **kwargs):\n",
        "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs)\n",
        "    for X_batch, y_batch in train_set:\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_batch)\n",
        "            main_loss = loss_fn(y_batch, y_pred)\n",
        "            loss = tf.add_n([main_loss] + model.losses)\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The TFRecord Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating a TFRecord dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And, This is the second Record.', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
        "    f.write(b\"This is the first record\")\n",
        "    f.write(b\"And, This is the second Record.\")\n",
        "filepaths = [\"my_data.tfrecord\"]\n",
        "dataset = tf.data.TFRecordDataset(filepaths)\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compressed TFRecord Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'This is First One', shape=(), dtype=string)\n",
            "tf.Tensor(b'And the Another One', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "with tf.io.TFRecordWriter(\"my_compressed_data.tfrecord\", options) as f:\n",
        "    f.write(\"This is First One\")\n",
        "    f.write(\"And the Another One\")\n",
        "dataset = tf.data.TFRecordDataset([\"my_compressed_data.tfrecord\"], \n",
        "                                  compression_type=\"GZIP\")\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Protocol Buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.train import BytesList, FloatList, Int64List\n",
        "from tensorflow.train import Feature, Features, Example\n",
        "\n",
        "person_example = Example(\n",
        "    features=Features(\n",
        "        feature={\n",
        "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])), \n",
        "            \"id\": Feature(int64_list=Int64List(value=[123])), \n",
        "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", \n",
        "                                                          b\"c@d.com\"]))\n",
        "        }))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.io.TFRecordWriter(\"my_contact.tfrecord\") as f:\n",
        "    f.write(person_example.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading and Parsing Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_description = {\n",
        "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"), \n",
        "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0), \n",
        "    \"emails\": tf.io.VarLenFeature(tf.string),\n",
        "}\n",
        "\n",
        "for serialized_example in tf.data.TFRecordDataset([\"my_contact.tfrecord\"]):\n",
        "    parsed_example = tf.io.parse_single_example(serialized_example, \n",
        "                                               feature_description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_example[\"emails\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = tf.data.TFRecordDataset([\"my_contact.tfrecord\"]).batch(10)\n",
        "for serialized_example in dataset:\n",
        "    parsed_examples = tf.io.parse_example(serialized_example, \n",
        "                                          feature_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling Lists of List Using SequenceExample ProtoBuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "FeatureList = tf.train.FeatureList\n",
        "FeatureLists = tf.train.FeatureLists\n",
        "SequenceExample = tf.train.SequenceExample\n",
        "\n",
        "context = Features(feature={\n",
        "    \"author_id\": Feature(int64_list=Int64List(value=[123])), \n",
        "    \"title\": Feature(bytes_list=BytesList(value=[b\"A\", b\"desert\", b\"place\", b\".\"])), \n",
        "    \"pub_date\": Feature(int64_list=Int64List(value=[1623, 12, 25]))\n",
        "})\n",
        "\n",
        "content = [[\"When\", \"shall\", \"we\", \"three\", \"meet\", \"again\", \"?\"], \n",
        "           [\"In\", \"thunder\", \",\", \"lightning\", \",\", \"or\", \"in\", \"rain\", \"?\"]]\n",
        "comments = [[\"When\", \"the\", \"hurlyburly\", \"'s\", \"done\", \".\"], \n",
        "            [\"When\", \"the\", \"battle\", \"'s\", \"lost\", \"and\", \"won\", \".\"]]\n",
        "\n",
        "def words_to_feature(words):\n",
        "    return Feature(bytes_list=BytesList(value=[word.encode(\"utf-8\") for word in words]))\n",
        "\n",
        "content_features = [words_to_feature(sentence) for sentence in content]\n",
        "comment_features = [words_to_feature(comment) for comment in comments]\n",
        "\n",
        "sequence_example = SequenceExample(\n",
        "    context=context, \n",
        "    feature_lists=FeatureLists(feature_list={\n",
        "        \"content\": FeatureList(feature=content_features), \n",
        "        \"comments\": FeatureList(feature=comment_features)\n",
        "    })\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "context_feature_descriptions = {\n",
        "    \"author_id\": tf.io.FixedLenFeature([], tf.int64, default_value=0), \n",
        "    \"title\": tf.io.VarLenFeature(tf.string), \n",
        "    \"pub_data\": tf.io.FixedLenFeature([3], tf.int64, default_value=[0, 0, 0]), \n",
        "}\n",
        "\n",
        "sequence_feature_descriptions = {\n",
        "    \"content\": tf.io.VarLenFeature(tf.string), \n",
        "    \"comments\": tf.io.VarLenFeature(tf.string), \n",
        "}\n",
        "\n",
        "serialized_sequence_example = sequence_example.SerializeToString()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
        "    serialized_sequence_example, context_feature_descriptions, \n",
        "    sequence_feature_descriptions)\n",
        "parsed_content = tf.RaggedTensor.from_sparse(parsed_feature_lists[\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x274a6b47af0>,\n",
              " 'author_id': <tf.Tensor: shape=(), dtype=int64, numpy=123>,\n",
              " 'pub_data': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 0, 0], dtype=int64)>}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'A', b'desert', b'place', b'.'], dtype=object)>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_context[\"title\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'comments': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x274ade08160>,\n",
              " 'content': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x274ae02c9d0>}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_feature_lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'When', b'shall', b'we', b'three', b'meet', b'again', b'?'], [b'In', b'thunder', b',', b'lightning', b',', b'or', b'in', b'rain', b'?']]>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing the Input Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Standardization of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "means = np.mean(X_train, axis=0, keepdims=True)\n",
        "stds = np.std(X_train, axis=0, keepdims=True)\n",
        "eps = keras.backend.epsilon()\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Lambda(lambda inputs: (input - means) / (stds + eps)), \n",
        "    keras.layers.Dense(10), \n",
        "    keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StandardScaler(keras.layers.Layer):\n",
        "    def adapt(self, data_samples):\n",
        "        self.means_ = np.mean(data_samples, axis=0, keepdims=True)\n",
        "        self.std_ = np.std(data_samples, axis=0, keepdims=True)\n",
        "    def call(self, inputs):\n",
        "        return (inputs - self.means_)/(self.std_ + keras.backend.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "std_layer = StandardScaler()\n",
        "std_layer.adapt(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(std_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding Categorical Features Using One-Hot Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"dataset\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "fetch_housing_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.23     37.88                41.0        880.0           129.0   \n",
              "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
              "2    -122.24     37.85                52.0       1467.0           190.0   \n",
              "3    -122.25     37.85                52.0       1274.0           235.0   \n",
              "4    -122.25     37.85                52.0       1627.0           280.0   \n",
              "\n",
              "   population  households  median_income  median_house_value ocean_proximity  \n",
              "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
              "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
              "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
              "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
              "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "housing = load_housing_data()\n",
        "housing.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### in github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "housing_median_age = tf.feature_column.numeric_column(\"housing_median_age\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "age_mean, age_std = X_mean[1], X_std[1]\n",
        "housing_median_age = tf.feature_column.numeric_column(\n",
        "    \"housing_median_age\", normalizer_fn=lambda x: (x - age_mean)/age_std\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "median_income = tf.feature_column.numeric_column(\"median_income\")\n",
        "bucketized_income = tf.feature_column.bucketized_column(\n",
        "    median_income, boundaries=[1.5, 3., 4.5, 6.]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BucketizedColumn(source_column=NumericColumn(key='median_income', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(1.5, 3.0, 4.5, 6.0))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bucketized_income"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "ocean_prox_vocab = [\"<1H OCEAN\", \"INLAND\", \"ISLAND\", \"NEAR BAY\", \"NEAR OCEAN\"]\n",
        "ocean_proximity = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    \"ocean_proximity\", ocean_prox_vocab\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VocabularyListCategoricalColumn(key='ocean_proximity', vocabulary_list=('<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ocean_proximity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
        "indices = tf.range(len(vocab), dtype=tf.int64)\n",
        "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
        "num_oov_buckets = 2\n",
        "table= tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets=num_oov_buckets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab)+num_oov_buckets)\n",
        "cat_one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding Categorical Features Using Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dim = 2\n",
        "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
        "embedding_matrix = tf.Variable(embed_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
              "array([[0.76847804, 0.24180698],\n",
              "       [0.53683543, 0.04629397],\n",
              "       [0.62679946, 0.00700271],\n",
              "       [0.723444  , 0.20266068],\n",
              "       [0.11565375, 0.5128256 ],\n",
              "       [0.3641951 , 0.01004899],\n",
              "       [0.14566624, 0.851266  ]], dtype=float32)>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[0.723444  , 0.20266068],\n",
              "       [0.3641951 , 0.01004899],\n",
              "       [0.53683543, 0.04629397],\n",
              "       [0.53683543, 0.04629397]], dtype=float32)>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding = keras.layers.Embedding(input_dim=len(vocab)+num_oov_buckets, \n",
        "                                   output_dim=embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[-0.03529421, -0.03804005],\n",
              "       [-0.03340534,  0.03543509],\n",
              "       [-0.03967112, -0.04716682],\n",
              "       [-0.03967112, -0.04716682]], dtype=float32)>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding(cat_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "regular_inputs = keras.layers.Input(shape=[8])\n",
        "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
        "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
        "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
        "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
        "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
        "model = keras.models.Model(inputs=[regular_inputs, categories], outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Keras Preprocessing Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalization = layers.Normalization()\n",
        "discretization = layers.Discretization()\n",
        "# pipeline = layers.PreprocessingStage([normalization, discretization])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TF Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_transform as tft\n",
        "\n",
        "def preprocess(inputs):\n",
        "    median_age = inputs[\"housing_median_age\"]\n",
        "    ocean_proximity = inputs[\"ocean_proximity\"]\n",
        "    standardized_age = tft.scale_to_z_score(median_age)\n",
        "    ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
        "    return {\n",
        "        \"standardized_median_age\": standardized_age, \n",
        "        \"ocean_proximity_id\": ocean_proximity_id\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Tensorflow Dataset (TFDS) Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset = tfds.load(name=\"mnist\")\n",
        "mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "mnist_train = mnist_train.shuffle(10000).batch(32)\n",
        "for item in mnist_train:\n",
        "    images = item[\"image\"]\n",
        "    labels = item[\"label\"]\n",
        "    for index in range(5):\n",
        "        plt.subplot(1, 5, index + 1)\n",
        "        image = images[index, ..., 0]\n",
        "        label = labels[index].numpy()\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.title(label)\n",
        "        plt.axis(\"off\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "mnist_train = mnist_train.map(lambda item: (item[\"image\"], item[\"label\"]))\n",
        "mnist_train = mnist_train.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Going all this while loading\n",
        "dataset = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
        "mnist_train = dataset[\"train\"].prefetch(1)\n",
        "mnist_test = dataset[\"test\"].prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 4ms/step - loss: 0.2149 - accuracy: 0.9339 - val_loss: 0.1012 - val_accuracy: 0.9690\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1003 - accuracy: 0.9688 - val_loss: 0.1040 - val_accuracy: 0.9684\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0722 - accuracy: 0.9770 - val_loss: 0.0965 - val_accuracy: 0.9740\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0516 - accuracy: 0.9826 - val_loss: 0.0978 - val_accuracy: 0.9751\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.1245 - val_accuracy: 0.9703\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0341 - accuracy: 0.9886 - val_loss: 0.1383 - val_accuracy: 0.9715\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0293 - accuracy: 0.9898 - val_loss: 0.1127 - val_accuracy: 0.9770\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.1068 - val_accuracy: 0.9772\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x215a09568e0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)), \n",
        "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    keras.layers.BatchNormalization(), \n",
        "    keras.layers.Dense(200, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    keras.layers.BatchNormalization(), \n",
        "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "              optimizer=\"adam\", \n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(mnist_train, epochs=10, \n",
        "          validation_data=mnist_test, \n",
        "          callbacks=[keras.callbacks.EarlyStopping(patience=5, \n",
        "                                                   restore_best_weights=True)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers, initializers, losses, Sequential, datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "r_in = random.randint(0, 59999)\n",
        "plt.imshow(X_train[r_in], cmap=plt.cm.binary)\n",
        "plt.title(y_train[r_in], c=\"r\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.train import BytesList, Int64List, Feature, Features, Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for index in range(X_train.shape[0]):\n",
        "    data = tf.io.encode_jpeg(X_train[index])\n",
        "    label = y_train[index]\n",
        "    image_ex = Example(features=Features(feature={\n",
        "        \"image\": Feature(bytes_list=BytesList(value=[data.numpy()])), \n",
        "        \"label\": Feature(int64_list=Int64List(value=[label]))\n",
        "    }))\n",
        "    with tf.io.TFRecordWriter(\"my_fashion_mnist.tfrecord\") as f:\n",
        "        f.write(image_ex.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Ch-13(Data Pipelines).ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "81727fb6587a0e5418c3cf386f53a5fb924b641d49e181fa8e28403b9a38d60e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
