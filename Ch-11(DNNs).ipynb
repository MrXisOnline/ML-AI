{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing/Exploding Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812ceb670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", \n",
    "                    kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dadb50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2, \n",
    "                                                mode=\"fan_avg\", \n",
    "                                                distribution=\"uniform\")\n",
    "keras.layers.Dense(10, activation=\"relu\", \n",
    "                    kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dadd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using leaky relu\n",
    "leaky_relu = keras.layers.LeakyReLU(alpha=0.2)\n",
    "keras.layers.Dense(10, activation=leaky_relu, \n",
    "                    kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dad970>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\", \n",
    "                    kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"elu\", \n",
    "                        kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"elu\", \n",
    "                        kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 784)              3136      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization_3/gamma:0', True),\n",
       " ('batch_normalization_3/beta:0', True),\n",
       " ('batch_normalization_3/moving_mean:0', False),\n",
       " ('batch_normalization_3/moving_variance:0', False)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SG704\\AppData\\Local\\Temp/ipykernel_12816/3873162892.py:1: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  model.layers[1].updates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, \n",
    "        kernel_initializer=\"he_normal\", \n",
    "        use_bias=False), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Activation(\"elu\"), \n",
    "    keras.layers.Dense(100, \n",
    "        kernel_initializer=\"he_normal\", \n",
    "        use_bias=False), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Activation(\"elu\"), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "def get_data_without_5_6(data, labels):\n",
    "    new_data, new_labels = [], []\n",
    "    for i, label in enumerate(labels):\n",
    "        if (label != 5) & (label != 6):\n",
    "            if label > 5:\n",
    "                new_labels.append(labels[i]-2)\n",
    "            else:\n",
    "                new_labels.append(labels[i])\n",
    "            new_data.append(data[i])\n",
    "    return np.array(new_data), np.array(new_labels)\n",
    "        \n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_A, y_train_A = get_data_without_5_6(X_train, y_train)\n",
    "X_test_A, y_test_A = get_data_without_5_6(X_test, y_test)\n",
    "X_train_A, X_val_A, y_train_A, y_val_A = X_train_A[:30000], X_train_A[30000:], y_train_A[:30000], y_train_A[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 5s 4ms/step - loss: 0.3892 - accuracy: 0.8676 - val_loss: 0.2706 - val_accuracy: 0.9073\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2725 - accuracy: 0.9046 - val_loss: 0.2450 - val_accuracy: 0.9166\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2371 - accuracy: 0.9168 - val_loss: 0.2353 - val_accuracy: 0.9197\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2207 - accuracy: 0.9227 - val_loss: 0.2266 - val_accuracy: 0.9239\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2028 - accuracy: 0.9296 - val_loss: 0.2209 - val_accuracy: 0.9247\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.1880 - accuracy: 0.9342 - val_loss: 0.2229 - val_accuracy: 0.9253\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1788 - accuracy: 0.9373 - val_loss: 0.2173 - val_accuracy: 0.9248\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1706 - accuracy: 0.9405 - val_loss: 0.2149 - val_accuracy: 0.9267\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1606 - accuracy: 0.9431 - val_loss: 0.2107 - val_accuracy: 0.9294\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1492 - accuracy: 0.9468 - val_loss: 0.2119 - val_accuracy: 0.9301\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1447 - accuracy: 0.9484 - val_loss: 0.2129 - val_accuracy: 0.9306\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1390 - accuracy: 0.9504 - val_loss: 0.2119 - val_accuracy: 0.9304\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1304 - accuracy: 0.9529 - val_loss: 0.2078 - val_accuracy: 0.9310\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1260 - accuracy: 0.9555 - val_loss: 0.2171 - val_accuracy: 0.9316\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1195 - accuracy: 0.9568 - val_loss: 0.2111 - val_accuracy: 0.9321\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1141 - accuracy: 0.9598 - val_loss: 0.2136 - val_accuracy: 0.9320\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1068 - accuracy: 0.9613 - val_loss: 0.2160 - val_accuracy: 0.9317\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.1044 - accuracy: 0.9636 - val_loss: 0.2184 - val_accuracy: 0.9315\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.0986 - accuracy: 0.9642 - val_loss: 0.2218 - val_accuracy: 0.9300\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0962 - accuracy: 0.9648 - val_loss: 0.2271 - val_accuracy: 0.9293\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0942 - accuracy: 0.9660 - val_loss: 0.2185 - val_accuracy: 0.9332\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0847 - accuracy: 0.9708 - val_loss: 0.2198 - val_accuracy: 0.9347\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0866 - accuracy: 0.9704 - val_loss: 0.2274 - val_accuracy: 0.9325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a46bfaf5e0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_A = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=\"accuracy\")\n",
    "model_A.fit(X_train_A, y_train_A, epochs=100, \n",
    "            validation_data=(X_val_A, y_val_A), \n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                     patience=10, \n",
    "                                                     restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 1ms/step - loss: 0.2616 - accuracy: 0.9186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2615906894207001, 0.918624997138977]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A.evaluate(X_test_A, y_test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_withonly_5_6(data, labels):\n",
    "    new_data, new_labels = [], []\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == 5:\n",
    "            new_data.append(data[i])\n",
    "            new_labels.append(1)\n",
    "        elif label == 6:\n",
    "            new_data.append(data[i])\n",
    "            new_labels.append(0)\n",
    "    return np.array(new_data), np.array(new_labels)\n",
    "\n",
    "X_train_B, y_train_B = get_data_withonly_5_6(X_train, y_train)\n",
    "X_test_B, y_test_B = get_data_withonly_5_6(X_test, y_test)\n",
    "X_train_B, X_val_B, y_train_B, y_val_B = X_train_B[:10000], X_train_B[10000:], y_train_B[:10000], y_train_B[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 2s 3ms/step - loss: 0.1158 - accuracy: 0.9719 - val_loss: 0.0414 - val_accuracy: 0.9960\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.9937 - val_loss: 0.0237 - val_accuracy: 0.9955\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9964 - val_loss: 0.0173 - val_accuracy: 0.9965\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0212 - accuracy: 0.9956 - val_loss: 0.0146 - val_accuracy: 0.9970\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9970 - val_loss: 0.0136 - val_accuracy: 0.9960\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: 0.0124 - val_accuracy: 0.9960\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.0118 - val_accuracy: 0.9965\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0116 - val_accuracy: 0.9965\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.0110 - val_accuracy: 0.9970\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0121 - val_accuracy: 0.9970\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.0110 - val_accuracy: 0.9970\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 0.0130 - val_accuracy: 0.9970\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0105 - val_accuracy: 0.9975\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0103 - val_accuracy: 0.9970\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0106 - val_accuracy: 0.9970\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0107 - val_accuracy: 0.9970\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0095 - val_accuracy: 0.9985\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0100 - val_accuracy: 0.9985\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0107 - val_accuracy: 0.9980\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0095 - val_accuracy: 0.9985\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0091 - val_accuracy: 0.9990\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0097 - val_accuracy: 0.9985\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0101 - val_accuracy: 0.9985\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0109 - val_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0121 - val_accuracy: 0.9965\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0134 - val_accuracy: 0.9965\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0120 - val_accuracy: 0.9975\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0121 - val_accuracy: 0.9980\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0105 - val_accuracy: 0.9980\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0106 - val_accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a46bd6a1c0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model_B.compile(loss=\"binary_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=\"accuracy\")\n",
    "model_B.fit(X_train_B, y_train_B, epochs=100, \n",
    "            validation_data=(X_val_B, y_val_B), \n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                     patience=10, \n",
    "                                                     restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005876780953258276, 0.9980000257492065]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25178515911102295, 0.9257500171661377]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A.evaluate(X_test_A, y_test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = keras.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", \n",
    "                     optimizer=\"sgd\", \n",
    "                     metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.1218 - accuracy: 0.9689 - val_loss: 0.0540 - val_accuracy: 0.9915\n",
      "Epoch 2/4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0376 - accuracy: 0.9948 - val_loss: 0.0357 - val_accuracy: 0.9945\n",
      "Epoch 3/4\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9957 - val_loss: 0.0292 - val_accuracy: 0.9960\n",
      "Epoch 4/4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.0258 - val_accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "history_b_on_A = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, \n",
    "                                  validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model_B_on_A.layers"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af68422bec32ee5a6de64dec1179cbe01bf4f7813cec231e0768ec582c2e4b4a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
