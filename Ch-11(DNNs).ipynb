{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing/Exploding Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812ceb670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", \n",
    "                    kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dadb50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2, \n",
    "                                                mode=\"fan_avg\", \n",
    "                                                distribution=\"uniform\")\n",
    "keras.layers.Dense(10, activation=\"relu\", \n",
    "                    kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dadd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using leaky relu\n",
    "leaky_relu = keras.layers.LeakyReLU(alpha=0.2)\n",
    "keras.layers.Dense(10, activation=leaky_relu, \n",
    "                    kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dad970>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\", \n",
    "                    kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"elu\", \n",
    "                        kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"elu\", \n",
    "                        kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 784)              3136      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization_3/gamma:0', True),\n",
       " ('batch_normalization_3/beta:0', True),\n",
       " ('batch_normalization_3/moving_mean:0', False),\n",
       " ('batch_normalization_3/moving_variance:0', False)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SG704\\AppData\\Local\\Temp/ipykernel_12816/3873162892.py:1: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  model.layers[1].updates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, \n",
    "        kernel_initializer=\"he_normal\", \n",
    "        use_bias=False), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Activation(\"elu\"), \n",
    "    keras.layers.Dense(100, \n",
    "        kernel_initializer=\"he_normal\", \n",
    "        use_bias=False), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Activation(\"elu\"), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train, X_val, y_train, y_val = X_train[:50000], X_train[50000:], y_train[:50000], y_train[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 0.3793 - accuracy: 0.8871 - val_loss: 0.3579 - val_accuracy: 0.9419\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1952 - accuracy: 0.9426 - val_loss: 0.3219 - val_accuracy: 0.9553\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1505 - accuracy: 0.9547 - val_loss: 0.3175 - val_accuracy: 0.9587\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1237 - accuracy: 0.9624 - val_loss: 0.5060 - val_accuracy: 0.9618\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1040 - accuracy: 0.9692 - val_loss: 0.4051 - val_accuracy: 0.9648\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0913 - accuracy: 0.9734 - val_loss: 0.3101 - val_accuracy: 0.9639\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0780 - accuracy: 0.9778 - val_loss: 0.2976 - val_accuracy: 0.9657\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0721 - accuracy: 0.9783 - val_loss: 0.1894 - val_accuracy: 0.9686\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0636 - accuracy: 0.9806 - val_loss: 0.3316 - val_accuracy: 0.9685\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0583 - accuracy: 0.9830 - val_loss: 0.3186 - val_accuracy: 0.9684\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0500 - accuracy: 0.9857 - val_loss: 0.3610 - val_accuracy: 0.9682\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.3900 - val_accuracy: 0.9681\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0441 - accuracy: 0.9869 - val_loss: 0.4342 - val_accuracy: 0.9688\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0397 - accuracy: 0.9884 - val_loss: 0.3132 - val_accuracy: 0.9702\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0366 - accuracy: 0.9896 - val_loss: 0.3952 - val_accuracy: 0.9695\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0346 - accuracy: 0.9898 - val_loss: 0.4889 - val_accuracy: 0.9690\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0308 - accuracy: 0.9913 - val_loss: 0.3535 - val_accuracy: 0.9708\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0303 - accuracy: 0.9910 - val_loss: 0.4184 - val_accuracy: 0.9704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e51e6e85b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model_A = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=\"accuracy\")\n",
    "model_A.fit(X_train, y_train, epochs=100, \n",
    "            validation_data=(X_val, y_val), \n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                     patience=10, \n",
    "                                                     restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3781 - accuracy: 0.9658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3781094253063202, 0.9657999873161316]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = keras.Sequential(model_A.la)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af68422bec32ee5a6de64dec1179cbe01bf4f7813cec231e0768ec582c2e4b4a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
