{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing/Exploding Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812ceb670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", \n",
    "                    kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dadb50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2, \n",
    "                                                mode=\"fan_avg\", \n",
    "                                                distribution=\"uniform\")\n",
    "keras.layers.Dense(10, activation=\"relu\", \n",
    "                    kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dadd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using leaky relu\n",
    "leaky_relu = keras.layers.LeakyReLU(alpha=0.2)\n",
    "keras.layers.Dense(10, activation=leaky_relu, \n",
    "                    kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dad970>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\", \n",
    "                    kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"elu\", \n",
    "                        kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"elu\", \n",
    "                        kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 784)              3136      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization_3/gamma:0', True),\n",
       " ('batch_normalization_3/beta:0', True),\n",
       " ('batch_normalization_3/moving_mean:0', False),\n",
       " ('batch_normalization_3/moving_variance:0', False)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SG704\\AppData\\Local\\Temp/ipykernel_12816/3873162892.py:1: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  model.layers[1].updates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, \n",
    "        kernel_initializer=\"he_normal\", \n",
    "        use_bias=False), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Activation(\"elu\"), \n",
    "    keras.layers.Dense(100, \n",
    "        kernel_initializer=\"he_normal\", \n",
    "        use_bias=False), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Activation(\"elu\"), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "def get_data_without_5_6(data, labels):\n",
    "    new_data, new_labels = [], []\n",
    "    for i, label in enumerate(labels):\n",
    "        if (label != 5) & (label != 6):\n",
    "            if label > 5:\n",
    "                new_labels.append(labels[i]-2)\n",
    "            else:\n",
    "                new_labels.append(labels[i])\n",
    "            new_data.append(data[i])\n",
    "    return np.array(new_data), np.array(new_labels)\n",
    "        \n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_A, y_train_A = get_data_without_5_6(X_train, y_train)\n",
    "X_test_A, y_test_A = get_data_without_5_6(X_test, y_test)\n",
    "X_train_A, X_val_A = X_train_A[:30000], X_train_A[30000:]\n",
    "y_train_A, y_val_A = y_train_A[:30000], y_train_A[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 7s 5ms/step - loss: 0.3977 - accuracy: 0.8659 - val_loss: 0.2692 - val_accuracy: 0.9088\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.2771 - accuracy: 0.9043 - val_loss: 0.2425 - val_accuracy: 0.9173\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2402 - accuracy: 0.9177 - val_loss: 0.2338 - val_accuracy: 0.9207\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2150 - accuracy: 0.9246 - val_loss: 0.2207 - val_accuracy: 0.9251\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2044 - accuracy: 0.9281 - val_loss: 0.2209 - val_accuracy: 0.9233\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1892 - accuracy: 0.9326 - val_loss: 0.2141 - val_accuracy: 0.9277\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1761 - accuracy: 0.9371 - val_loss: 0.2168 - val_accuracy: 0.9251\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1654 - accuracy: 0.9397 - val_loss: 0.2088 - val_accuracy: 0.9282\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1579 - accuracy: 0.9439 - val_loss: 0.2177 - val_accuracy: 0.92680s - loss: 0\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1511 - accuracy: 0.9464 - val_loss: 0.2061 - val_accuracy: 0.9316\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1448 - accuracy: 0.9490 - val_loss: 0.2025 - val_accuracy: 0.9320\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1380 - accuracy: 0.9515 - val_loss: 0.2066 - val_accuracy: 0.9319\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1313 - accuracy: 0.9533 - val_loss: 0.2161 - val_accuracy: 0.9277\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1260 - accuracy: 0.9557 - val_loss: 0.2042 - val_accuracy: 0.9331\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1211 - accuracy: 0.9565 - val_loss: 0.2101 - val_accuracy: 0.9299\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1123 - accuracy: 0.9605 - val_loss: 0.2117 - val_accuracy: 0.9294\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1090 - accuracy: 0.9610 - val_loss: 0.2098 - val_accuracy: 0.9306\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1025 - accuracy: 0.9633 - val_loss: 0.2136 - val_accuracy: 0.9303\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0990 - accuracy: 0.9650 - val_loss: 0.2125 - val_accuracy: 0.9317\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0943 - accuracy: 0.9668 - val_loss: 0.2237 - val_accuracy: 0.9288\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0920 - accuracy: 0.9662 - val_loss: 0.2159 - val_accuracy: 0.9317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24762e9e580>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_A = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=\"accuracy\")\n",
    "model_A.fit(X_train_A, y_train_A, epochs=100, \n",
    "            validation_data=(X_val_A, y_val_A), \n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                     patience=10, \n",
    "                                                     restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2272 - accuracy: 0.9243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22721777856349945, 0.9242500066757202]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A.evaluate(X_test_A, y_test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_withonly_5_6(data, labels):\n",
    "    new_data, new_labels = [], []\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == 5:\n",
    "            new_data.append(data[i])\n",
    "            new_labels.append(1)\n",
    "        elif label == 6:\n",
    "            new_data.append(data[i])\n",
    "            new_labels.append(0)\n",
    "    return np.array(new_data), np.array(new_labels)\n",
    "\n",
    "X_train_B, y_train_B = get_data_withonly_5_6(X_train, y_train)\n",
    "X_test_B, y_test_B = get_data_withonly_5_6(X_test, y_test)\n",
    "X_train_B, X_val_B = X_train_B[:10000], X_train_B[10000:]\n",
    "y_train_B, y_val_B = y_train_B[:10000], y_train_B[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1196 - accuracy: 0.9791 - val_loss: 0.0525 - val_accuracy: 0.9920\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9923 - val_loss: 0.0312 - val_accuracy: 0.9925\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9956 - val_loss: 0.0316 - val_accuracy: 0.9930\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9970 - val_loss: 0.0238 - val_accuracy: 0.9950\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9965 - val_loss: 0.0205 - val_accuracy: 0.9950\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 0.0240 - val_accuracy: 0.9950\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.0163 - val_accuracy: 0.9955\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0149 - val_accuracy: 0.9960\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9975 - val_loss: 0.0154 - val_accuracy: 0.9955\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0118 - val_accuracy: 0.9965\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.0134 - val_accuracy: 0.9960\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0122 - val_accuracy: 0.9970\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0112 - val_accuracy: 0.9965\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0112 - val_accuracy: 0.9970\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0133 - val_accuracy: 0.9965\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0124 - val_accuracy: 0.9965\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.0122 - val_accuracy: 0.9970\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0122 - val_accuracy: 0.9975\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0147 - val_accuracy: 0.9970\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0106 - val_accuracy: 0.9975\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0124 - val_accuracy: 0.9975\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0121 - val_accuracy: 0.9975\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0117 - val_accuracy: 0.9975\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0123 - val_accuracy: 0.9975\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0160 - val_accuracy: 0.9965\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0131 - val_accuracy: 0.9970\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0108 - val_accuracy: 0.9970\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0113 - val_accuracy: 0.9970\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0111 - val_accuracy: 0.9970\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0101 - val_accuracy: 0.9970\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0108 - val_accuracy: 0.9970\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0128 - val_accuracy: 0.9970\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0118 - val_accuracy: 0.9975\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0116 - val_accuracy: 0.9970\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0111 - val_accuracy: 0.9975\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0182 - val_accuracy: 0.9970\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0137 - val_accuracy: 0.9970\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0135 - val_accuracy: 0.9970\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0107 - val_accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2476345fa90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model_B.compile(loss=\"binary_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=\"accuracy\")\n",
    "model_B.fit(X_train_B, y_train_B, epochs=100, \n",
    "            validation_data=(X_val_B, y_val_B), \n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                     patience=10, \n",
    "                                                     restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0075619034469127655, 0.9984999895095825]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2272 - accuracy: 0.9243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22721777856349945, 0.9242500066757202]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A.evaluate(X_test_A, y_test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = keras.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", \n",
    "                     optimizer=\"sgd\", \n",
    "                     metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9611 - val_loss: 0.0554 - val_accuracy: 0.9880\n",
      "Epoch 2/4\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9950 - val_loss: 0.0379 - val_accuracy: 0.9905\n",
      "Epoch 3/4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9962 - val_loss: 0.0313 - val_accuracy: 0.9910\n",
      "Epoch 4/4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.0280 - val_accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "history_b_on_A = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, \n",
    "                                  validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.0403 - accuracy: 0.9886 - val_loss: 0.0410 - val_accuracy: 0.9905\n",
      "Epoch 2/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9916 - val_loss: 0.0398 - val_accuracy: 0.9915\n",
      "Epoch 3/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9919 - val_loss: 0.0361 - val_accuracy: 0.9915\n",
      "Epoch 4/16\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.0353 - val_accuracy: 0.9910\n",
      "Epoch 5/16\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0334 - accuracy: 0.9917 - val_loss: 0.0327 - val_accuracy: 0.9910\n",
      "Epoch 6/16\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0312 - accuracy: 0.9919 - val_loss: 0.0321 - val_accuracy: 0.9915\n",
      "Epoch 7/16\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0268 - accuracy: 0.9946 - val_loss: 0.0312 - val_accuracy: 0.9915\n",
      "Epoch 8/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9938 - val_loss: 0.0317 - val_accuracy: 0.9915\n",
      "Epoch 9/16\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0259 - accuracy: 0.9935 - val_loss: 0.0303 - val_accuracy: 0.9910\n",
      "Epoch 10/16\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.9927 - val_loss: 0.0309 - val_accuracy: 0.9910\n",
      "Epoch 11/16\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.0286 - val_accuracy: 0.9915\n",
      "Epoch 12/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9952 - val_loss: 0.0288 - val_accuracy: 0.9915\n",
      "Epoch 13/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9943 - val_loss: 0.0276 - val_accuracy: 0.9915\n",
      "Epoch 14/16\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.9940 - val_loss: 0.0287 - val_accuracy: 0.9915\n",
      "Epoch 15/16\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0241 - accuracy: 0.9946 - val_loss: 0.0273 - val_accuracy: 0.9915\n",
      "Epoch 16/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9945 - val_loss: 0.0266 - val_accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", \n",
    "                     optimizer=optimizer, \n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "history_b_on_A = model_B_on_A.fit(X_train_B, y_train_B, epochs=16, \n",
    "                                  validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.015052733942866325, 0.9975000023841858]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "momentum_optimizer = keras.optimizers.SGD(learning_rate=0.001, \n",
    "                                          momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "nag_optimizer = keras.optimizers.SGD(learning_rate=1e-3, \n",
    "                                     momentum=0.9, \n",
    "                                     nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af68422bec32ee5a6de64dec1179cbe01bf4f7813cec231e0768ec582c2e4b4a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
