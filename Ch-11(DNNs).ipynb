{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing/Exploding Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812ceb670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", \n",
    "                    kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dadb50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2, \n",
    "                                                mode=\"fan_avg\", \n",
    "                                                distribution=\"uniform\")\n",
    "keras.layers.Dense(10, activation=\"relu\", \n",
    "                    kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dadd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using leaky relu\n",
    "leaky_relu = keras.layers.LeakyReLU(alpha=0.2)\n",
    "keras.layers.Dense(10, activation=leaky_relu, \n",
    "                    kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1f812dad970>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\", \n",
    "                    kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"elu\", \n",
    "                        kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"elu\", \n",
    "                        kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 784)              3136      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization_3/gamma:0', True),\n",
       " ('batch_normalization_3/beta:0', True),\n",
       " ('batch_normalization_3/moving_mean:0', False),\n",
       " ('batch_normalization_3/moving_variance:0', False)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SG704\\AppData\\Local\\Temp/ipykernel_12816/3873162892.py:1: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  model.layers[1].updates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, \n",
    "        kernel_initializer=\"he_normal\", \n",
    "        use_bias=False), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Activation(\"elu\"), \n",
    "    keras.layers.Dense(100, \n",
    "        kernel_initializer=\"he_normal\", \n",
    "        use_bias=False), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Activation(\"elu\"), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "def get_data_without_5_6(data, labels):\n",
    "    new_data, new_labels = [], []\n",
    "    for i, label in enumerate(labels):\n",
    "        if (label != 5) & (label != 6):\n",
    "            if label > 5:\n",
    "                new_labels.append(labels[i]-2)\n",
    "            else:\n",
    "                new_labels.append(labels[i])\n",
    "            new_data.append(data[i])\n",
    "    return np.array(new_data), np.array(new_labels)\n",
    "        \n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_A, y_train_A = get_data_without_5_6(X_train, y_train)\n",
    "X_test_A, y_test_A = get_data_without_5_6(X_test, y_test)\n",
    "X_train_A, X_val_A = X_train_A[:30000], X_train_A[30000:]\n",
    "y_train_A, y_val_A = y_train_A[:30000], y_train_A[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 7s 5ms/step - loss: 0.3977 - accuracy: 0.8659 - val_loss: 0.2692 - val_accuracy: 0.9088\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.2771 - accuracy: 0.9043 - val_loss: 0.2425 - val_accuracy: 0.9173\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2402 - accuracy: 0.9177 - val_loss: 0.2338 - val_accuracy: 0.9207\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2150 - accuracy: 0.9246 - val_loss: 0.2207 - val_accuracy: 0.9251\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2044 - accuracy: 0.9281 - val_loss: 0.2209 - val_accuracy: 0.9233\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1892 - accuracy: 0.9326 - val_loss: 0.2141 - val_accuracy: 0.9277\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1761 - accuracy: 0.9371 - val_loss: 0.2168 - val_accuracy: 0.9251\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1654 - accuracy: 0.9397 - val_loss: 0.2088 - val_accuracy: 0.9282\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1579 - accuracy: 0.9439 - val_loss: 0.2177 - val_accuracy: 0.92680s - loss: 0\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1511 - accuracy: 0.9464 - val_loss: 0.2061 - val_accuracy: 0.9316\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1448 - accuracy: 0.9490 - val_loss: 0.2025 - val_accuracy: 0.9320\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1380 - accuracy: 0.9515 - val_loss: 0.2066 - val_accuracy: 0.9319\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1313 - accuracy: 0.9533 - val_loss: 0.2161 - val_accuracy: 0.9277\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1260 - accuracy: 0.9557 - val_loss: 0.2042 - val_accuracy: 0.9331\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1211 - accuracy: 0.9565 - val_loss: 0.2101 - val_accuracy: 0.9299\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1123 - accuracy: 0.9605 - val_loss: 0.2117 - val_accuracy: 0.9294\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1090 - accuracy: 0.9610 - val_loss: 0.2098 - val_accuracy: 0.9306\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1025 - accuracy: 0.9633 - val_loss: 0.2136 - val_accuracy: 0.9303\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0990 - accuracy: 0.9650 - val_loss: 0.2125 - val_accuracy: 0.9317\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0943 - accuracy: 0.9668 - val_loss: 0.2237 - val_accuracy: 0.9288\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0920 - accuracy: 0.9662 - val_loss: 0.2159 - val_accuracy: 0.9317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24762e9e580>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_A = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=\"accuracy\")\n",
    "model_A.fit(X_train_A, y_train_A, epochs=100, \n",
    "            validation_data=(X_val_A, y_val_A), \n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                     patience=10, \n",
    "                                                     restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2272 - accuracy: 0.9243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22721777856349945, 0.9242500066757202]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A.evaluate(X_test_A, y_test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_withonly_5_6(data, labels):\n",
    "    new_data, new_labels = [], []\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == 5:\n",
    "            new_data.append(data[i])\n",
    "            new_labels.append(1)\n",
    "        elif label == 6:\n",
    "            new_data.append(data[i])\n",
    "            new_labels.append(0)\n",
    "    return np.array(new_data), np.array(new_labels)\n",
    "\n",
    "X_train_B, y_train_B = get_data_withonly_5_6(X_train, y_train)\n",
    "X_test_B, y_test_B = get_data_withonly_5_6(X_test, y_test)\n",
    "X_train_B, X_val_B = X_train_B[:10000], X_train_B[10000:]\n",
    "y_train_B, y_val_B = y_train_B[:10000], y_train_B[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1196 - accuracy: 0.9791 - val_loss: 0.0525 - val_accuracy: 0.9920\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9923 - val_loss: 0.0312 - val_accuracy: 0.9925\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9956 - val_loss: 0.0316 - val_accuracy: 0.9930\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9970 - val_loss: 0.0238 - val_accuracy: 0.9950\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9965 - val_loss: 0.0205 - val_accuracy: 0.9950\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 0.0240 - val_accuracy: 0.9950\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.0163 - val_accuracy: 0.9955\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0149 - val_accuracy: 0.9960\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9975 - val_loss: 0.0154 - val_accuracy: 0.9955\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0118 - val_accuracy: 0.9965\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.0134 - val_accuracy: 0.9960\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0122 - val_accuracy: 0.9970\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0112 - val_accuracy: 0.9965\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0112 - val_accuracy: 0.9970\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0133 - val_accuracy: 0.9965\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0124 - val_accuracy: 0.9965\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.0122 - val_accuracy: 0.9970\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0122 - val_accuracy: 0.9975\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0147 - val_accuracy: 0.9970\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0106 - val_accuracy: 0.9975\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0124 - val_accuracy: 0.9975\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0121 - val_accuracy: 0.9975\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0117 - val_accuracy: 0.9975\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0123 - val_accuracy: 0.9975\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0160 - val_accuracy: 0.9965\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0131 - val_accuracy: 0.9970\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0108 - val_accuracy: 0.9970\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0113 - val_accuracy: 0.9970\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0111 - val_accuracy: 0.9970\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0101 - val_accuracy: 0.9970\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0108 - val_accuracy: 0.9970\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0128 - val_accuracy: 0.9970\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0118 - val_accuracy: 0.9975\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0116 - val_accuracy: 0.9970\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0111 - val_accuracy: 0.9975\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0182 - val_accuracy: 0.9970\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0137 - val_accuracy: 0.9970\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0135 - val_accuracy: 0.9970\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0107 - val_accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2476345fa90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation=\"relu\"), \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model_B.compile(loss=\"binary_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=\"accuracy\")\n",
    "model_B.fit(X_train_B, y_train_B, epochs=100, \n",
    "            validation_data=(X_val_B, y_val_B), \n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                     patience=10, \n",
    "                                                     restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0075619034469127655, 0.9984999895095825]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2272 - accuracy: 0.9243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22721777856349945, 0.9242500066757202]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A.evaluate(X_test_A, y_test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = keras.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", \n",
    "                     optimizer=\"sgd\", \n",
    "                     metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9611 - val_loss: 0.0554 - val_accuracy: 0.9880\n",
      "Epoch 2/4\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9950 - val_loss: 0.0379 - val_accuracy: 0.9905\n",
      "Epoch 3/4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9962 - val_loss: 0.0313 - val_accuracy: 0.9910\n",
      "Epoch 4/4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.0280 - val_accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "history_b_on_A = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, \n",
    "                                  validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.0403 - accuracy: 0.9886 - val_loss: 0.0410 - val_accuracy: 0.9905\n",
      "Epoch 2/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9916 - val_loss: 0.0398 - val_accuracy: 0.9915\n",
      "Epoch 3/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9919 - val_loss: 0.0361 - val_accuracy: 0.9915\n",
      "Epoch 4/16\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.0353 - val_accuracy: 0.9910\n",
      "Epoch 5/16\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0334 - accuracy: 0.9917 - val_loss: 0.0327 - val_accuracy: 0.9910\n",
      "Epoch 6/16\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0312 - accuracy: 0.9919 - val_loss: 0.0321 - val_accuracy: 0.9915\n",
      "Epoch 7/16\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0268 - accuracy: 0.9946 - val_loss: 0.0312 - val_accuracy: 0.9915\n",
      "Epoch 8/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9938 - val_loss: 0.0317 - val_accuracy: 0.9915\n",
      "Epoch 9/16\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0259 - accuracy: 0.9935 - val_loss: 0.0303 - val_accuracy: 0.9910\n",
      "Epoch 10/16\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.9927 - val_loss: 0.0309 - val_accuracy: 0.9910\n",
      "Epoch 11/16\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.0286 - val_accuracy: 0.9915\n",
      "Epoch 12/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9952 - val_loss: 0.0288 - val_accuracy: 0.9915\n",
      "Epoch 13/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9943 - val_loss: 0.0276 - val_accuracy: 0.9915\n",
      "Epoch 14/16\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.9940 - val_loss: 0.0287 - val_accuracy: 0.9915\n",
      "Epoch 15/16\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0241 - accuracy: 0.9946 - val_loss: 0.0273 - val_accuracy: 0.9915\n",
      "Epoch 16/16\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9945 - val_loss: 0.0266 - val_accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", \n",
    "                     optimizer=optimizer, \n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "history_b_on_A = model_B_on_A.fit(X_train_B, y_train_B, epochs=16, \n",
    "                                  validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.015052733942866325, 0.9975000023841858]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "momentum_optimizer = keras.optimizers.SGD(learning_rate=0.001, \n",
    "                                          momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "nag_optimizer = keras.optimizers.SGD(learning_rate=1e-3, \n",
    "                                     momentum=0.9, \n",
    "                                     nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adagrad_optimizer = keras.optimizers.Adagrad(learning_rate=1e-3, \n",
    "                                             initial_accumulator_value=0.1, \n",
    "                                             epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop_optimizer = keras.optimizers.RMSprop(learning_rate=1e-3, \n",
    "                                             rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = keras.optimizers.Adam(learning_rate=0.001, \n",
    "                                       beta_1=0.9, \n",
    "                                       beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch/s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, \n",
    "                                                 patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_dataset = 2000\n",
    "s = 20 * length_of_dataset // 32\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "l1_dense_layer = keras.layers.Dense(\n",
    "    units=100, \n",
    "    activation=\"elu\", \n",
    "    kernel_initializer=\"he_normal\", \n",
    "    kernel_regularizer=keras.regularizers.l1(0.01)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dense_layer = keras.layers.Dense(\n",
    "    units=100, \n",
    "    activation=\"elu\", \n",
    "    kernel_initializer=\"he_normal\", \n",
    "    kernel_regularizer=keras.regularizers.l2(0.01)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_l2_dense_layer = keras.layers.Dense(\n",
    "    units=100, \n",
    "    activation=\"elu\", \n",
    "    kernel_initializer=\"he_normal\", \n",
    "    kernel_regularizer=keras.regularizers.l1_l2(0.01)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(\n",
    "    keras.layers.Dense, \n",
    "    activation=\"elu\", \n",
    "    kernel_initializer=\"he_normal\", \n",
    "    kernel_regularizer=keras.regularizers.l2(0.01)\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    RegularizedDense(300), \n",
    "    RegularizedDense(100), \n",
    "    RegularizedDense(10, activation=\"softmax\", \n",
    "                     kernel_initializer=\"glorot_uniform\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.Dropout(rate=0.2), \n",
    "    keras.layers.Dense(300, activation=\"elu\", \n",
    "                       kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.Dropout(rate=0.2), \n",
    "    keras.layers.Dense(100, activation=\"elu\", \n",
    "                       kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.Dropout(rate=0.2), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 7s 3ms/step - loss: 0.7499 - accuracy: 0.7347 - val_loss: 0.4495 - val_accuracy: 0.8339\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5557 - accuracy: 0.8009 - val_loss: 0.4183 - val_accuracy: 0.8449\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5038 - accuracy: 0.8169 - val_loss: 0.3996 - val_accuracy: 0.8519\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4814 - accuracy: 0.8258 - val_loss: 0.3785 - val_accuracy: 0.8615\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4537 - accuracy: 0.8347 - val_loss: 0.3762 - val_accuracy: 0.8636\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4426 - accuracy: 0.8378 - val_loss: 0.3611 - val_accuracy: 0.8694\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4325 - accuracy: 0.8420 - val_loss: 0.3584 - val_accuracy: 0.8677\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4281 - accuracy: 0.8441 - val_loss: 0.3528 - val_accuracy: 0.8685\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4144 - accuracy: 0.8473 - val_loss: 0.3461 - val_accuracy: 0.8725\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4097 - accuracy: 0.8509 - val_loss: 0.3458 - val_accuracy: 0.8716\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4031 - accuracy: 0.8526 - val_loss: 0.3370 - val_accuracy: 0.8747\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3964 - accuracy: 0.8540 - val_loss: 0.3363 - val_accuracy: 0.8750\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3939 - accuracy: 0.8556 - val_loss: 0.3356 - val_accuracy: 0.8756\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3871 - accuracy: 0.8561 - val_loss: 0.3282 - val_accuracy: 0.8786\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3842 - accuracy: 0.8583 - val_loss: 0.3240 - val_accuracy: 0.8796\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3766 - accuracy: 0.8594 - val_loss: 0.3214 - val_accuracy: 0.8810\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3759 - accuracy: 0.8607 - val_loss: 0.3279 - val_accuracy: 0.8779\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3700 - accuracy: 0.8636 - val_loss: 0.3268 - val_accuracy: 0.8793\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3652 - accuracy: 0.8635 - val_loss: 0.3211 - val_accuracy: 0.8797\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3647 - accuracy: 0.8652 - val_loss: 0.3174 - val_accuracy: 0.8830\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3629 - accuracy: 0.8653 - val_loss: 0.3147 - val_accuracy: 0.8832\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3582 - accuracy: 0.8679 - val_loss: 0.3137 - val_accuracy: 0.8840\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3539 - accuracy: 0.8676 - val_loss: 0.3139 - val_accuracy: 0.8855\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3503 - accuracy: 0.8685 - val_loss: 0.3173 - val_accuracy: 0.8848\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3468 - accuracy: 0.8715 - val_loss: 0.3103 - val_accuracy: 0.8863\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3504 - accuracy: 0.8701 - val_loss: 0.3074 - val_accuracy: 0.8862\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3432 - accuracy: 0.8726 - val_loss: 0.3107 - val_accuracy: 0.8868\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3444 - accuracy: 0.8706 - val_loss: 0.3055 - val_accuracy: 0.8862\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3381 - accuracy: 0.8720 - val_loss: 0.3090 - val_accuracy: 0.8876\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3359 - accuracy: 0.8742 - val_loss: 0.3055 - val_accuracy: 0.8875\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3355 - accuracy: 0.8741 - val_loss: 0.3045 - val_accuracy: 0.8878\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3317 - accuracy: 0.8776 - val_loss: 0.3020 - val_accuracy: 0.8904\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3345 - accuracy: 0.8752 - val_loss: 0.3034 - val_accuracy: 0.8885\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3293 - accuracy: 0.8770 - val_loss: 0.3080 - val_accuracy: 0.8881\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3303 - accuracy: 0.8757 - val_loss: 0.2996 - val_accuracy: 0.8889\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3283 - accuracy: 0.8782 - val_loss: 0.3017 - val_accuracy: 0.8895\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3249 - accuracy: 0.8779 - val_loss: 0.3000 - val_accuracy: 0.8876\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3256 - accuracy: 0.8773 - val_loss: 0.2985 - val_accuracy: 0.8931\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3215 - accuracy: 0.8795 - val_loss: 0.2940 - val_accuracy: 0.8916\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3181 - accuracy: 0.8809 - val_loss: 0.2950 - val_accuracy: 0.8895\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3178 - accuracy: 0.8815 - val_loss: 0.2967 - val_accuracy: 0.8881\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3182 - accuracy: 0.8815 - val_loss: 0.2973 - val_accuracy: 0.8904\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3134 - accuracy: 0.8830 - val_loss: 0.2968 - val_accuracy: 0.8891\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3151 - accuracy: 0.8805 - val_loss: 0.3022 - val_accuracy: 0.8879\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3114 - accuracy: 0.8832 - val_loss: 0.2918 - val_accuracy: 0.8906\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3109 - accuracy: 0.8822 - val_loss: 0.2913 - val_accuracy: 0.8924\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3066 - accuracy: 0.8854 - val_loss: 0.2924 - val_accuracy: 0.8926\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3102 - accuracy: 0.8832 - val_loss: 0.2910 - val_accuracy: 0.8927\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3073 - accuracy: 0.8848 - val_loss: 0.2933 - val_accuracy: 0.8908\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3091 - accuracy: 0.8821 - val_loss: 0.2943 - val_accuracy: 0.8909\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2999 - accuracy: 0.8863 - val_loss: 0.2914 - val_accuracy: 0.8933\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3029 - accuracy: 0.8871 - val_loss: 0.2935 - val_accuracy: 0.8932\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3011 - accuracy: 0.8872 - val_loss: 0.2865 - val_accuracy: 0.8924\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3015 - accuracy: 0.8863 - val_loss: 0.2905 - val_accuracy: 0.8913\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2997 - accuracy: 0.8875 - val_loss: 0.2893 - val_accuracy: 0.8914\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2976 - accuracy: 0.8865 - val_loss: 0.2842 - val_accuracy: 0.8947\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2951 - accuracy: 0.8899 - val_loss: 0.2875 - val_accuracy: 0.8935\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2932 - accuracy: 0.8892 - val_loss: 0.2879 - val_accuracy: 0.8950\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2925 - accuracy: 0.8911 - val_loss: 0.2863 - val_accuracy: 0.8941\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2930 - accuracy: 0.8910 - val_loss: 0.2852 - val_accuracy: 0.8933\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2921 - accuracy: 0.8904 - val_loss: 0.2832 - val_accuracy: 0.8955\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2920 - accuracy: 0.8906 - val_loss: 0.2864 - val_accuracy: 0.8954\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2914 - accuracy: 0.8899 - val_loss: 0.2927 - val_accuracy: 0.8896\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2876 - accuracy: 0.8913 - val_loss: 0.2829 - val_accuracy: 0.8943\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2844 - accuracy: 0.8929 - val_loss: 0.2810 - val_accuracy: 0.8964\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2875 - accuracy: 0.8926 - val_loss: 0.2809 - val_accuracy: 0.8960 loss: 0.2900  - ETA: 0s - loss: 0.2872 - accuracy: \n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2859 - accuracy: 0.8930 - val_loss: 0.2852 - val_accuracy: 0.8955\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2843 - accuracy: 0.8917 - val_loss: 0.2893 - val_accuracy: 0.8946\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2849 - accuracy: 0.8932 - val_loss: 0.2848 - val_accuracy: 0.8955\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2833 - accuracy: 0.8923 - val_loss: 0.2835 - val_accuracy: 0.8935\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2813 - accuracy: 0.8951 - val_loss: 0.2853 - val_accuracy: 0.8946\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2800 - accuracy: 0.8931 - val_loss: 0.2824 - val_accuracy: 0.8952\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2797 - accuracy: 0.8943 - val_loss: 0.2798 - val_accuracy: 0.8951\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2794 - accuracy: 0.8950 - val_loss: 0.2840 - val_accuracy: 0.8947\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2750 - accuracy: 0.8957 - val_loss: 0.2795 - val_accuracy: 0.8965\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2797 - accuracy: 0.8944 - val_loss: 0.2831 - val_accuracy: 0.8953\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2778 - accuracy: 0.8955 - val_loss: 0.2814 - val_accuracy: 0.8952\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2780 - accuracy: 0.8944 - val_loss: 0.2796 - val_accuracy: 0.8970\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2755 - accuracy: 0.8960 - val_loss: 0.2810 - val_accuracy: 0.8964\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2743 - accuracy: 0.8965 - val_loss: 0.2789 - val_accuracy: 0.8961\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2697 - accuracy: 0.8971 - val_loss: 0.2813 - val_accuracy: 0.8974\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2721 - accuracy: 0.8978 - val_loss: 0.2800 - val_accuracy: 0.8953\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2743 - accuracy: 0.8951 - val_loss: 0.2793 - val_accuracy: 0.8970\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2707 - accuracy: 0.8975 - val_loss: 0.2758 - val_accuracy: 0.8965\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2686 - accuracy: 0.8983 - val_loss: 0.2772 - val_accuracy: 0.8985\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2707 - accuracy: 0.8979 - val_loss: 0.2787 - val_accuracy: 0.8971\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2663 - accuracy: 0.8983 - val_loss: 0.2771 - val_accuracy: 0.8988\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2664 - accuracy: 0.9002 - val_loss: 0.2824 - val_accuracy: 0.8962\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2634 - accuracy: 0.8997 - val_loss: 0.2832 - val_accuracy: 0.8990\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2653 - accuracy: 0.8997 - val_loss: 0.2804 - val_accuracy: 0.8974\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2670 - accuracy: 0.8988 - val_loss: 0.2782 - val_accuracy: 0.8982\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2651 - accuracy: 0.8997 - val_loss: 0.2813 - val_accuracy: 0.8963\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2668 - accuracy: 0.8995 - val_loss: 0.2821 - val_accuracy: 0.8973\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2652 - accuracy: 0.8981 - val_loss: 0.2818 - val_accuracy: 0.8967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1950ca3e550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train, X_val = X_train[:50000], X_train[50000:]\n",
    "y_train, y_val = y_train[:50000], y_train[50000:]\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=0.2), \n",
    "    keras.layers.Dense(300, activation=\"relu\", \n",
    "                        kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate=0.2), \n",
    "    keras.layers.Dense(100, activation=\"relu\", \n",
    "                        kernel_initializer=\"he_normal\"), \n",
    "    keras.layers.Dropout(rate=0.2), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "]) \n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, \n",
    "                                                 patience=5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=\"sgd\", \n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=100, \n",
    "          validation_data=(X_val, y_val), \n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=10, \n",
    "                                                   restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"fashion_mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi1\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:113: UserWarning: `tf.keras.backend.learning_phase_scope` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  return next(self.gen)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with keras.backend.learning_phase_scope(1):\n",
    "    y_probas = np.stack([model.predict(X_test) for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "        0.998]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test[:1]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.   ,\n",
       "         0.998]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([X_test[1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x16b383c4b50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras.layers.Dense(100, activation=\"elu\", \n",
    "                   kernel_initializer=\"he_normal\", \n",
    "                   kernel_constraint=keras.constraints.max_norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "def dataset_split(data, labels, yes=True):\n",
    "    n_data, n_labels = [], []\n",
    "    for i, label in enumerate(labels):\n",
    "        if yes:\n",
    "            if label < 5:\n",
    "                n_data.append(data[i])\n",
    "                n_labels.append(labels[i])\n",
    "        else:\n",
    "            if label > 5:\n",
    "                n_data.append(data[i])\n",
    "                n_labels.append(labels[i]-5)\n",
    "    return np.array(n_data), np.array(n_labels)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train_A, y_train_A = dataset_split(X_train, y_train)\n",
    "X_train_A, X_val_A = X_train_A[:23000], X_train_A[23000:]\n",
    "y_train_A, y_val_A = y_train_A[:23000], y_train_A[23000:]\n",
    "X_test_A, y_test_A = dataset_split(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "719/719 [==============================] - 5s 6ms/step - loss: 1.7513 - accuracy: 0.9307 - val_loss: 0.4829 - val_accuracy: 0.9600\n",
      "Epoch 2/100\n",
      "719/719 [==============================] - 4s 6ms/step - loss: 0.2946 - accuracy: 0.9650 - val_loss: 0.1782 - val_accuracy: 0.9758\n",
      "Epoch 3/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.1645 - accuracy: 0.9730 - val_loss: 0.1930 - val_accuracy: 0.9742\n",
      "Epoch 4/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.1129 - accuracy: 0.9769 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 5/100\n",
      "719/719 [==============================] - 4s 6ms/step - loss: 0.1037 - accuracy: 0.9791 - val_loss: 0.0896 - val_accuracy: 0.9787\n",
      "Epoch 6/100\n",
      "719/719 [==============================] - 4s 6ms/step - loss: 0.0665 - accuracy: 0.9848 - val_loss: 0.0937 - val_accuracy: 0.9837\n",
      "Epoch 7/100\n",
      "719/719 [==============================] - 4s 5ms/step - loss: 0.0555 - accuracy: 0.9858 - val_loss: 0.0642 - val_accuracy: 0.9838\n",
      "Epoch 8/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0557 - accuracy: 0.9861 - val_loss: 0.1435 - val_accuracy: 0.9696\n",
      "Epoch 9/100\n",
      "719/719 [==============================] - 2s 2ms/step - loss: 0.0552 - accuracy: 0.9851 - val_loss: 0.0721 - val_accuracy: 0.9821\n",
      "Epoch 10/100\n",
      "719/719 [==============================] - 3s 5ms/step - loss: 0.0584 - accuracy: 0.9861 - val_loss: 0.0559 - val_accuracy: 0.9851\n",
      "Epoch 11/100\n",
      "719/719 [==============================] - 4s 6ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.0591 - val_accuracy: 0.9829\n",
      "Epoch 12/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0359 - accuracy: 0.9910 - val_loss: 0.0562 - val_accuracy: 0.9862\n",
      "Epoch 13/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0337 - accuracy: 0.9907 - val_loss: 0.0697 - val_accuracy: 0.9825\n",
      "Epoch 14/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0569 - val_accuracy: 0.9860\n",
      "Epoch 15/100\n",
      "719/719 [==============================] - 4s 5ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.0610 - val_accuracy: 0.9863\n",
      "Epoch 16/100\n",
      "719/719 [==============================] - 2s 2ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0507 - val_accuracy: 0.9896\n",
      "Epoch 17/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0315 - accuracy: 0.9929 - val_loss: 0.0469 - val_accuracy: 0.9904\n",
      "Epoch 18/100\n",
      "719/719 [==============================] - 3s 5ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 0.0697 - val_accuracy: 0.9857\n",
      "Epoch 19/100\n",
      "719/719 [==============================] - 1s 2ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.0622 - val_accuracy: 0.9870\n",
      "Epoch 20/100\n",
      "719/719 [==============================] - 1s 2ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0658 - val_accuracy: 0.9866\n",
      "Epoch 21/100\n",
      "719/719 [==============================] - 1s 2ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0802 - val_accuracy: 0.9863\n",
      "Epoch 22/100\n",
      "719/719 [==============================] - 2s 2ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.0597 - val_accuracy: 0.9887\n",
      "Epoch 23/100\n",
      "719/719 [==============================] - 2s 2ms/step - loss: 0.0178 - accuracy: 0.9955 - val_loss: 0.0468 - val_accuracy: 0.9897\n",
      "Epoch 24/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.0595 - val_accuracy: 0.9879\n",
      "Epoch 25/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0211 - accuracy: 0.9956 - val_loss: 0.0696 - val_accuracy: 0.9853\n",
      "Epoch 26/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.0471 - val_accuracy: 0.9900\n",
      "Epoch 27/100\n",
      "719/719 [==============================] - 4s 5ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.0627 - val_accuracy: 0.9887\n",
      "Epoch 28/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.0600 - val_accuracy: 0.9878\n",
      "Epoch 29/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.0785 - val_accuracy: 0.9880\n",
      "Epoch 30/100\n",
      "719/719 [==============================] - 3s 5ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0490 - val_accuracy: 0.9884\n",
      "Epoch 31/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.0800 - val_accuracy: 0.9887\n",
      "Epoch 32/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0576 - val_accuracy: 0.9914\n",
      "Epoch 33/100\n",
      "719/719 [==============================] - 2s 2ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0625 - val_accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model_A = keras.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(100, kernel_initializer=\"he_normal\", \n",
    "                 activation=\"elu\"), \n",
    "    layers.Dense(100, kernel_initializer=\"he_normal\", \n",
    "                 activation=\"elu\"), \n",
    "    layers.Dense(100, kernel_initializer=\"he_normal\", \n",
    "                 activation=\"elu\"), \n",
    "    layers.Dense(100, kernel_initializer=\"he_normal\", \n",
    "                 activation=\"elu\"), \n",
    "    layers.Dense(100, kernel_initializer=\"he_normal\", \n",
    "                 activation=\"elu\"), \n",
    "    layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=\"adam\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history_A = model_A.fit(X_train_A, y_train_A, epochs=100, \n",
    "                      validation_data=(X_val_A, y_val_A), \n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, \n",
    "                                                               restore_best_weights=True, \n",
    "                                                               monitor=\"val_loss\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 1s 2ms/step - loss: 0.0468 - accuracy: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04679414629936218, 0.9897314310073853]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A.evaluate(X_val_A, y_val_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_B, y_train_B = dataset_split(X_train, y_train, yes=False)\n",
    "X_train_B, X_val_B = X_train_A[:15000], X_train_A[15000:]\n",
    "y_train_B, y_val_B = y_train_A[:15000], y_train_A[15000:]\n",
    "X_test_B, y_test_B = dataset_split(X_test, y_test, yes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_B = keras.Sequential(model_A.layers[:-1])\n",
    "model_B.add(layers.Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0769 - accuracy: 0.9949 - val_loss: 0.0246 - val_accuracy: 0.9962\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0185 - accuracy: 0.9981 - val_loss: 0.0173 - val_accuracy: 0.9967\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0135 - accuracy: 0.9985 - val_loss: 0.0150 - val_accuracy: 0.9973\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0134 - val_accuracy: 0.9973\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.0128 - val_accuracy: 0.9975\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=[\"accuracy\"])\n",
    "history_B = model_B.fit(X_train_B, y_train_B, epochs=5, \n",
    "                        validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0124 - val_accuracy: 0.9975\n",
      "Epoch 2/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.0121 - val_accuracy: 0.9975\n",
      "Epoch 3/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0119 - val_accuracy: 0.9975\n",
      "Epoch 4/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0117 - val_accuracy: 0.9975\n",
      "Epoch 5/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0116 - val_accuracy: 0.9975\n",
      "Epoch 6/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0114 - val_accuracy: 0.9975\n",
      "Epoch 7/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0113 - val_accuracy: 0.9975\n",
      "Epoch 8/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0113 - val_accuracy: 0.9975\n",
      "Epoch 9/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0112 - val_accuracy: 0.9975\n",
      "Epoch 10/16\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0111 - val_accuracy: 0.9975\n",
      "Epoch 11/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0110 - val_accuracy: 0.9975\n",
      "Epoch 12/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 13/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 14/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0108 - val_accuracy: 0.9975\n",
      "Epoch 15/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0107 - val_accuracy: 0.9976\n",
      "Epoch 16/16\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0106 - val_accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n",
    "model_B.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=optimizer, \n",
    "                metrics=[\"accuracy\"])\n",
    "history_B = model_B.fit(X_train_B, y_train_B, epochs=16, \n",
    "                        validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "pandas.DataFrame(history_A.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas.DataFrame(history_B.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"model_A.h5\")\n",
    "model_B.save(\"model_B.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(n_hiddens=4, n_neurons=100, learning_rate=1e-3, input_shape=[28, 28]):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=input_shape))\n",
    "    for layer in range(n_hiddens):\n",
    "        model.add(layers.Dense(n_neurons, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(layers.Dense(5, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "469/469 [==============================] - 5s 6ms/step - loss: 2.8375 - accuracy: 0.8982 - val_loss: 0.5121 - val_accuracy: 0.9361\n",
      "Epoch 2/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2543 - accuracy: 0.9550 - val_loss: 0.3506 - val_accuracy: 0.9452\n",
      "Epoch 3/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1325 - accuracy: 0.9686 - val_loss: 0.2683 - val_accuracy: 0.9582\n",
      "Epoch 4/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0794 - accuracy: 0.9798 - val_loss: 0.2602 - val_accuracy: 0.9559\n",
      "Epoch 5/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0526 - accuracy: 0.9851 - val_loss: 0.2523 - val_accuracy: 0.9597\n",
      "Epoch 6/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9891 - val_loss: 0.2430 - val_accuracy: 0.9605\n",
      "Epoch 7/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9929 - val_loss: 0.2412 - val_accuracy: 0.9625\n",
      "Epoch 8/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.2404 - val_accuracy: 0.9621\n",
      "Epoch 9/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.2451 - val_accuracy: 0.9597\n",
      "Epoch 10/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.2442 - val_accuracy: 0.9629\n",
      "Epoch 11/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.2446 - val_accuracy: 0.9624\n",
      "Epoch 12/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.2459 - val_accuracy: 0.9639\n",
      "Epoch 13/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.2457 - val_accuracy: 0.9641\n",
      "Epoch 14/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.2468 - val_accuracy: 0.9636\n",
      "Epoch 15/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.2481 - val_accuracy: 0.9640\n",
      "Epoch 16/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.2504 - val_accuracy: 0.9653\n",
      "Epoch 17/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.2503 - val_accuracy: 0.9650\n",
      "Epoch 18/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.2504 - val_accuracy: 0.9647\n",
      "Epoch 19/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.2513 - val_accuracy: 0.9650\n",
      "Epoch 20/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.2522 - val_accuracy: 0.9653\n",
      "Epoch 21/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.2539 - val_accuracy: 0.9657\n",
      "Epoch 22/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.2540 - val_accuracy: 0.9649\n",
      "Epoch 23/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9657\n",
      "Epoch 24/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.2560 - val_accuracy: 0.9660\n",
      "Epoch 25/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9666\n",
      "Epoch 26/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9661\n",
      "Epoch 27/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9659\n",
      "Epoch 28/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9664\n",
      "Epoch 29/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9665\n",
      "Epoch 30/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9663\n",
      "Epoch 31/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 9.6747e-04 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9666\n",
      "Epoch 32/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 9.2126e-04 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9665\n",
      "Epoch 33/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 8.8246e-04 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9663\n",
      "Epoch 34/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 8.5516e-04 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9664\n",
      "Epoch 35/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 8.1952e-04 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9660\n",
      "Epoch 36/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 7.8831e-04 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9665\n",
      "Epoch 37/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 7.6032e-04 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9664\n",
      "Epoch 38/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 7.3190e-04 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9663\n",
      "Epoch 39/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 7.1170e-04 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9666\n",
      "Epoch 40/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 6.9017e-04 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9665\n",
      "Epoch 41/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 6.6732e-04 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9663\n",
      "Epoch 42/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 6.4775e-04 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9663\n",
      "Epoch 43/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 6.2762e-04 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9665\n",
      "Epoch 44/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 6.0872e-04 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9661\n",
      "Epoch 45/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 5.9534e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9663\n",
      "Epoch 46/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 5.7601e-04 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9663\n",
      "Epoch 47/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 5.6197e-04 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9665\n",
      "Epoch 48/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 5.4740e-04 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9666\n",
      "Epoch 49/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 5.3285e-04 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9665\n",
      "Epoch 50/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 5.2212e-04 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9664\n",
      "Epoch 51/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 5.0583e-04 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9664\n",
      "Epoch 52/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 4.9583e-04 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9664\n",
      "Epoch 53/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 4.8302e-04 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9668\n",
      "Epoch 54/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 4.7163e-04 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9670\n",
      "Epoch 55/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 4.6038e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9665\n",
      "Epoch 56/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 4.5348e-04 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9666\n",
      "Epoch 57/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 4.4275e-04 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9668\n",
      "Epoch 58/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 4.3362e-04 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9668\n",
      "Epoch 59/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 4.2416e-04 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9668\n",
      "Epoch 60/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 4.1610e-04 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9665\n",
      "Epoch 61/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 4.0738e-04 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9668\n",
      "Epoch 62/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 3.9955e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9669\n",
      "Epoch 63/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 3.9138e-04 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9670\n",
      "Epoch 64/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 3.8489e-04 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9672\n",
      "Epoch 65/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.7545e-04 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9670\n",
      "Epoch 66/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 3.7035e-04 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9672\n",
      "Epoch 67/100\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 3.6480e-04 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9671\n",
      "Epoch 68/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 3.5741e-04 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9671\n",
      "Epoch 69/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 3.5117e-04 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9671\n",
      "Epoch 70/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 3.4518e-04 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9670\n",
      "Epoch 71/100\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 3.3922e-04 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9669\n",
      "Epoch 72/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 3.3406e-04 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9672\n",
      "Epoch 73/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 3.2829e-04 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9672\n",
      "Epoch 74/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 3.2306e-04 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9671\n",
      "Epoch 75/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 3.1821e-04 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9672\n",
      "Epoch 76/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 3.1223e-04 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9669\n",
      "Epoch 77/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 3.0818e-04 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9674\n",
      "Epoch 78/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 3.0325e-04 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9672\n",
      "Epoch 79/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.9870e-04 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9672\n",
      "Epoch 80/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.9393e-04 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9672\n",
      "Epoch 81/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 2.8963e-04 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9672\n",
      "Epoch 82/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.8526e-04 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9671\n",
      "Epoch 83/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.8124e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9670\n",
      "Epoch 84/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.7739e-04 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9670\n",
      "Epoch 85/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.7371e-04 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9671\n",
      "Epoch 86/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.6984e-04 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9670\n",
      "Epoch 87/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.6578e-04 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9671\n",
      "Epoch 88/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.6230e-04 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9671\n",
      "Epoch 89/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.5884e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9670\n",
      "Epoch 90/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.5533e-04 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9670\n",
      "Epoch 91/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.5227e-04 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9671\n",
      "Epoch 92/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.4866e-04 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9670\n",
      "Epoch 93/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.4566e-04 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9669\n",
      "Epoch 94/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.4240e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9668\n",
      "Epoch 95/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.3912e-04 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9669\n",
      "Epoch 96/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3671e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9670\n",
      "Epoch 97/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.3358e-04 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9670\n",
      "Epoch 98/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.3077e-04 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9671\n",
      "Epoch 99/100\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 2.2789e-04 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9671\n",
      "Epoch 100/100\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.2518e-04 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function build_model at 0x000002B82740FC10>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(model=build_model)\n",
    "keras_clf.fit(X_train_B, y_train_B, epochs=100, \n",
    "              validation_data=(X_val_B, y_val_B), \n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\",\n",
    "                                                       restore_best_weights=True)])\n",
    "\n",
    "# score_B = keras_clf.score(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_distrib = {\n",
    "    \"n_hiddens\":[1, 2, 3, 4], \n",
    "    \"n_neurons\": np.arange(1, 100), \n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "gridsearch_cv = GridSearchCV(keras_clf, param_distrib, n_iter=10, cv=10)\n",
    "gridsearch_cv.fit(X_train_B, y_train_B, epochs=100, \n",
    "                  validation_data=(X_val_B, y_val_B), \n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 3.1093 - accuracy: 0.8805\n",
      "157/157 [==============================] - 0s 2ms/step\n",
      "313/313 [==============================] - 2s 3ms/step - loss: 2.6862 - accuracy: 0.8925\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 4.3411 - accuracy: 0.8804\n",
      "157/157 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9262666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "np.average(cross_val_score(keras_clf, X_train_B, y_train_B, cv=3, scoring=\"accuracy\"), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = keras_clf.predict(X_val_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1524,    0,   14,    3,   10],\n",
       "       [   1, 1755,   14,   11,    7],\n",
       "       [  18,   11, 1470,   45,   21],\n",
       "       [  10,   14,   42, 1493,    4],\n",
       "       [   5,    5,   26,    3, 1494]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_val_B, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9669908378314356, 0.967)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_val_B, y_val_pred, average=\"weighted\"), recall_score(y_val_B, y_val_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "pandas.DataFrame(history_A.history).plot(figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "719/719 [==============================] - 4s 4ms/step - loss: 0.1444 - accuracy: 0.9552 - val_loss: 0.1240 - val_accuracy: 0.9783\n",
      "Epoch 2/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0612 - accuracy: 0.9800 - val_loss: 0.1899 - val_accuracy: 0.9791\n",
      "Epoch 3/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.1317 - val_accuracy: 0.9825\n",
      "Epoch 4/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.2364 - val_accuracy: 0.9808\n",
      "Epoch 5/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 0.2077 - val_accuracy: 0.9842\n",
      "Epoch 6/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.2349 - val_accuracy: 0.9822\n",
      "Epoch 7/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.2249 - val_accuracy: 0.9796\n",
      "Epoch 8/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.2838 - val_accuracy: 0.9838\n",
      "Epoch 9/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.3256 - val_accuracy: 0.9843\n",
      "Epoch 10/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.2565 - val_accuracy: 0.9837\n",
      "Epoch 11/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.1962 - val_accuracy: 0.9847\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Sequential, callbacks\n",
    "model_A_with_BN = Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    # layers.BatchNormalization(), \n",
    "    layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_A_with_BN.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                        optimizer=\"adam\", \n",
    "                        metrics=[\"accuracy\"])\n",
    "\n",
    "history_A_BN = model_A_with_BN.fit(X_train_A, y_train_A, epochs=100, \n",
    "                                   validation_data=(X_val_A, y_val_A), \n",
    "                                   callbacks=[callbacks.EarlyStopping(patience=10, \n",
    "                                                                      restore_best_weights=True, \n",
    "                                                                      monitor=\"val_loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12395511567592621, 0.9782780408859253]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A_with_BN.evaluate(X_val_A, y_val_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas.DataFrame(history_A_BN.history).plot(figsize=(10, 7), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "719/719 [==============================] - 8s 7ms/step - loss: 0.2764 - accuracy: 0.9130 - val_loss: 0.1127 - val_accuracy: 0.9722\n",
      "Epoch 2/100\n",
      "719/719 [==============================] - 3s 5ms/step - loss: 0.1370 - accuracy: 0.9578 - val_loss: 0.1193 - val_accuracy: 0.9774\n",
      "Epoch 3/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.1090 - accuracy: 0.9667 - val_loss: 0.1050 - val_accuracy: 0.9812\n",
      "Epoch 4/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0902 - accuracy: 0.9735 - val_loss: 0.1046 - val_accuracy: 0.9817\n",
      "Epoch 5/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0817 - accuracy: 0.9759 - val_loss: 0.1324 - val_accuracy: 0.9831\n",
      "Epoch 6/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0727 - accuracy: 0.9766 - val_loss: 0.2502 - val_accuracy: 0.9841\n",
      "Epoch 7/100\n",
      "719/719 [==============================] - 5s 6ms/step - loss: 0.0673 - accuracy: 0.9795 - val_loss: 0.1440 - val_accuracy: 0.9829\n",
      "Epoch 8/100\n",
      "719/719 [==============================] - 4s 5ms/step - loss: 0.0611 - accuracy: 0.9821 - val_loss: 0.1605 - val_accuracy: 0.9851\n",
      "Epoch 9/100\n",
      "719/719 [==============================] - 4s 5ms/step - loss: 0.0549 - accuracy: 0.9833 - val_loss: 0.0954 - val_accuracy: 0.9871\n",
      "Epoch 10/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0590 - accuracy: 0.9820 - val_loss: 0.1306 - val_accuracy: 0.9843\n",
      "Epoch 11/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0548 - accuracy: 0.9832 - val_loss: 0.1715 - val_accuracy: 0.9851\n",
      "Epoch 12/100\n",
      "719/719 [==============================] - 4s 5ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 0.1313 - val_accuracy: 0.9857\n",
      "Epoch 13/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.1373 - val_accuracy: 0.9867\n",
      "Epoch 14/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0426 - accuracy: 0.9873 - val_loss: 0.1500 - val_accuracy: 0.9842\n",
      "Epoch 15/100\n",
      "719/719 [==============================] - 2s 3ms/step - loss: 0.0400 - accuracy: 0.9873 - val_loss: 0.1582 - val_accuracy: 0.9868\n",
      "Epoch 16/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 0.0989 - val_accuracy: 0.9875\n",
      "Epoch 17/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9893 - val_loss: 0.1419 - val_accuracy: 0.9855\n",
      "Epoch 18/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.1350 - val_accuracy: 0.9872\n",
      "Epoch 19/100\n",
      "719/719 [==============================] - 3s 4ms/step - loss: 0.0371 - accuracy: 0.9875 - val_loss: 0.1095 - val_accuracy: 0.9879\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Sequential, callbacks\n",
    "model_A_with_BN_DP = Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.Dropout(0.2), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.Dropout(0.2), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.Dropout(0.2), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.Dropout(0.2), \n",
    "    layers.BatchNormalization(), \n",
    "    layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"), \n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_A_with_BN_DP.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                           optimizer=\"adam\", \n",
    "                           metrics=[\"accuracy\"])\n",
    "\n",
    "history_A_BN_DP = model_A_with_BN_DP.fit(X_train_A, y_train_A, epochs=100, \n",
    "                       validation_data=(X_val_A, y_val_A), \n",
    "                       callbacks=[callbacks.EarlyStopping(patience=10, \n",
    "                                                          restore_best_weights=True, \n",
    "                                                          monitor=\"val_loss\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13092/2889016840.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_A_BN_DP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "pandas.DataFrame(history_A_BN_DP.history).plot(figsize=(10, 7), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_with_BN_DP.save(\"model_A_BN_DP.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "13/13 [==============================] - 2s 138ms/step - loss: 2.9798 - accuracy: 0.1625 - val_loss: 1.9937 - val_accuracy: 0.2071\n",
      "Epoch 2/4\n",
      "13/13 [==============================] - 1s 124ms/step - loss: 1.9609 - accuracy: 0.3425 - val_loss: 1.1660 - val_accuracy: 0.5790\n",
      "Epoch 3/4\n",
      "13/13 [==============================] - 2s 143ms/step - loss: 1.2376 - accuracy: 0.5475 - val_loss: 0.6619 - val_accuracy: 0.7909\n",
      "Epoch 4/4\n",
      "13/13 [==============================] - 2s 145ms/step - loss: 0.8343 - accuracy: 0.6975 - val_loss: 0.3911 - val_accuracy: 0.9165\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers\n",
    "import numpy as np\n",
    "\n",
    "def dataset_split(data, labels, yes=True):\n",
    "    n_data, n_labels = [], []\n",
    "    for i, label in enumerate(labels):\n",
    "        if yes:\n",
    "            if label < 5:\n",
    "                n_data.append(data[i])\n",
    "                n_labels.append(labels[i])\n",
    "        else:\n",
    "            if label > 5:\n",
    "                n_data.append(data[i])\n",
    "                n_labels.append(labels[i]-5)\n",
    "    return np.array(n_data), np.array(n_labels)\n",
    "\n",
    "\n",
    "def reduce_dataset(data, labels):\n",
    "    n_data, n_labels=[], []\n",
    "    count = [0, 0, 0, 0, 0]\n",
    "    for i, label in enumerate(labels):\n",
    "        if (label == 5) & (count[0]< 99):\n",
    "            n_data.append(data[i])\n",
    "            n_labels.append(labels[i]-5)\n",
    "            count[0] += 1\n",
    "        elif (label == 6) & (count[1]< 99):\n",
    "            n_data.append(data[i])\n",
    "            n_labels.append(labels[i]-5)\n",
    "            count[1] += 1\n",
    "        elif (label == 7) & (count[2]< 99):\n",
    "            n_data.append(data[i])\n",
    "            n_labels.append(labels[i]-5)\n",
    "            count[2] += 1\n",
    "        elif (label == 8) & (count[3]< 99):\n",
    "            n_data.append(data[i])\n",
    "            n_labels.append(labels[i]-5)\n",
    "            count[3] += 1\n",
    "        elif (label == 9) & (count[4]< 99):\n",
    "            n_data.append(data[i])\n",
    "            n_labels.append(labels[i]-5)\n",
    "            count[4] += 1        \n",
    "    return np.array(n_data), np.array(n_labels)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train_B, y_train_B = reduce_dataset(X_train, y_train)\n",
    "X_train_B, X_val_B = X_train_A[:400], X_train_A[400:]\n",
    "y_train_B, y_val_B = y_train_A[:400], y_train_A[400:]\n",
    "X_test_B, y_test_B = dataset_split(X_test, y_test, yes=False)\n",
    "\n",
    "pre_model = keras.models.load_model(\"model_A_BN_DP.h5\")\n",
    "model_tf = Sequential(pre_model.layers[:-1])\n",
    "model_tf.add(layers.Dense(5, activation=\"softmax\"))\n",
    "\n",
    "for layer in model_tf.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_tf.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                 optimizer=\"adam\", \n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "history_tf = model_tf.fit(X_train_B, y_train_B, epochs=4, \n",
    "                          validation_data=(X_val_B, y_val_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "13/13 [==============================] - 4s 215ms/step - loss: 0.6008 - accuracy: 0.7700 - val_loss: 0.2651 - val_accuracy: 0.9608\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 0.4847 - accuracy: 0.8275 - val_loss: 0.1955 - val_accuracy: 0.9742\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.3850 - accuracy: 0.8700 - val_loss: 0.1587 - val_accuracy: 0.9778\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.3036 - accuracy: 0.9025 - val_loss: 0.1398 - val_accuracy: 0.9792\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 2s 169ms/step - loss: 0.2836 - accuracy: 0.9200 - val_loss: 0.1291 - val_accuracy: 0.9797\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 2s 198ms/step - loss: 0.2212 - accuracy: 0.9375 - val_loss: 0.1231 - val_accuracy: 0.9804\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 1s 98ms/step - loss: 0.1713 - accuracy: 0.9575 - val_loss: 0.1212 - val_accuracy: 0.9803\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.1758 - accuracy: 0.9625 - val_loss: 0.1205 - val_accuracy: 0.9804\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.1779 - accuracy: 0.9500 - val_loss: 0.1216 - val_accuracy: 0.9806\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.1499 - accuracy: 0.9700 - val_loss: 0.1255 - val_accuracy: 0.9802\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 0.1239 - accuracy: 0.9675 - val_loss: 0.1296 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "for layer in model_tf.layers[:-1]:\n",
    "    layer.trainable=True\n",
    "\n",
    "model_tf.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                 optimizer=keras.optimizers.Adam(learning_rate=1e-4), \n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "history_tf = model_tf.fit(X_train_B, y_train_B, epochs=100, initial_epoch=4, \n",
    "                          validation_data=(X_val_B, y_val_B), \n",
    "                          callbacks=[keras.callbacks.EarlyStopping(patience=3, \n",
    "                                                                   restore_best_weights=True, \n",
    "                                                                   monitor=\"val_loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 2s 97ms/step - loss: 1.6253 - accuracy: 0.4900 - val_loss: 0.3282 - val_accuracy: 0.9129\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.3004 - accuracy: 0.9075 - val_loss: 0.1083 - val_accuracy: 0.9832\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.1364 - accuracy: 0.9675 - val_loss: 0.0956 - val_accuracy: 0.9833\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.0803 - accuracy: 0.9775 - val_loss: 0.0951 - val_accuracy: 0.9832\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.1023 - accuracy: 0.9725 - val_loss: 0.0953 - val_accuracy: 0.9834\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0658 - accuracy: 0.9825 - val_loss: 0.0958 - val_accuracy: 0.9838\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.0452 - accuracy: 0.9875 - val_loss: 0.0962 - val_accuracy: 0.9840\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.0642 - accuracy: 0.9800 - val_loss: 0.0965 - val_accuracy: 0.9842\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0869 - accuracy: 0.9650 - val_loss: 0.0974 - val_accuracy: 0.9842\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0699 - accuracy: 0.9775 - val_loss: 0.0974 - val_accuracy: 0.9845\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.0486 - accuracy: 0.9875 - val_loss: 0.0977 - val_accuracy: 0.9845\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.0672 - accuracy: 0.9750 - val_loss: 0.0971 - val_accuracy: 0.9850\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.0634 - accuracy: 0.9850 - val_loss: 0.0979 - val_accuracy: 0.9850\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.0517 - accuracy: 0.9850 - val_loss: 0.0989 - val_accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "model_tf_2 = Sequential(pre_model.layers[:-1])\n",
    "model_tf_2.add(layers.Dense(5, activation=\"softmax\"))\n",
    "\n",
    "for layer in model_tf_2.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_tf_2.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                   optimizer=\"adam\", \n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "history_tf_2 = model_tf_2.fit(X_train_B, y_train_B, epochs=100, \n",
    "                              validation_data=(X_val_B, y_val_B), \n",
    "                              callbacks=[keras.callbacks.EarlyStopping(patience=10, \n",
    "                                                                       restore_best_weights=True, \n",
    "                                                                       monitor=\"val_loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "13/13 [==============================] - 2s 76ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.1012 - val_accuracy: 0.9835\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.0590 - accuracy: 0.9875 - val_loss: 0.1035 - val_accuracy: 0.9844\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.0459 - accuracy: 0.9875 - val_loss: 0.1063 - val_accuracy: 0.9847\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.0567 - accuracy: 0.9825 - val_loss: 0.1076 - val_accuracy: 0.9847\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0417 - accuracy: 0.9875 - val_loss: 0.1119 - val_accuracy: 0.9843\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.0712 - accuracy: 0.9725 - val_loss: 0.1134 - val_accuracy: 0.9838\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.0213 - accuracy: 0.9950 - val_loss: 0.1147 - val_accuracy: 0.9841\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.0649 - accuracy: 0.9775 - val_loss: 0.1141 - val_accuracy: 0.9845\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.0212 - accuracy: 0.9975 - val_loss: 0.1121 - val_accuracy: 0.9849\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.1130 - val_accuracy: 0.9851\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.0510 - accuracy: 0.9825 - val_loss: 0.1122 - val_accuracy: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd3f0510a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model_A_with_BN_DP.layers[1:7]:\n",
    "    layer.trainble=True\n",
    "\n",
    "model_tf_2.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                   optimizer=\"adam\", \n",
    "                   metrics=[\"accuracy\"])\n",
    "model_tf_2.fit(X_train_B, y_train_B, epochs=100, initial_epoch=14,  \n",
    "               validation_data=(X_val_B, y_val_B), \n",
    "               callbacks=[keras.callbacks.EarlyStopping(patience=10, \n",
    "                                                        restore_best_weights=True, \n",
    "                                                        monitor=\"val_loss\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, callbacks, models\n",
    "from tensorflow import keras\n",
    "\n",
    "input_A = layers.Input(shape=[28, 28], name=\"input_A\")\n",
    "input_B = layers.Input(shape=[28, 28], name=\"input_B\")\n",
    "hidden_A_1 = layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_A_1\")(input_A)\n",
    "hidden_B_1 = layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_B_1\")(input_B)\n",
    "hidden_A_2 = layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_A_2\")(hidden_A_1)\n",
    "hidden_B_2 = layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_B_2\")(hidden_B_1)\n",
    "hidden_A_3 = layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_A_3\")(hidden_A_2)\n",
    "hidden_B_3 = layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_B_3\")(hidden_B_2)\n",
    "hidden_A_4 = layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_A_4\")(hidden_A_3)\n",
    "hidden_B_4 = layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_B_4\")(hidden_B_3)\n",
    "hidden_A_5 = layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_A_5\")(hidden_A_4)\n",
    "hidden_B_5 = layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_B_5\")(hidden_B_4)\n",
    "intersection = layers.Concatenate(name=\"Join_layer\")([hidden_A_5, hidden_B_5])\n",
    "hidden_dnn = layers.Dense(10, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"hidden_layer\")(intersection)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(hidden_dnn)\n",
    "ax_model = models.Model(inputs=[input_A, input_B], outputs=output)\n",
    "\n",
    "ax_model.compile(loss=\"binary_crossentropy\", \n",
    "                 optimizer=\"adam\", \n",
    "                 metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(ax_model, to_file=\"dot_img_file.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af68422bec32ee5a6de64dec1179cbe01bf4f7813cec231e0768ec582c2e4b4a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
